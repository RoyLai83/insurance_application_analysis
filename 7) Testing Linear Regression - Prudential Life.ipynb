{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 7) Testing Linear Regression - Prudential Life"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Importing Packages and loading into DF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import print_function\n",
    "import timeit\n",
    "\n",
    "from sklearn.model_selection import learning_curve, ShuffleSplit\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import scipy.stats as stats\n",
    "\n",
    "%matplotlib inline\n",
    "\n",
    "import xgboost as xgb\n",
    "from xgboost import XGBRegressor\n",
    "\n",
    "from sklearn.model_selection import train_test_split, cross_val_score, cross_val_predict\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn import metrics\n",
    "from sklearn.metrics import log_loss, confusion_matrix, mean_squared_error\n",
    "\n",
    "pd.set_option('display.max_columns',500)\n",
    "pd.set_option('display.max_rows',500)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "ins_data = './dataset/train.csv'\n",
    "ins = pd.read_csv(ins_data)\n",
    "# ins_test_data = './dataset/test.csv'\n",
    "# ins_test = pd.read_csv(ins_test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(59381, 128)\n"
     ]
    }
   ],
   "source": [
    "print(ins.shape)\n",
    "# print(ins_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cleaing Data\n",
    "- Dropping Axis Column\n",
    "- Creating dummy for column Product_Info_2 column\n",
    "- Removing NaN values - where normally distributed, replacing with mean value, where other columns used meadian."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "ins.drop('Id',axis=1,inplace=True)\n",
    "# ins_test.drop('Id',axis=1,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "ins.Product_Info_2.value_counts()\n",
    "prod_2 = {'A1':1,'A2':2,'A3':3,'A4':4,'A5':5,'A6':6,'A7':7,'A8':8,'B1':9,'B2':10,'C1':11,'C2':12,\n",
    "          'C3':13,'C4':14,'D1':15,'D2':16,'D3':17,'D4':18,'E1':19}\n",
    "\n",
    "ins.replace({\"Product_Info_2\": prod_2},inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(2,6):\n",
    "    ins['Family_Hist_%i' % i].fillna(0,inplace=True)\n",
    "#     ins_test['Family_Hist_%i' % i].fillna(0,inplace=True)\n",
    "\n",
    "for i in [1,10,15,24,32]:\n",
    "    ins['Medical_History_%i' % i].fillna(0,inplace=True)\n",
    "#     ins_test['Medical_History_%i' % i].fillna(0,inplace=True)\n",
    "\n",
    "for i in [1,4,6]:\n",
    "    ins['Employment_Info_%i' % i].fillna(0,inplace=True)\n",
    "#     ins_test['Employment_Info_%i' % i].fillna(0,inplace=True)\n",
    "\n",
    "ins['Insurance_History_5'].fillna(0,inplace=True)\n",
    "# ins_test['Insurance_History_5'].fillna(0,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Product_Info_1         0\n",
       "Product_Info_2         0\n",
       "Product_Info_3         0\n",
       "Product_Info_4         0\n",
       "Product_Info_5         0\n",
       "Product_Info_6         0\n",
       "Product_Info_7         0\n",
       "Ins_Age                0\n",
       "Ht                     0\n",
       "Wt                     0\n",
       "BMI                    0\n",
       "Employment_Info_1      0\n",
       "Employment_Info_2      0\n",
       "Employment_Info_3      0\n",
       "Employment_Info_4      0\n",
       "Employment_Info_5      0\n",
       "Employment_Info_6      0\n",
       "InsuredInfo_1          0\n",
       "InsuredInfo_2          0\n",
       "InsuredInfo_3          0\n",
       "InsuredInfo_4          0\n",
       "InsuredInfo_5          0\n",
       "InsuredInfo_6          0\n",
       "InsuredInfo_7          0\n",
       "Insurance_History_1    0\n",
       "Insurance_History_2    0\n",
       "Insurance_History_3    0\n",
       "Insurance_History_4    0\n",
       "Insurance_History_5    0\n",
       "Insurance_History_7    0\n",
       "Insurance_History_8    0\n",
       "Insurance_History_9    0\n",
       "Family_Hist_1          0\n",
       "Family_Hist_2          0\n",
       "Family_Hist_3          0\n",
       "Family_Hist_4          0\n",
       "Family_Hist_5          0\n",
       "Medical_History_1      0\n",
       "Medical_History_2      0\n",
       "Medical_History_3      0\n",
       "Medical_History_4      0\n",
       "Medical_History_5      0\n",
       "Medical_History_6      0\n",
       "Medical_History_7      0\n",
       "Medical_History_8      0\n",
       "Medical_History_9      0\n",
       "Medical_History_10     0\n",
       "Medical_History_11     0\n",
       "Medical_History_12     0\n",
       "Medical_History_13     0\n",
       "Medical_History_14     0\n",
       "Medical_History_15     0\n",
       "Medical_History_16     0\n",
       "Medical_History_17     0\n",
       "Medical_History_18     0\n",
       "Medical_History_19     0\n",
       "Medical_History_20     0\n",
       "Medical_History_21     0\n",
       "Medical_History_22     0\n",
       "Medical_History_23     0\n",
       "Medical_History_24     0\n",
       "Medical_History_25     0\n",
       "Medical_History_26     0\n",
       "Medical_History_27     0\n",
       "Medical_History_28     0\n",
       "Medical_History_29     0\n",
       "Medical_History_30     0\n",
       "Medical_History_31     0\n",
       "Medical_History_32     0\n",
       "Medical_History_33     0\n",
       "Medical_History_34     0\n",
       "Medical_History_35     0\n",
       "Medical_History_36     0\n",
       "Medical_History_37     0\n",
       "Medical_History_38     0\n",
       "Medical_History_39     0\n",
       "Medical_History_40     0\n",
       "Medical_History_41     0\n",
       "Medical_Keyword_1      0\n",
       "Medical_Keyword_2      0\n",
       "Medical_Keyword_3      0\n",
       "Medical_Keyword_4      0\n",
       "Medical_Keyword_5      0\n",
       "Medical_Keyword_6      0\n",
       "Medical_Keyword_7      0\n",
       "Medical_Keyword_8      0\n",
       "Medical_Keyword_9      0\n",
       "Medical_Keyword_10     0\n",
       "Medical_Keyword_11     0\n",
       "Medical_Keyword_12     0\n",
       "Medical_Keyword_13     0\n",
       "Medical_Keyword_14     0\n",
       "Medical_Keyword_15     0\n",
       "Medical_Keyword_16     0\n",
       "Medical_Keyword_17     0\n",
       "Medical_Keyword_18     0\n",
       "Medical_Keyword_19     0\n",
       "Medical_Keyword_20     0\n",
       "Medical_Keyword_21     0\n",
       "Medical_Keyword_22     0\n",
       "Medical_Keyword_23     0\n",
       "Medical_Keyword_24     0\n",
       "Medical_Keyword_25     0\n",
       "Medical_Keyword_26     0\n",
       "Medical_Keyword_27     0\n",
       "Medical_Keyword_28     0\n",
       "Medical_Keyword_29     0\n",
       "Medical_Keyword_30     0\n",
       "Medical_Keyword_31     0\n",
       "Medical_Keyword_32     0\n",
       "Medical_Keyword_33     0\n",
       "Medical_Keyword_34     0\n",
       "Medical_Keyword_35     0\n",
       "Medical_Keyword_36     0\n",
       "Medical_Keyword_37     0\n",
       "Medical_Keyword_38     0\n",
       "Medical_Keyword_39     0\n",
       "Medical_Keyword_40     0\n",
       "Medical_Keyword_41     0\n",
       "Medical_Keyword_42     0\n",
       "Medical_Keyword_43     0\n",
       "Medical_Keyword_44     0\n",
       "Medical_Keyword_45     0\n",
       "Medical_Keyword_46     0\n",
       "Medical_Keyword_47     0\n",
       "Medical_Keyword_48     0\n",
       "Response               0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ins.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "mvc = ['Family_Hist_2','Family_Hist_3','Family_Hist_4','Family_Hist_5','Medical_History_1',\n",
    "       'Medical_History_10','Medical_History_15','Medical_History_24','Medical_History_32',\n",
    "       'Employment_Info_1','Employment_Info_4','Employment_Info_6','Insurance_History_5']\n",
    "data = ins[pd.notnull(ins['Family_Hist_2'])]\n",
    "target = ins[pd.isnull(ins['Family_Hist_2'])]\n",
    "\n",
    "y = data['Family_Hist_2']\n",
    "X = data.drop(mvc,axis=1)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Linear Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "\n",
    "reg = LinearRegression()\n",
    "scores = cross_val_score(reg,X,y,cv=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.12965417145379787"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scores.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Found array with 0 sample(s) (shape=(0, 114)) while a minimum of 1 is required.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-11-03383b51766a>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[0mreg\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0my\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0mpredictions\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mreg\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtarget\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdrop\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmvc\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0maxis\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      3\u001b[0m \u001b[0mtarget\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'Family_Hist_2'\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpredictions\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[0mins\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mconcat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mtarget\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\base.py\u001b[0m in \u001b[0;36mpredict\u001b[1;34m(self, X)\u001b[0m\n\u001b[0;32m    211\u001b[0m             \u001b[0mReturns\u001b[0m \u001b[0mpredicted\u001b[0m \u001b[0mvalues\u001b[0m\u001b[1;33m.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    212\u001b[0m         \"\"\"\n\u001b[1;32m--> 213\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_decision_function\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    214\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    215\u001b[0m     \u001b[0m_preprocess_data\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mstaticmethod\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0m_preprocess_data\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\base.py\u001b[0m in \u001b[0;36m_decision_function\u001b[1;34m(self, X)\u001b[0m\n\u001b[0;32m    194\u001b[0m         \u001b[0mcheck_is_fitted\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"coef_\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    195\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 196\u001b[1;33m         \u001b[0mX\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcheck_array\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maccept_sparse\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'csr'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'csc'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'coo'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    197\u001b[0m         return safe_sparse_dot(X, self.coef_.T,\n\u001b[0;32m    198\u001b[0m                                dense_output=True) + self.intercept_\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\u001b[0m in \u001b[0;36mcheck_array\u001b[1;34m(array, accept_sparse, accept_large_sparse, dtype, order, copy, force_all_finite, ensure_2d, allow_nd, ensure_min_samples, ensure_min_features, warn_on_dtype, estimator)\u001b[0m\n\u001b[0;32m    580\u001b[0m                              \u001b[1;34m\" minimum of %d is required%s.\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    581\u001b[0m                              % (n_samples, shape_repr, ensure_min_samples,\n\u001b[1;32m--> 582\u001b[1;33m                                 context))\n\u001b[0m\u001b[0;32m    583\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    584\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mensure_min_features\u001b[0m \u001b[1;33m>\u001b[0m \u001b[1;36m0\u001b[0m \u001b[1;32mand\u001b[0m \u001b[0marray\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mndim\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;36m2\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: Found array with 0 sample(s) (shape=(0, 114)) while a minimum of 1 is required."
     ]
    }
   ],
   "source": [
    "reg.fit(X,y)\n",
    "predictions = reg.predict(target.drop(mvc,axis=1))\n",
    "target['Family_Hist_2'] = predictions\n",
    "ins = pd.concat([data,target])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ins.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Family_Hist_3,Family_Hist_5,Medical_History_1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mvc = ['Family_Hist_3','Family_Hist_4','Family_Hist_5','Medical_History_1',\n",
    "       'Medical_History_10','Medical_History_15','Medical_History_24','Medical_History_32',\n",
    "       'Employment_Info_1','Employment_Info_4','Employment_Info_6','Insurance_History_5']\n",
    "data = ins[pd.notnull(ins['Family_Hist_4'])]\n",
    "target = ins[pd.isnull(ins['Family_Hist_4'])]\n",
    "\n",
    "y = data['Family_Hist_4']\n",
    "X = data.drop(mvc,axis=1)\n",
    "reg = LinearRegression()\n",
    "scores = cross_val_score(reg,X,y,cv=5)\n",
    "scores.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "reg.fit(X,y)\n",
    "predictions = reg.predict(target.drop(mvc,axis=1))\n",
    "target['Family_Hist_4'] = predictions\n",
    "ins = pd.concat([data,target])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ins = ins[ins['Employment_Info_1'].notnull()]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Attempting to fit polynomial with degree 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "poly_reg = PolynomialFeatures(degree=2)\n",
    "x_poly = poly_reg.fit_transform(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import neighbors\n",
    "\n",
    "mvc = ['Family_Hist_3','Family_Hist_5','Medical_History_1',\n",
    "       'Medical_History_10','Medical_History_15','Medical_History_24','Medical_History_32',\n",
    "       'Employment_Info_4','Employment_Info_6','Insurance_History_5']\n",
    "data = ins[pd.notnull(ins['Insurance_History_5'])]\n",
    "target = ins[pd.isnull(ins['Insurance_History_5'])]\n",
    "\n",
    "y = data['Insurance_History_5']\n",
    "X = data.drop(mvc,axis=1)\n",
    "knn = neighbors.KNeighborsRegressor(n_neighbors= 5)\n",
    "scores = cross_val_score(reg,X,y,cv=5,n_jobs=-1)\n",
    "scores.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "reg.fit(X,y)\n",
    "predictions = reg.predict(target.drop(mvc,axis=1))\n",
    "target['Family_Hist_4'] = predictions\n",
    "ins = pd.concat([data,target])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ins['Family_Hist_3'].hist()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creating X and y for modelling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in ins.columns:\n",
    "    if str(ins[i].dtypes) == 'int64':\n",
    "        ins[i] = ins[i].astype('int8')\n",
    "    else:\n",
    "        ins[i] = ins[i].astype('float16')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "features = ins.drop(['Response','Ht','Wt'],axis=1)\n",
    "targets = ins.Response\n",
    "targets = targets.map(lambda x: x-1)\n",
    "X, X_holdout, y, y_holdout = train_test_split(features,targets, train_size = 0.8,test_size=0.2,random_state=77)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X,y, train_size = 0.9,test_size=0.1,random_state=50)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Determining Baseline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "7    14028\n",
       "5     8069\n",
       "6     5821\n",
       "1     4714\n",
       "0     4489\n",
       "4     3906\n",
       "3     1003\n",
       "2      723\n",
       "Name: Response, dtype: int64"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.36575211096297333\n"
     ]
    }
   ],
   "source": [
    "baseline=15637/len(y_train)\n",
    "print(baseline)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## XGBoost"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Attempting to use XGBoost Regressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Roy\\Anaconda3\\lib\\site-packages\\xgboost\\core.py:587: FutureWarning: Series.base is deprecated and will be removed in a future version\n",
      "  if getattr(data, 'base', None) is not None and \\\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "XGBRegressor(base_score=0.5, booster='gbtree', colsample_bylevel=1,\n",
       "       colsample_bynode=1, colsample_bytree=0.6, eta=0.02, gamma=5,\n",
       "       importance_type='gain', learning_rate=0.1, max_delta_step=0,\n",
       "       max_depth=6, min_child_weight=5, missing=None, n_estimators=100,\n",
       "       n_jobs=1, nthread=None, num_class=8, objective='multi:softprob',\n",
       "       random_state=0, reg_alpha=6, reg_lambda=10, scale_pos_weight=1,\n",
       "       seed=None, silent=None, subsample=0.8, verbosity=1)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xgb = XGBRegressor(n_estimators=100,max_depth=6,subsample=0.8,min_child_weight=5,eta=0.02,verbosity= 1,colsample_bytree=0.6,objective= 'multi:softprob',num_class= 8,gamma=5,reg_lambda=10,reg_alpha=6)\n",
    "xgb.fit(X_train.values,y_train)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
