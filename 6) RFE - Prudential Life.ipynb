{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# RFE - Prudential Life"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Importing Packages and loading into DF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import print_function\n",
    "import timeit\n",
    "\n",
    "from sklearn.model_selection import learning_curve, ShuffleSplit\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import scipy.stats as stats\n",
    "\n",
    "%matplotlib inline\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression, LogisticRegressionCV\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.svm import SVC\n",
    "import xgboost as xgboost\n",
    "from xgboost import XGBClassifier\n",
    "\n",
    "\n",
    "from sklearn.model_selection import train_test_split, cross_val_score, cross_val_predict\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "import sklearn.ensemble\n",
    "from sklearn.ensemble import VotingClassifier, RandomForestClassifier, GradientBoostingClassifier, ExtraTreesClassifier\n",
    "from sklearn import metrics\n",
    "from sklearn.metrics import log_loss, confusion_matrix, mean_squared_error, accuracy_score\n",
    "\n",
    "import lime\n",
    "import lime.lime_tabular\n",
    "\n",
    "pd.set_option('display.max_columns',500)\n",
    "pd.set_option('display.max_rows',500)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "ins_data = './dataset/train.csv'\n",
    "ins = pd.read_csv(ins_data)\n",
    "# ins_test_data = './dataset/test.csv'\n",
    "# ins_test = pd.read_csv(ins_test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(59381, 128)\n"
     ]
    }
   ],
   "source": [
    "print(ins.shape)\n",
    "# print(ins_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cleaing Data\n",
    "- Dropping Axis Column\n",
    "- Creating dummy for column Product_Info_2 column\n",
    "- Removing NaN values - where normally distributed, replacing with mean value, where other columns used meadian."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[1,\n",
       " 2,\n",
       " 3,\n",
       " 4,\n",
       " 5,\n",
       " 6,\n",
       " 7,\n",
       " 9,\n",
       " 10,\n",
       " 11,\n",
       " 12,\n",
       " 13,\n",
       " 14,\n",
       " 15,\n",
       " 16,\n",
       " 17,\n",
       " 18,\n",
       " 19,\n",
       " 20,\n",
       " 21,\n",
       " 22,\n",
       " 23,\n",
       " 25,\n",
       " 26,\n",
       " 27,\n",
       " 28,\n",
       " 29,\n",
       " 30,\n",
       " 31,\n",
       " 32,\n",
       " 33,\n",
       " 34,\n",
       " 35,\n",
       " 36,\n",
       " 37,\n",
       " 38]"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sorted(ins.Employment_Info_2.value_counts().index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Id</th>\n",
       "      <th>Product_Info_1</th>\n",
       "      <th>Product_Info_2</th>\n",
       "      <th>Product_Info_3</th>\n",
       "      <th>Product_Info_4</th>\n",
       "      <th>Product_Info_5</th>\n",
       "      <th>Product_Info_6</th>\n",
       "      <th>Product_Info_7</th>\n",
       "      <th>Ins_Age</th>\n",
       "      <th>Ht</th>\n",
       "      <th>Wt</th>\n",
       "      <th>BMI</th>\n",
       "      <th>Employment_Info_1</th>\n",
       "      <th>Employment_Info_2</th>\n",
       "      <th>Employment_Info_3</th>\n",
       "      <th>Employment_Info_4</th>\n",
       "      <th>Employment_Info_5</th>\n",
       "      <th>Employment_Info_6</th>\n",
       "      <th>InsuredInfo_1</th>\n",
       "      <th>InsuredInfo_2</th>\n",
       "      <th>InsuredInfo_3</th>\n",
       "      <th>InsuredInfo_4</th>\n",
       "      <th>InsuredInfo_5</th>\n",
       "      <th>InsuredInfo_6</th>\n",
       "      <th>InsuredInfo_7</th>\n",
       "      <th>Insurance_History_1</th>\n",
       "      <th>Insurance_History_2</th>\n",
       "      <th>Insurance_History_3</th>\n",
       "      <th>Insurance_History_4</th>\n",
       "      <th>Insurance_History_5</th>\n",
       "      <th>Insurance_History_7</th>\n",
       "      <th>Insurance_History_8</th>\n",
       "      <th>Insurance_History_9</th>\n",
       "      <th>Family_Hist_1</th>\n",
       "      <th>Family_Hist_2</th>\n",
       "      <th>Family_Hist_3</th>\n",
       "      <th>Family_Hist_4</th>\n",
       "      <th>Family_Hist_5</th>\n",
       "      <th>Medical_History_1</th>\n",
       "      <th>Medical_History_2</th>\n",
       "      <th>Medical_History_3</th>\n",
       "      <th>Medical_History_4</th>\n",
       "      <th>Medical_History_5</th>\n",
       "      <th>Medical_History_6</th>\n",
       "      <th>Medical_History_7</th>\n",
       "      <th>Medical_History_8</th>\n",
       "      <th>Medical_History_9</th>\n",
       "      <th>Medical_History_10</th>\n",
       "      <th>Medical_History_11</th>\n",
       "      <th>Medical_History_12</th>\n",
       "      <th>Medical_History_13</th>\n",
       "      <th>Medical_History_14</th>\n",
       "      <th>Medical_History_15</th>\n",
       "      <th>Medical_History_16</th>\n",
       "      <th>Medical_History_17</th>\n",
       "      <th>Medical_History_18</th>\n",
       "      <th>Medical_History_19</th>\n",
       "      <th>Medical_History_20</th>\n",
       "      <th>Medical_History_21</th>\n",
       "      <th>Medical_History_22</th>\n",
       "      <th>Medical_History_23</th>\n",
       "      <th>Medical_History_24</th>\n",
       "      <th>Medical_History_25</th>\n",
       "      <th>Medical_History_26</th>\n",
       "      <th>Medical_History_27</th>\n",
       "      <th>Medical_History_28</th>\n",
       "      <th>Medical_History_29</th>\n",
       "      <th>Medical_History_30</th>\n",
       "      <th>Medical_History_31</th>\n",
       "      <th>Medical_History_32</th>\n",
       "      <th>Medical_History_33</th>\n",
       "      <th>Medical_History_34</th>\n",
       "      <th>Medical_History_35</th>\n",
       "      <th>Medical_History_36</th>\n",
       "      <th>Medical_History_37</th>\n",
       "      <th>Medical_History_38</th>\n",
       "      <th>Medical_History_39</th>\n",
       "      <th>Medical_History_40</th>\n",
       "      <th>Medical_History_41</th>\n",
       "      <th>Medical_Keyword_1</th>\n",
       "      <th>Medical_Keyword_2</th>\n",
       "      <th>Medical_Keyword_3</th>\n",
       "      <th>Medical_Keyword_4</th>\n",
       "      <th>Medical_Keyword_5</th>\n",
       "      <th>Medical_Keyword_6</th>\n",
       "      <th>Medical_Keyword_7</th>\n",
       "      <th>Medical_Keyword_8</th>\n",
       "      <th>Medical_Keyword_9</th>\n",
       "      <th>Medical_Keyword_10</th>\n",
       "      <th>Medical_Keyword_11</th>\n",
       "      <th>Medical_Keyword_12</th>\n",
       "      <th>Medical_Keyword_13</th>\n",
       "      <th>Medical_Keyword_14</th>\n",
       "      <th>Medical_Keyword_15</th>\n",
       "      <th>Medical_Keyword_16</th>\n",
       "      <th>Medical_Keyword_17</th>\n",
       "      <th>Medical_Keyword_18</th>\n",
       "      <th>Medical_Keyword_19</th>\n",
       "      <th>Medical_Keyword_20</th>\n",
       "      <th>Medical_Keyword_21</th>\n",
       "      <th>Medical_Keyword_22</th>\n",
       "      <th>Medical_Keyword_23</th>\n",
       "      <th>Medical_Keyword_24</th>\n",
       "      <th>Medical_Keyword_25</th>\n",
       "      <th>Medical_Keyword_26</th>\n",
       "      <th>Medical_Keyword_27</th>\n",
       "      <th>Medical_Keyword_28</th>\n",
       "      <th>Medical_Keyword_29</th>\n",
       "      <th>Medical_Keyword_30</th>\n",
       "      <th>Medical_Keyword_31</th>\n",
       "      <th>Medical_Keyword_32</th>\n",
       "      <th>Medical_Keyword_33</th>\n",
       "      <th>Medical_Keyword_34</th>\n",
       "      <th>Medical_Keyword_35</th>\n",
       "      <th>Medical_Keyword_36</th>\n",
       "      <th>Medical_Keyword_37</th>\n",
       "      <th>Medical_Keyword_38</th>\n",
       "      <th>Medical_Keyword_39</th>\n",
       "      <th>Medical_Keyword_40</th>\n",
       "      <th>Medical_Keyword_41</th>\n",
       "      <th>Medical_Keyword_42</th>\n",
       "      <th>Medical_Keyword_43</th>\n",
       "      <th>Medical_Keyword_44</th>\n",
       "      <th>Medical_Keyword_45</th>\n",
       "      <th>Medical_Keyword_46</th>\n",
       "      <th>Medical_Keyword_47</th>\n",
       "      <th>Medical_Keyword_48</th>\n",
       "      <th>Response</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>D3</td>\n",
       "      <td>10</td>\n",
       "      <td>0.076923</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.641791</td>\n",
       "      <td>0.581818</td>\n",
       "      <td>0.148536</td>\n",
       "      <td>0.323008</td>\n",
       "      <td>0.028</td>\n",
       "      <td>12</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>6</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0.000667</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.598039</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.526786</td>\n",
       "      <td>4.0</td>\n",
       "      <td>112</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>240.0</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>A1</td>\n",
       "      <td>26</td>\n",
       "      <td>0.076923</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0.059701</td>\n",
       "      <td>0.600000</td>\n",
       "      <td>0.131799</td>\n",
       "      <td>0.272288</td>\n",
       "      <td>0.000</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2</td>\n",
       "      <td>0.0018</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>6</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0.000133</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0.188406</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.084507</td>\n",
       "      <td>NaN</td>\n",
       "      <td>5.0</td>\n",
       "      <td>412</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "      <td>E1</td>\n",
       "      <td>26</td>\n",
       "      <td>0.076923</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0.029851</td>\n",
       "      <td>0.745455</td>\n",
       "      <td>0.288703</td>\n",
       "      <td>0.428780</td>\n",
       "      <td>0.030</td>\n",
       "      <td>9</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2</td>\n",
       "      <td>0.0300</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>8</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>0.304348</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.225352</td>\n",
       "      <td>NaN</td>\n",
       "      <td>10.0</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>7</td>\n",
       "      <td>1</td>\n",
       "      <td>D4</td>\n",
       "      <td>10</td>\n",
       "      <td>0.487179</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0.164179</td>\n",
       "      <td>0.672727</td>\n",
       "      <td>0.205021</td>\n",
       "      <td>0.352438</td>\n",
       "      <td>0.042</td>\n",
       "      <td>9</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3</td>\n",
       "      <td>0.2000</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>8</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>0.420290</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.352113</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>350</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>8</td>\n",
       "      <td>1</td>\n",
       "      <td>D2</td>\n",
       "      <td>26</td>\n",
       "      <td>0.230769</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0.417910</td>\n",
       "      <td>0.654545</td>\n",
       "      <td>0.234310</td>\n",
       "      <td>0.424046</td>\n",
       "      <td>0.027</td>\n",
       "      <td>9</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2</td>\n",
       "      <td>0.0500</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>6</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>0.463768</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.408451</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>162</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Id  Product_Info_1 Product_Info_2  Product_Info_3  Product_Info_4  \\\n",
       "0   2               1             D3              10        0.076923   \n",
       "1   5               1             A1              26        0.076923   \n",
       "2   6               1             E1              26        0.076923   \n",
       "3   7               1             D4              10        0.487179   \n",
       "4   8               1             D2              26        0.230769   \n",
       "\n",
       "   Product_Info_5  Product_Info_6  Product_Info_7   Ins_Age        Ht  \\\n",
       "0               2               1               1  0.641791  0.581818   \n",
       "1               2               3               1  0.059701  0.600000   \n",
       "2               2               3               1  0.029851  0.745455   \n",
       "3               2               3               1  0.164179  0.672727   \n",
       "4               2               3               1  0.417910  0.654545   \n",
       "\n",
       "         Wt       BMI  Employment_Info_1  Employment_Info_2  \\\n",
       "0  0.148536  0.323008              0.028                 12   \n",
       "1  0.131799  0.272288              0.000                  1   \n",
       "2  0.288703  0.428780              0.030                  9   \n",
       "3  0.205021  0.352438              0.042                  9   \n",
       "4  0.234310  0.424046              0.027                  9   \n",
       "\n",
       "   Employment_Info_3  Employment_Info_4  Employment_Info_5  Employment_Info_6  \\\n",
       "0                  1                0.0                  3                NaN   \n",
       "1                  3                0.0                  2             0.0018   \n",
       "2                  1                0.0                  2             0.0300   \n",
       "3                  1                0.0                  3             0.2000   \n",
       "4                  1                0.0                  2             0.0500   \n",
       "\n",
       "   InsuredInfo_1  InsuredInfo_2  InsuredInfo_3  InsuredInfo_4  InsuredInfo_5  \\\n",
       "0              1              2              6              3              1   \n",
       "1              1              2              6              3              1   \n",
       "2              1              2              8              3              1   \n",
       "3              2              2              8              3              1   \n",
       "4              1              2              6              3              1   \n",
       "\n",
       "   InsuredInfo_6  InsuredInfo_7  Insurance_History_1  Insurance_History_2  \\\n",
       "0              2              1                    1                    1   \n",
       "1              2              1                    2                    1   \n",
       "2              1              1                    2                    1   \n",
       "3              2              1                    2                    1   \n",
       "4              2              1                    2                    1   \n",
       "\n",
       "   Insurance_History_3  Insurance_History_4  Insurance_History_5  \\\n",
       "0                    3                    1             0.000667   \n",
       "1                    3                    1             0.000133   \n",
       "2                    1                    3                  NaN   \n",
       "3                    1                    3                  NaN   \n",
       "4                    1                    3                  NaN   \n",
       "\n",
       "   Insurance_History_7  Insurance_History_8  Insurance_History_9  \\\n",
       "0                    1                    1                    2   \n",
       "1                    1                    3                    2   \n",
       "2                    3                    2                    3   \n",
       "3                    3                    2                    3   \n",
       "4                    3                    2                    3   \n",
       "\n",
       "   Family_Hist_1  Family_Hist_2  Family_Hist_3  Family_Hist_4  Family_Hist_5  \\\n",
       "0              2            NaN       0.598039            NaN       0.526786   \n",
       "1              2       0.188406            NaN       0.084507            NaN   \n",
       "2              3       0.304348            NaN       0.225352            NaN   \n",
       "3              3       0.420290            NaN       0.352113            NaN   \n",
       "4              2       0.463768            NaN       0.408451            NaN   \n",
       "\n",
       "   Medical_History_1  Medical_History_2  Medical_History_3  Medical_History_4  \\\n",
       "0                4.0                112                  2                  1   \n",
       "1                5.0                412                  2                  1   \n",
       "2               10.0                  3                  2                  2   \n",
       "3                0.0                350                  2                  2   \n",
       "4                NaN                162                  2                  2   \n",
       "\n",
       "   Medical_History_5  Medical_History_6  Medical_History_7  Medical_History_8  \\\n",
       "0                  1                  3                  2                  2   \n",
       "1                  1                  3                  2                  2   \n",
       "2                  1                  3                  2                  2   \n",
       "3                  1                  3                  2                  2   \n",
       "4                  1                  3                  2                  2   \n",
       "\n",
       "   Medical_History_9  Medical_History_10  Medical_History_11  \\\n",
       "0                  1                 NaN                   3   \n",
       "1                  1                 NaN                   3   \n",
       "2                  2                 NaN                   3   \n",
       "3                  2                 NaN                   3   \n",
       "4                  2                 NaN                   3   \n",
       "\n",
       "   Medical_History_12  Medical_History_13  Medical_History_14  \\\n",
       "0                   2                   3                   3   \n",
       "1                   2                   3                   3   \n",
       "2                   2                   3                   3   \n",
       "3                   2                   3                   3   \n",
       "4                   2                   3                   3   \n",
       "\n",
       "   Medical_History_15  Medical_History_16  Medical_History_17  \\\n",
       "0               240.0                   3                   3   \n",
       "1                 0.0                   1                   3   \n",
       "2                 NaN                   1                   3   \n",
       "3                 NaN                   1                   3   \n",
       "4                 NaN                   1                   3   \n",
       "\n",
       "   Medical_History_18  Medical_History_19  Medical_History_20  \\\n",
       "0                   1                   1                   2   \n",
       "1                   1                   1                   2   \n",
       "2                   1                   1                   2   \n",
       "3                   1                   1                   2   \n",
       "4                   1                   1                   2   \n",
       "\n",
       "   Medical_History_21  Medical_History_22  Medical_History_23  \\\n",
       "0                   1                   2                   3   \n",
       "1                   1                   2                   3   \n",
       "2                   1                   2                   3   \n",
       "3                   2                   2                   3   \n",
       "4                   1                   2                   3   \n",
       "\n",
       "   Medical_History_24  Medical_History_25  Medical_History_26  \\\n",
       "0                 NaN                   1                   3   \n",
       "1                 NaN                   1                   3   \n",
       "2                 NaN                   2                   2   \n",
       "3                 NaN                   1                   3   \n",
       "4                 NaN                   2                   2   \n",
       "\n",
       "   Medical_History_27  Medical_History_28  Medical_History_29  \\\n",
       "0                   3                   1                   3   \n",
       "1                   3                   1                   3   \n",
       "2                   3                   1                   3   \n",
       "3                   3                   1                   3   \n",
       "4                   3                   1                   3   \n",
       "\n",
       "   Medical_History_30  Medical_History_31  Medical_History_32  \\\n",
       "0                   2                   3                 NaN   \n",
       "1                   2                   3                 NaN   \n",
       "2                   2                   3                 NaN   \n",
       "3                   2                   3                 NaN   \n",
       "4                   2                   3                 NaN   \n",
       "\n",
       "   Medical_History_33  Medical_History_34  Medical_History_35  \\\n",
       "0                   1                   3                   1   \n",
       "1                   3                   1                   1   \n",
       "2                   3                   3                   1   \n",
       "3                   3                   3                   1   \n",
       "4                   3                   3                   1   \n",
       "\n",
       "   Medical_History_36  Medical_History_37  Medical_History_38  \\\n",
       "0                   2                   2                   1   \n",
       "1                   2                   2                   1   \n",
       "2                   3                   2                   1   \n",
       "3                   2                   2                   1   \n",
       "4                   3                   2                   1   \n",
       "\n",
       "   Medical_History_39  Medical_History_40  Medical_History_41  \\\n",
       "0                   3                   3                   3   \n",
       "1                   3                   3                   1   \n",
       "2                   3                   3                   1   \n",
       "3                   3                   3                   1   \n",
       "4                   3                   3                   1   \n",
       "\n",
       "   Medical_Keyword_1  Medical_Keyword_2  Medical_Keyword_3  Medical_Keyword_4  \\\n",
       "0                  0                  0                  0                  0   \n",
       "1                  0                  0                  0                  0   \n",
       "2                  0                  0                  0                  0   \n",
       "3                  0                  0                  0                  0   \n",
       "4                  0                  0                  0                  0   \n",
       "\n",
       "   Medical_Keyword_5  Medical_Keyword_6  Medical_Keyword_7  Medical_Keyword_8  \\\n",
       "0                  0                  0                  0                  0   \n",
       "1                  0                  0                  0                  0   \n",
       "2                  0                  0                  0                  0   \n",
       "3                  0                  0                  0                  0   \n",
       "4                  0                  0                  0                  0   \n",
       "\n",
       "   Medical_Keyword_9  Medical_Keyword_10  Medical_Keyword_11  \\\n",
       "0                  0                   0                   0   \n",
       "1                  0                   0                   0   \n",
       "2                  0                   0                   0   \n",
       "3                  0                   0                   0   \n",
       "4                  0                   0                   0   \n",
       "\n",
       "   Medical_Keyword_12  Medical_Keyword_13  Medical_Keyword_14  \\\n",
       "0                   0                   0                   0   \n",
       "1                   0                   0                   0   \n",
       "2                   0                   0                   0   \n",
       "3                   0                   0                   0   \n",
       "4                   0                   0                   0   \n",
       "\n",
       "   Medical_Keyword_15  Medical_Keyword_16  Medical_Keyword_17  \\\n",
       "0                   0                   0                   0   \n",
       "1                   0                   0                   0   \n",
       "2                   0                   0                   0   \n",
       "3                   0                   0                   0   \n",
       "4                   0                   0                   0   \n",
       "\n",
       "   Medical_Keyword_18  Medical_Keyword_19  Medical_Keyword_20  \\\n",
       "0                   0                   0                   0   \n",
       "1                   0                   0                   0   \n",
       "2                   0                   0                   0   \n",
       "3                   0                   0                   0   \n",
       "4                   0                   0                   0   \n",
       "\n",
       "   Medical_Keyword_21  Medical_Keyword_22  Medical_Keyword_23  \\\n",
       "0                   0                   0                   0   \n",
       "1                   0                   0                   0   \n",
       "2                   0                   0                   0   \n",
       "3                   0                   0                   0   \n",
       "4                   0                   0                   0   \n",
       "\n",
       "   Medical_Keyword_24  Medical_Keyword_25  Medical_Keyword_26  \\\n",
       "0                   0                   0                   0   \n",
       "1                   0                   0                   0   \n",
       "2                   0                   0                   0   \n",
       "3                   0                   0                   0   \n",
       "4                   0                   0                   0   \n",
       "\n",
       "   Medical_Keyword_27  Medical_Keyword_28  Medical_Keyword_29  \\\n",
       "0                   0                   0                   0   \n",
       "1                   0                   0                   0   \n",
       "2                   0                   0                   0   \n",
       "3                   0                   0                   0   \n",
       "4                   0                   0                   0   \n",
       "\n",
       "   Medical_Keyword_30  Medical_Keyword_31  Medical_Keyword_32  \\\n",
       "0                   0                   0                   0   \n",
       "1                   0                   0                   0   \n",
       "2                   0                   0                   0   \n",
       "3                   0                   0                   1   \n",
       "4                   0                   0                   0   \n",
       "\n",
       "   Medical_Keyword_33  Medical_Keyword_34  Medical_Keyword_35  \\\n",
       "0                   0                   0                   0   \n",
       "1                   0                   0                   0   \n",
       "2                   0                   0                   0   \n",
       "3                   0                   0                   0   \n",
       "4                   0                   0                   0   \n",
       "\n",
       "   Medical_Keyword_36  Medical_Keyword_37  Medical_Keyword_38  \\\n",
       "0                   0                   0                   0   \n",
       "1                   0                   0                   0   \n",
       "2                   0                   0                   0   \n",
       "3                   0                   0                   0   \n",
       "4                   0                   0                   0   \n",
       "\n",
       "   Medical_Keyword_39  Medical_Keyword_40  Medical_Keyword_41  \\\n",
       "0                   0                   0                   0   \n",
       "1                   0                   0                   0   \n",
       "2                   0                   0                   0   \n",
       "3                   0                   0                   0   \n",
       "4                   0                   0                   0   \n",
       "\n",
       "   Medical_Keyword_42  Medical_Keyword_43  Medical_Keyword_44  \\\n",
       "0                   0                   0                   0   \n",
       "1                   0                   0                   0   \n",
       "2                   0                   0                   0   \n",
       "3                   0                   0                   0   \n",
       "4                   0                   0                   0   \n",
       "\n",
       "   Medical_Keyword_45  Medical_Keyword_46  Medical_Keyword_47  \\\n",
       "0                   0                   0                   0   \n",
       "1                   0                   0                   0   \n",
       "2                   0                   0                   0   \n",
       "3                   0                   0                   0   \n",
       "4                   0                   0                   0   \n",
       "\n",
       "   Medical_Keyword_48  Response  \n",
       "0                   0         8  \n",
       "1                   0         4  \n",
       "2                   0         8  \n",
       "3                   0         8  \n",
       "4                   0         8  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ins.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Id</th>\n",
       "      <th>Product_Info_1</th>\n",
       "      <th>Product_Info_3</th>\n",
       "      <th>Product_Info_4</th>\n",
       "      <th>Product_Info_5</th>\n",
       "      <th>Product_Info_6</th>\n",
       "      <th>Product_Info_7</th>\n",
       "      <th>Ins_Age</th>\n",
       "      <th>Ht</th>\n",
       "      <th>Wt</th>\n",
       "      <th>BMI</th>\n",
       "      <th>Employment_Info_1</th>\n",
       "      <th>Employment_Info_2</th>\n",
       "      <th>Employment_Info_3</th>\n",
       "      <th>Employment_Info_4</th>\n",
       "      <th>Employment_Info_5</th>\n",
       "      <th>Employment_Info_6</th>\n",
       "      <th>InsuredInfo_1</th>\n",
       "      <th>InsuredInfo_2</th>\n",
       "      <th>InsuredInfo_3</th>\n",
       "      <th>InsuredInfo_4</th>\n",
       "      <th>InsuredInfo_5</th>\n",
       "      <th>InsuredInfo_6</th>\n",
       "      <th>InsuredInfo_7</th>\n",
       "      <th>Insurance_History_1</th>\n",
       "      <th>Insurance_History_2</th>\n",
       "      <th>Insurance_History_3</th>\n",
       "      <th>Insurance_History_4</th>\n",
       "      <th>Insurance_History_5</th>\n",
       "      <th>Insurance_History_7</th>\n",
       "      <th>Insurance_History_8</th>\n",
       "      <th>Insurance_History_9</th>\n",
       "      <th>Family_Hist_1</th>\n",
       "      <th>Family_Hist_2</th>\n",
       "      <th>Family_Hist_3</th>\n",
       "      <th>Family_Hist_4</th>\n",
       "      <th>Family_Hist_5</th>\n",
       "      <th>Medical_History_1</th>\n",
       "      <th>Medical_History_2</th>\n",
       "      <th>Medical_History_3</th>\n",
       "      <th>Medical_History_4</th>\n",
       "      <th>Medical_History_5</th>\n",
       "      <th>Medical_History_6</th>\n",
       "      <th>Medical_History_7</th>\n",
       "      <th>Medical_History_8</th>\n",
       "      <th>Medical_History_9</th>\n",
       "      <th>Medical_History_10</th>\n",
       "      <th>Medical_History_11</th>\n",
       "      <th>Medical_History_12</th>\n",
       "      <th>Medical_History_13</th>\n",
       "      <th>Medical_History_14</th>\n",
       "      <th>Medical_History_15</th>\n",
       "      <th>Medical_History_16</th>\n",
       "      <th>Medical_History_17</th>\n",
       "      <th>Medical_History_18</th>\n",
       "      <th>Medical_History_19</th>\n",
       "      <th>Medical_History_20</th>\n",
       "      <th>Medical_History_21</th>\n",
       "      <th>Medical_History_22</th>\n",
       "      <th>Medical_History_23</th>\n",
       "      <th>Medical_History_24</th>\n",
       "      <th>Medical_History_25</th>\n",
       "      <th>Medical_History_26</th>\n",
       "      <th>Medical_History_27</th>\n",
       "      <th>Medical_History_28</th>\n",
       "      <th>Medical_History_29</th>\n",
       "      <th>Medical_History_30</th>\n",
       "      <th>Medical_History_31</th>\n",
       "      <th>Medical_History_32</th>\n",
       "      <th>Medical_History_33</th>\n",
       "      <th>Medical_History_34</th>\n",
       "      <th>Medical_History_35</th>\n",
       "      <th>Medical_History_36</th>\n",
       "      <th>Medical_History_37</th>\n",
       "      <th>Medical_History_38</th>\n",
       "      <th>Medical_History_39</th>\n",
       "      <th>Medical_History_40</th>\n",
       "      <th>Medical_History_41</th>\n",
       "      <th>Medical_Keyword_1</th>\n",
       "      <th>Medical_Keyword_2</th>\n",
       "      <th>Medical_Keyword_3</th>\n",
       "      <th>Medical_Keyword_4</th>\n",
       "      <th>Medical_Keyword_5</th>\n",
       "      <th>Medical_Keyword_6</th>\n",
       "      <th>Medical_Keyword_7</th>\n",
       "      <th>Medical_Keyword_8</th>\n",
       "      <th>Medical_Keyword_9</th>\n",
       "      <th>Medical_Keyword_10</th>\n",
       "      <th>Medical_Keyword_11</th>\n",
       "      <th>Medical_Keyword_12</th>\n",
       "      <th>Medical_Keyword_13</th>\n",
       "      <th>Medical_Keyword_14</th>\n",
       "      <th>Medical_Keyword_15</th>\n",
       "      <th>Medical_Keyword_16</th>\n",
       "      <th>Medical_Keyword_17</th>\n",
       "      <th>Medical_Keyword_18</th>\n",
       "      <th>Medical_Keyword_19</th>\n",
       "      <th>Medical_Keyword_20</th>\n",
       "      <th>Medical_Keyword_21</th>\n",
       "      <th>Medical_Keyword_22</th>\n",
       "      <th>Medical_Keyword_23</th>\n",
       "      <th>Medical_Keyword_24</th>\n",
       "      <th>Medical_Keyword_25</th>\n",
       "      <th>Medical_Keyword_26</th>\n",
       "      <th>Medical_Keyword_27</th>\n",
       "      <th>Medical_Keyword_28</th>\n",
       "      <th>Medical_Keyword_29</th>\n",
       "      <th>Medical_Keyword_30</th>\n",
       "      <th>Medical_Keyword_31</th>\n",
       "      <th>Medical_Keyword_32</th>\n",
       "      <th>Medical_Keyword_33</th>\n",
       "      <th>Medical_Keyword_34</th>\n",
       "      <th>Medical_Keyword_35</th>\n",
       "      <th>Medical_Keyword_36</th>\n",
       "      <th>Medical_Keyword_37</th>\n",
       "      <th>Medical_Keyword_38</th>\n",
       "      <th>Medical_Keyword_39</th>\n",
       "      <th>Medical_Keyword_40</th>\n",
       "      <th>Medical_Keyword_41</th>\n",
       "      <th>Medical_Keyword_42</th>\n",
       "      <th>Medical_Keyword_43</th>\n",
       "      <th>Medical_Keyword_44</th>\n",
       "      <th>Medical_Keyword_45</th>\n",
       "      <th>Medical_Keyword_46</th>\n",
       "      <th>Medical_Keyword_47</th>\n",
       "      <th>Medical_Keyword_48</th>\n",
       "      <th>Response</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>59381.000000</td>\n",
       "      <td>59381.000000</td>\n",
       "      <td>59381.000000</td>\n",
       "      <td>59381.000000</td>\n",
       "      <td>59381.000000</td>\n",
       "      <td>59381.000000</td>\n",
       "      <td>59381.000000</td>\n",
       "      <td>59381.000000</td>\n",
       "      <td>59381.000000</td>\n",
       "      <td>59381.000000</td>\n",
       "      <td>59381.000000</td>\n",
       "      <td>59362.000000</td>\n",
       "      <td>59381.000000</td>\n",
       "      <td>59381.000000</td>\n",
       "      <td>52602.000000</td>\n",
       "      <td>59381.000000</td>\n",
       "      <td>48527.000000</td>\n",
       "      <td>59381.000000</td>\n",
       "      <td>59381.000000</td>\n",
       "      <td>59381.000000</td>\n",
       "      <td>59381.000000</td>\n",
       "      <td>59381.000000</td>\n",
       "      <td>59381.000000</td>\n",
       "      <td>59381.000000</td>\n",
       "      <td>59381.000000</td>\n",
       "      <td>59381.000000</td>\n",
       "      <td>59381.000000</td>\n",
       "      <td>59381.000000</td>\n",
       "      <td>33985.000000</td>\n",
       "      <td>59381.000000</td>\n",
       "      <td>59381.000000</td>\n",
       "      <td>59381.000000</td>\n",
       "      <td>59381.000000</td>\n",
       "      <td>30725.000000</td>\n",
       "      <td>25140.000000</td>\n",
       "      <td>40197.000000</td>\n",
       "      <td>17570.000000</td>\n",
       "      <td>50492.000000</td>\n",
       "      <td>59381.000000</td>\n",
       "      <td>59381.000000</td>\n",
       "      <td>59381.000000</td>\n",
       "      <td>59381.000000</td>\n",
       "      <td>59381.000000</td>\n",
       "      <td>59381.000000</td>\n",
       "      <td>59381.000000</td>\n",
       "      <td>59381.000000</td>\n",
       "      <td>557.000000</td>\n",
       "      <td>59381.000000</td>\n",
       "      <td>59381.000000</td>\n",
       "      <td>59381.000000</td>\n",
       "      <td>59381.000000</td>\n",
       "      <td>14785.000000</td>\n",
       "      <td>59381.000000</td>\n",
       "      <td>59381.000000</td>\n",
       "      <td>59381.000000</td>\n",
       "      <td>59381.000000</td>\n",
       "      <td>59381.000000</td>\n",
       "      <td>59381.000000</td>\n",
       "      <td>59381.000000</td>\n",
       "      <td>59381.000000</td>\n",
       "      <td>3801.000000</td>\n",
       "      <td>59381.000000</td>\n",
       "      <td>59381.000000</td>\n",
       "      <td>59381.000000</td>\n",
       "      <td>59381.000000</td>\n",
       "      <td>59381.000000</td>\n",
       "      <td>59381.000000</td>\n",
       "      <td>59381.000000</td>\n",
       "      <td>1107.000000</td>\n",
       "      <td>59381.000000</td>\n",
       "      <td>59381.000000</td>\n",
       "      <td>59381.000000</td>\n",
       "      <td>59381.000000</td>\n",
       "      <td>59381.000000</td>\n",
       "      <td>59381.000000</td>\n",
       "      <td>59381.000000</td>\n",
       "      <td>59381.000000</td>\n",
       "      <td>59381.000000</td>\n",
       "      <td>59381.000000</td>\n",
       "      <td>59381.000000</td>\n",
       "      <td>59381.000000</td>\n",
       "      <td>59381.000000</td>\n",
       "      <td>59381.000000</td>\n",
       "      <td>59381.000000</td>\n",
       "      <td>59381.000000</td>\n",
       "      <td>59381.000000</td>\n",
       "      <td>59381.000000</td>\n",
       "      <td>59381.000000</td>\n",
       "      <td>59381.000000</td>\n",
       "      <td>59381.000000</td>\n",
       "      <td>59381.000000</td>\n",
       "      <td>59381.000000</td>\n",
       "      <td>59381.000000</td>\n",
       "      <td>59381.000000</td>\n",
       "      <td>59381.000000</td>\n",
       "      <td>59381.000000</td>\n",
       "      <td>59381.000000</td>\n",
       "      <td>59381.000000</td>\n",
       "      <td>59381.000000</td>\n",
       "      <td>59381.000000</td>\n",
       "      <td>59381.000000</td>\n",
       "      <td>59381.000000</td>\n",
       "      <td>59381.000000</td>\n",
       "      <td>59381.000000</td>\n",
       "      <td>59381.000000</td>\n",
       "      <td>59381.000000</td>\n",
       "      <td>59381.000000</td>\n",
       "      <td>59381.000000</td>\n",
       "      <td>59381.000000</td>\n",
       "      <td>59381.000000</td>\n",
       "      <td>59381.000000</td>\n",
       "      <td>59381.000000</td>\n",
       "      <td>59381.000000</td>\n",
       "      <td>59381.000000</td>\n",
       "      <td>59381.000000</td>\n",
       "      <td>59381.000000</td>\n",
       "      <td>59381.000000</td>\n",
       "      <td>59381.000000</td>\n",
       "      <td>59381.000000</td>\n",
       "      <td>59381.000000</td>\n",
       "      <td>59381.000000</td>\n",
       "      <td>59381.000000</td>\n",
       "      <td>59381.000000</td>\n",
       "      <td>59381.000000</td>\n",
       "      <td>59381.000000</td>\n",
       "      <td>59381.000000</td>\n",
       "      <td>59381.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>39507.211515</td>\n",
       "      <td>1.026355</td>\n",
       "      <td>24.415655</td>\n",
       "      <td>0.328952</td>\n",
       "      <td>2.006955</td>\n",
       "      <td>2.673599</td>\n",
       "      <td>1.043583</td>\n",
       "      <td>0.405567</td>\n",
       "      <td>0.707283</td>\n",
       "      <td>0.292587</td>\n",
       "      <td>0.469462</td>\n",
       "      <td>0.077582</td>\n",
       "      <td>8.641821</td>\n",
       "      <td>1.300904</td>\n",
       "      <td>0.006283</td>\n",
       "      <td>2.142958</td>\n",
       "      <td>0.361469</td>\n",
       "      <td>1.209326</td>\n",
       "      <td>2.007427</td>\n",
       "      <td>5.835840</td>\n",
       "      <td>2.883666</td>\n",
       "      <td>1.027180</td>\n",
       "      <td>1.409188</td>\n",
       "      <td>1.038531</td>\n",
       "      <td>1.727606</td>\n",
       "      <td>1.055792</td>\n",
       "      <td>2.146983</td>\n",
       "      <td>1.958707</td>\n",
       "      <td>0.001733</td>\n",
       "      <td>1.901989</td>\n",
       "      <td>2.048484</td>\n",
       "      <td>2.419360</td>\n",
       "      <td>2.686230</td>\n",
       "      <td>0.474550</td>\n",
       "      <td>0.497737</td>\n",
       "      <td>0.444890</td>\n",
       "      <td>0.484635</td>\n",
       "      <td>7.962172</td>\n",
       "      <td>253.987100</td>\n",
       "      <td>2.102171</td>\n",
       "      <td>1.654873</td>\n",
       "      <td>1.007359</td>\n",
       "      <td>2.889897</td>\n",
       "      <td>2.012277</td>\n",
       "      <td>2.044088</td>\n",
       "      <td>1.769943</td>\n",
       "      <td>141.118492</td>\n",
       "      <td>2.993836</td>\n",
       "      <td>2.056601</td>\n",
       "      <td>2.768141</td>\n",
       "      <td>2.968542</td>\n",
       "      <td>123.760974</td>\n",
       "      <td>1.327529</td>\n",
       "      <td>2.978006</td>\n",
       "      <td>1.053536</td>\n",
       "      <td>1.034455</td>\n",
       "      <td>1.985079</td>\n",
       "      <td>1.108991</td>\n",
       "      <td>1.981644</td>\n",
       "      <td>2.528115</td>\n",
       "      <td>50.635622</td>\n",
       "      <td>1.194961</td>\n",
       "      <td>2.808979</td>\n",
       "      <td>2.980213</td>\n",
       "      <td>1.067210</td>\n",
       "      <td>2.542699</td>\n",
       "      <td>2.040771</td>\n",
       "      <td>2.985265</td>\n",
       "      <td>11.965673</td>\n",
       "      <td>2.804618</td>\n",
       "      <td>2.689076</td>\n",
       "      <td>1.002055</td>\n",
       "      <td>2.179468</td>\n",
       "      <td>1.938398</td>\n",
       "      <td>1.004850</td>\n",
       "      <td>2.830720</td>\n",
       "      <td>2.967599</td>\n",
       "      <td>1.641064</td>\n",
       "      <td>0.042000</td>\n",
       "      <td>0.008942</td>\n",
       "      <td>0.049275</td>\n",
       "      <td>0.014550</td>\n",
       "      <td>0.008622</td>\n",
       "      <td>0.012597</td>\n",
       "      <td>0.013910</td>\n",
       "      <td>0.010407</td>\n",
       "      <td>0.006652</td>\n",
       "      <td>0.036459</td>\n",
       "      <td>0.058015</td>\n",
       "      <td>0.010003</td>\n",
       "      <td>0.005962</td>\n",
       "      <td>0.007848</td>\n",
       "      <td>0.190465</td>\n",
       "      <td>0.012715</td>\n",
       "      <td>0.009161</td>\n",
       "      <td>0.007494</td>\n",
       "      <td>0.009296</td>\n",
       "      <td>0.008134</td>\n",
       "      <td>0.014601</td>\n",
       "      <td>0.037167</td>\n",
       "      <td>0.097775</td>\n",
       "      <td>0.018895</td>\n",
       "      <td>0.089456</td>\n",
       "      <td>0.013439</td>\n",
       "      <td>0.011856</td>\n",
       "      <td>0.014937</td>\n",
       "      <td>0.011755</td>\n",
       "      <td>0.025042</td>\n",
       "      <td>0.010896</td>\n",
       "      <td>0.021168</td>\n",
       "      <td>0.022836</td>\n",
       "      <td>0.020646</td>\n",
       "      <td>0.006938</td>\n",
       "      <td>0.010407</td>\n",
       "      <td>0.066587</td>\n",
       "      <td>0.006837</td>\n",
       "      <td>0.013658</td>\n",
       "      <td>0.056954</td>\n",
       "      <td>0.010054</td>\n",
       "      <td>0.045536</td>\n",
       "      <td>0.010710</td>\n",
       "      <td>0.007528</td>\n",
       "      <td>0.013691</td>\n",
       "      <td>0.008488</td>\n",
       "      <td>0.019905</td>\n",
       "      <td>0.054496</td>\n",
       "      <td>5.636837</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>22815.883089</td>\n",
       "      <td>0.160191</td>\n",
       "      <td>5.072885</td>\n",
       "      <td>0.282562</td>\n",
       "      <td>0.083107</td>\n",
       "      <td>0.739103</td>\n",
       "      <td>0.291949</td>\n",
       "      <td>0.197190</td>\n",
       "      <td>0.074239</td>\n",
       "      <td>0.089037</td>\n",
       "      <td>0.122213</td>\n",
       "      <td>0.082347</td>\n",
       "      <td>4.227082</td>\n",
       "      <td>0.715034</td>\n",
       "      <td>0.032816</td>\n",
       "      <td>0.350033</td>\n",
       "      <td>0.349551</td>\n",
       "      <td>0.417939</td>\n",
       "      <td>0.085858</td>\n",
       "      <td>2.674536</td>\n",
       "      <td>0.320627</td>\n",
       "      <td>0.231566</td>\n",
       "      <td>0.491688</td>\n",
       "      <td>0.274915</td>\n",
       "      <td>0.445195</td>\n",
       "      <td>0.329328</td>\n",
       "      <td>0.989139</td>\n",
       "      <td>0.945739</td>\n",
       "      <td>0.007338</td>\n",
       "      <td>0.971223</td>\n",
       "      <td>0.755149</td>\n",
       "      <td>0.509577</td>\n",
       "      <td>0.483159</td>\n",
       "      <td>0.154959</td>\n",
       "      <td>0.140187</td>\n",
       "      <td>0.163012</td>\n",
       "      <td>0.129200</td>\n",
       "      <td>13.027697</td>\n",
       "      <td>178.621154</td>\n",
       "      <td>0.303098</td>\n",
       "      <td>0.475414</td>\n",
       "      <td>0.085864</td>\n",
       "      <td>0.456128</td>\n",
       "      <td>0.172360</td>\n",
       "      <td>0.291353</td>\n",
       "      <td>0.421032</td>\n",
       "      <td>107.759559</td>\n",
       "      <td>0.095340</td>\n",
       "      <td>0.231153</td>\n",
       "      <td>0.640259</td>\n",
       "      <td>0.197715</td>\n",
       "      <td>98.516206</td>\n",
       "      <td>0.740118</td>\n",
       "      <td>0.146778</td>\n",
       "      <td>0.225848</td>\n",
       "      <td>0.182859</td>\n",
       "      <td>0.121375</td>\n",
       "      <td>0.311847</td>\n",
       "      <td>0.134236</td>\n",
       "      <td>0.849170</td>\n",
       "      <td>78.149069</td>\n",
       "      <td>0.406082</td>\n",
       "      <td>0.393237</td>\n",
       "      <td>0.197652</td>\n",
       "      <td>0.250589</td>\n",
       "      <td>0.839904</td>\n",
       "      <td>0.198100</td>\n",
       "      <td>0.170989</td>\n",
       "      <td>38.718774</td>\n",
       "      <td>0.593798</td>\n",
       "      <td>0.724661</td>\n",
       "      <td>0.063806</td>\n",
       "      <td>0.412633</td>\n",
       "      <td>0.240574</td>\n",
       "      <td>0.069474</td>\n",
       "      <td>0.556665</td>\n",
       "      <td>0.252427</td>\n",
       "      <td>0.933361</td>\n",
       "      <td>0.200591</td>\n",
       "      <td>0.094141</td>\n",
       "      <td>0.216443</td>\n",
       "      <td>0.119744</td>\n",
       "      <td>0.092456</td>\n",
       "      <td>0.111526</td>\n",
       "      <td>0.117119</td>\n",
       "      <td>0.101485</td>\n",
       "      <td>0.081289</td>\n",
       "      <td>0.187432</td>\n",
       "      <td>0.233774</td>\n",
       "      <td>0.099515</td>\n",
       "      <td>0.076981</td>\n",
       "      <td>0.088239</td>\n",
       "      <td>0.392671</td>\n",
       "      <td>0.112040</td>\n",
       "      <td>0.095275</td>\n",
       "      <td>0.086244</td>\n",
       "      <td>0.095967</td>\n",
       "      <td>0.089821</td>\n",
       "      <td>0.119949</td>\n",
       "      <td>0.189172</td>\n",
       "      <td>0.297013</td>\n",
       "      <td>0.136155</td>\n",
       "      <td>0.285404</td>\n",
       "      <td>0.115145</td>\n",
       "      <td>0.108237</td>\n",
       "      <td>0.121304</td>\n",
       "      <td>0.107780</td>\n",
       "      <td>0.156253</td>\n",
       "      <td>0.103813</td>\n",
       "      <td>0.143947</td>\n",
       "      <td>0.149380</td>\n",
       "      <td>0.142198</td>\n",
       "      <td>0.083007</td>\n",
       "      <td>0.101485</td>\n",
       "      <td>0.249307</td>\n",
       "      <td>0.082405</td>\n",
       "      <td>0.116066</td>\n",
       "      <td>0.231757</td>\n",
       "      <td>0.099764</td>\n",
       "      <td>0.208479</td>\n",
       "      <td>0.102937</td>\n",
       "      <td>0.086436</td>\n",
       "      <td>0.116207</td>\n",
       "      <td>0.091737</td>\n",
       "      <td>0.139676</td>\n",
       "      <td>0.226995</td>\n",
       "      <td>2.456833</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>2.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>19780.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>26.000000</td>\n",
       "      <td>0.076923</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.238806</td>\n",
       "      <td>0.654545</td>\n",
       "      <td>0.225941</td>\n",
       "      <td>0.385517</td>\n",
       "      <td>0.035000</td>\n",
       "      <td>9.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>0.060000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000400</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>0.362319</td>\n",
       "      <td>0.401961</td>\n",
       "      <td>0.323944</td>\n",
       "      <td>0.401786</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>112.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>8.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>17.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>4.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>39487.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>26.000000</td>\n",
       "      <td>0.230769</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.402985</td>\n",
       "      <td>0.709091</td>\n",
       "      <td>0.288703</td>\n",
       "      <td>0.451349</td>\n",
       "      <td>0.060000</td>\n",
       "      <td>9.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>0.250000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>0.000973</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>0.463768</td>\n",
       "      <td>0.519608</td>\n",
       "      <td>0.422535</td>\n",
       "      <td>0.508929</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>162.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>229.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>117.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>8.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>6.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>59211.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>26.000000</td>\n",
       "      <td>0.487179</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.567164</td>\n",
       "      <td>0.763636</td>\n",
       "      <td>0.345188</td>\n",
       "      <td>0.532858</td>\n",
       "      <td>0.100000</td>\n",
       "      <td>9.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>0.550000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>8.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>0.002000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>0.579710</td>\n",
       "      <td>0.598039</td>\n",
       "      <td>0.563380</td>\n",
       "      <td>0.580357</td>\n",
       "      <td>9.000000</td>\n",
       "      <td>418.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>240.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>240.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>64.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>8.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>79146.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>38.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>38.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>11.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.943662</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>240.000000</td>\n",
       "      <td>648.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>240.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>240.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>240.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>240.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>8.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 Id  Product_Info_1  Product_Info_3  Product_Info_4  \\\n",
       "count  59381.000000    59381.000000    59381.000000    59381.000000   \n",
       "mean   39507.211515        1.026355       24.415655        0.328952   \n",
       "std    22815.883089        0.160191        5.072885        0.282562   \n",
       "min        2.000000        1.000000        1.000000        0.000000   \n",
       "25%    19780.000000        1.000000       26.000000        0.076923   \n",
       "50%    39487.000000        1.000000       26.000000        0.230769   \n",
       "75%    59211.000000        1.000000       26.000000        0.487179   \n",
       "max    79146.000000        2.000000       38.000000        1.000000   \n",
       "\n",
       "       Product_Info_5  Product_Info_6  Product_Info_7       Ins_Age  \\\n",
       "count    59381.000000    59381.000000    59381.000000  59381.000000   \n",
       "mean         2.006955        2.673599        1.043583      0.405567   \n",
       "std          0.083107        0.739103        0.291949      0.197190   \n",
       "min          2.000000        1.000000        1.000000      0.000000   \n",
       "25%          2.000000        3.000000        1.000000      0.238806   \n",
       "50%          2.000000        3.000000        1.000000      0.402985   \n",
       "75%          2.000000        3.000000        1.000000      0.567164   \n",
       "max          3.000000        3.000000        3.000000      1.000000   \n",
       "\n",
       "                 Ht            Wt           BMI  Employment_Info_1  \\\n",
       "count  59381.000000  59381.000000  59381.000000       59362.000000   \n",
       "mean       0.707283      0.292587      0.469462           0.077582   \n",
       "std        0.074239      0.089037      0.122213           0.082347   \n",
       "min        0.000000      0.000000      0.000000           0.000000   \n",
       "25%        0.654545      0.225941      0.385517           0.035000   \n",
       "50%        0.709091      0.288703      0.451349           0.060000   \n",
       "75%        0.763636      0.345188      0.532858           0.100000   \n",
       "max        1.000000      1.000000      1.000000           1.000000   \n",
       "\n",
       "       Employment_Info_2  Employment_Info_3  Employment_Info_4  \\\n",
       "count       59381.000000       59381.000000       52602.000000   \n",
       "mean            8.641821           1.300904           0.006283   \n",
       "std             4.227082           0.715034           0.032816   \n",
       "min             1.000000           1.000000           0.000000   \n",
       "25%             9.000000           1.000000           0.000000   \n",
       "50%             9.000000           1.000000           0.000000   \n",
       "75%             9.000000           1.000000           0.000000   \n",
       "max            38.000000           3.000000           1.000000   \n",
       "\n",
       "       Employment_Info_5  Employment_Info_6  InsuredInfo_1  InsuredInfo_2  \\\n",
       "count       59381.000000       48527.000000   59381.000000   59381.000000   \n",
       "mean            2.142958           0.361469       1.209326       2.007427   \n",
       "std             0.350033           0.349551       0.417939       0.085858   \n",
       "min             2.000000           0.000000       1.000000       2.000000   \n",
       "25%             2.000000           0.060000       1.000000       2.000000   \n",
       "50%             2.000000           0.250000       1.000000       2.000000   \n",
       "75%             2.000000           0.550000       1.000000       2.000000   \n",
       "max             3.000000           1.000000       3.000000       3.000000   \n",
       "\n",
       "       InsuredInfo_3  InsuredInfo_4  InsuredInfo_5  InsuredInfo_6  \\\n",
       "count   59381.000000   59381.000000   59381.000000   59381.000000   \n",
       "mean        5.835840       2.883666       1.027180       1.409188   \n",
       "std         2.674536       0.320627       0.231566       0.491688   \n",
       "min         1.000000       2.000000       1.000000       1.000000   \n",
       "25%         3.000000       3.000000       1.000000       1.000000   \n",
       "50%         6.000000       3.000000       1.000000       1.000000   \n",
       "75%         8.000000       3.000000       1.000000       2.000000   \n",
       "max        11.000000       3.000000       3.000000       2.000000   \n",
       "\n",
       "       InsuredInfo_7  Insurance_History_1  Insurance_History_2  \\\n",
       "count   59381.000000         59381.000000         59381.000000   \n",
       "mean        1.038531             1.727606             1.055792   \n",
       "std         0.274915             0.445195             0.329328   \n",
       "min         1.000000             1.000000             1.000000   \n",
       "25%         1.000000             1.000000             1.000000   \n",
       "50%         1.000000             2.000000             1.000000   \n",
       "75%         1.000000             2.000000             1.000000   \n",
       "max         3.000000             2.000000             3.000000   \n",
       "\n",
       "       Insurance_History_3  Insurance_History_4  Insurance_History_5  \\\n",
       "count         59381.000000         59381.000000         33985.000000   \n",
       "mean              2.146983             1.958707             0.001733   \n",
       "std               0.989139             0.945739             0.007338   \n",
       "min               1.000000             1.000000             0.000000   \n",
       "25%               1.000000             1.000000             0.000400   \n",
       "50%               3.000000             2.000000             0.000973   \n",
       "75%               3.000000             3.000000             0.002000   \n",
       "max               3.000000             3.000000             1.000000   \n",
       "\n",
       "       Insurance_History_7  Insurance_History_8  Insurance_History_9  \\\n",
       "count         59381.000000         59381.000000         59381.000000   \n",
       "mean              1.901989             2.048484             2.419360   \n",
       "std               0.971223             0.755149             0.509577   \n",
       "min               1.000000             1.000000             1.000000   \n",
       "25%               1.000000             1.000000             2.000000   \n",
       "50%               1.000000             2.000000             2.000000   \n",
       "75%               3.000000             3.000000             3.000000   \n",
       "max               3.000000             3.000000             3.000000   \n",
       "\n",
       "       Family_Hist_1  Family_Hist_2  Family_Hist_3  Family_Hist_4  \\\n",
       "count   59381.000000   30725.000000   25140.000000   40197.000000   \n",
       "mean        2.686230       0.474550       0.497737       0.444890   \n",
       "std         0.483159       0.154959       0.140187       0.163012   \n",
       "min         1.000000       0.000000       0.000000       0.000000   \n",
       "25%         2.000000       0.362319       0.401961       0.323944   \n",
       "50%         3.000000       0.463768       0.519608       0.422535   \n",
       "75%         3.000000       0.579710       0.598039       0.563380   \n",
       "max         3.000000       1.000000       1.000000       0.943662   \n",
       "\n",
       "       Family_Hist_5  Medical_History_1  Medical_History_2  Medical_History_3  \\\n",
       "count   17570.000000       50492.000000       59381.000000       59381.000000   \n",
       "mean        0.484635           7.962172         253.987100           2.102171   \n",
       "std         0.129200          13.027697         178.621154           0.303098   \n",
       "min         0.000000           0.000000           1.000000           1.000000   \n",
       "25%         0.401786           2.000000         112.000000           2.000000   \n",
       "50%         0.508929           4.000000         162.000000           2.000000   \n",
       "75%         0.580357           9.000000         418.000000           2.000000   \n",
       "max         1.000000         240.000000         648.000000           3.000000   \n",
       "\n",
       "       Medical_History_4  Medical_History_5  Medical_History_6  \\\n",
       "count       59381.000000       59381.000000       59381.000000   \n",
       "mean            1.654873           1.007359           2.889897   \n",
       "std             0.475414           0.085864           0.456128   \n",
       "min             1.000000           1.000000           1.000000   \n",
       "25%             1.000000           1.000000           3.000000   \n",
       "50%             2.000000           1.000000           3.000000   \n",
       "75%             2.000000           1.000000           3.000000   \n",
       "max             2.000000           3.000000           3.000000   \n",
       "\n",
       "       Medical_History_7  Medical_History_8  Medical_History_9  \\\n",
       "count       59381.000000       59381.000000       59381.000000   \n",
       "mean            2.012277           2.044088           1.769943   \n",
       "std             0.172360           0.291353           0.421032   \n",
       "min             1.000000           1.000000           1.000000   \n",
       "25%             2.000000           2.000000           2.000000   \n",
       "50%             2.000000           2.000000           2.000000   \n",
       "75%             2.000000           2.000000           2.000000   \n",
       "max             3.000000           3.000000           3.000000   \n",
       "\n",
       "       Medical_History_10  Medical_History_11  Medical_History_12  \\\n",
       "count          557.000000        59381.000000        59381.000000   \n",
       "mean           141.118492            2.993836            2.056601   \n",
       "std            107.759559            0.095340            0.231153   \n",
       "min              0.000000            1.000000            1.000000   \n",
       "25%              8.000000            3.000000            2.000000   \n",
       "50%            229.000000            3.000000            2.000000   \n",
       "75%            240.000000            3.000000            2.000000   \n",
       "max            240.000000            3.000000            3.000000   \n",
       "\n",
       "       Medical_History_13  Medical_History_14  Medical_History_15  \\\n",
       "count        59381.000000        59381.000000        14785.000000   \n",
       "mean             2.768141            2.968542          123.760974   \n",
       "std              0.640259            0.197715           98.516206   \n",
       "min              1.000000            1.000000            0.000000   \n",
       "25%              3.000000            3.000000           17.000000   \n",
       "50%              3.000000            3.000000          117.000000   \n",
       "75%              3.000000            3.000000          240.000000   \n",
       "max              3.000000            3.000000          240.000000   \n",
       "\n",
       "       Medical_History_16  Medical_History_17  Medical_History_18  \\\n",
       "count        59381.000000        59381.000000        59381.000000   \n",
       "mean             1.327529            2.978006            1.053536   \n",
       "std              0.740118            0.146778            0.225848   \n",
       "min              1.000000            1.000000            1.000000   \n",
       "25%              1.000000            3.000000            1.000000   \n",
       "50%              1.000000            3.000000            1.000000   \n",
       "75%              1.000000            3.000000            1.000000   \n",
       "max              3.000000            3.000000            3.000000   \n",
       "\n",
       "       Medical_History_19  Medical_History_20  Medical_History_21  \\\n",
       "count        59381.000000        59381.000000        59381.000000   \n",
       "mean             1.034455            1.985079            1.108991   \n",
       "std              0.182859            0.121375            0.311847   \n",
       "min              1.000000            1.000000            1.000000   \n",
       "25%              1.000000            2.000000            1.000000   \n",
       "50%              1.000000            2.000000            1.000000   \n",
       "75%              1.000000            2.000000            1.000000   \n",
       "max              3.000000            3.000000            3.000000   \n",
       "\n",
       "       Medical_History_22  Medical_History_23  Medical_History_24  \\\n",
       "count        59381.000000        59381.000000         3801.000000   \n",
       "mean             1.981644            2.528115           50.635622   \n",
       "std              0.134236            0.849170           78.149069   \n",
       "min              1.000000            1.000000            0.000000   \n",
       "25%              2.000000            3.000000            1.000000   \n",
       "50%              2.000000            3.000000            8.000000   \n",
       "75%              2.000000            3.000000           64.000000   \n",
       "max              2.000000            3.000000          240.000000   \n",
       "\n",
       "       Medical_History_25  Medical_History_26  Medical_History_27  \\\n",
       "count        59381.000000        59381.000000        59381.000000   \n",
       "mean             1.194961            2.808979            2.980213   \n",
       "std              0.406082            0.393237            0.197652   \n",
       "min              1.000000            1.000000            1.000000   \n",
       "25%              1.000000            3.000000            3.000000   \n",
       "50%              1.000000            3.000000            3.000000   \n",
       "75%              1.000000            3.000000            3.000000   \n",
       "max              3.000000            3.000000            3.000000   \n",
       "\n",
       "       Medical_History_28  Medical_History_29  Medical_History_30  \\\n",
       "count        59381.000000        59381.000000        59381.000000   \n",
       "mean             1.067210            2.542699            2.040771   \n",
       "std              0.250589            0.839904            0.198100   \n",
       "min              1.000000            1.000000            1.000000   \n",
       "25%              1.000000            3.000000            2.000000   \n",
       "50%              1.000000            3.000000            2.000000   \n",
       "75%              1.000000            3.000000            2.000000   \n",
       "max              3.000000            3.000000            3.000000   \n",
       "\n",
       "       Medical_History_31  Medical_History_32  Medical_History_33  \\\n",
       "count        59381.000000         1107.000000        59381.000000   \n",
       "mean             2.985265           11.965673            2.804618   \n",
       "std              0.170989           38.718774            0.593798   \n",
       "min              1.000000            0.000000            1.000000   \n",
       "25%              3.000000            0.000000            3.000000   \n",
       "50%              3.000000            0.000000            3.000000   \n",
       "75%              3.000000            2.000000            3.000000   \n",
       "max              3.000000          240.000000            3.000000   \n",
       "\n",
       "       Medical_History_34  Medical_History_35  Medical_History_36  \\\n",
       "count        59381.000000        59381.000000        59381.000000   \n",
       "mean             2.689076            1.002055            2.179468   \n",
       "std              0.724661            0.063806            0.412633   \n",
       "min              1.000000            1.000000            1.000000   \n",
       "25%              3.000000            1.000000            2.000000   \n",
       "50%              3.000000            1.000000            2.000000   \n",
       "75%              3.000000            1.000000            2.000000   \n",
       "max              3.000000            3.000000            3.000000   \n",
       "\n",
       "       Medical_History_37  Medical_History_38  Medical_History_39  \\\n",
       "count        59381.000000        59381.000000        59381.000000   \n",
       "mean             1.938398            1.004850            2.830720   \n",
       "std              0.240574            0.069474            0.556665   \n",
       "min              1.000000            1.000000            1.000000   \n",
       "25%              2.000000            1.000000            3.000000   \n",
       "50%              2.000000            1.000000            3.000000   \n",
       "75%              2.000000            1.000000            3.000000   \n",
       "max              3.000000            2.000000            3.000000   \n",
       "\n",
       "       Medical_History_40  Medical_History_41  Medical_Keyword_1  \\\n",
       "count        59381.000000        59381.000000       59381.000000   \n",
       "mean             2.967599            1.641064           0.042000   \n",
       "std              0.252427            0.933361           0.200591   \n",
       "min              1.000000            1.000000           0.000000   \n",
       "25%              3.000000            1.000000           0.000000   \n",
       "50%              3.000000            1.000000           0.000000   \n",
       "75%              3.000000            3.000000           0.000000   \n",
       "max              3.000000            3.000000           1.000000   \n",
       "\n",
       "       Medical_Keyword_2  Medical_Keyword_3  Medical_Keyword_4  \\\n",
       "count       59381.000000       59381.000000       59381.000000   \n",
       "mean            0.008942           0.049275           0.014550   \n",
       "std             0.094141           0.216443           0.119744   \n",
       "min             0.000000           0.000000           0.000000   \n",
       "25%             0.000000           0.000000           0.000000   \n",
       "50%             0.000000           0.000000           0.000000   \n",
       "75%             0.000000           0.000000           0.000000   \n",
       "max             1.000000           1.000000           1.000000   \n",
       "\n",
       "       Medical_Keyword_5  Medical_Keyword_6  Medical_Keyword_7  \\\n",
       "count       59381.000000       59381.000000       59381.000000   \n",
       "mean            0.008622           0.012597           0.013910   \n",
       "std             0.092456           0.111526           0.117119   \n",
       "min             0.000000           0.000000           0.000000   \n",
       "25%             0.000000           0.000000           0.000000   \n",
       "50%             0.000000           0.000000           0.000000   \n",
       "75%             0.000000           0.000000           0.000000   \n",
       "max             1.000000           1.000000           1.000000   \n",
       "\n",
       "       Medical_Keyword_8  Medical_Keyword_9  Medical_Keyword_10  \\\n",
       "count       59381.000000       59381.000000        59381.000000   \n",
       "mean            0.010407           0.006652            0.036459   \n",
       "std             0.101485           0.081289            0.187432   \n",
       "min             0.000000           0.000000            0.000000   \n",
       "25%             0.000000           0.000000            0.000000   \n",
       "50%             0.000000           0.000000            0.000000   \n",
       "75%             0.000000           0.000000            0.000000   \n",
       "max             1.000000           1.000000            1.000000   \n",
       "\n",
       "       Medical_Keyword_11  Medical_Keyword_12  Medical_Keyword_13  \\\n",
       "count        59381.000000        59381.000000        59381.000000   \n",
       "mean             0.058015            0.010003            0.005962   \n",
       "std              0.233774            0.099515            0.076981   \n",
       "min              0.000000            0.000000            0.000000   \n",
       "25%              0.000000            0.000000            0.000000   \n",
       "50%              0.000000            0.000000            0.000000   \n",
       "75%              0.000000            0.000000            0.000000   \n",
       "max              1.000000            1.000000            1.000000   \n",
       "\n",
       "       Medical_Keyword_14  Medical_Keyword_15  Medical_Keyword_16  \\\n",
       "count        59381.000000        59381.000000        59381.000000   \n",
       "mean             0.007848            0.190465            0.012715   \n",
       "std              0.088239            0.392671            0.112040   \n",
       "min              0.000000            0.000000            0.000000   \n",
       "25%              0.000000            0.000000            0.000000   \n",
       "50%              0.000000            0.000000            0.000000   \n",
       "75%              0.000000            0.000000            0.000000   \n",
       "max              1.000000            1.000000            1.000000   \n",
       "\n",
       "       Medical_Keyword_17  Medical_Keyword_18  Medical_Keyword_19  \\\n",
       "count        59381.000000        59381.000000        59381.000000   \n",
       "mean             0.009161            0.007494            0.009296   \n",
       "std              0.095275            0.086244            0.095967   \n",
       "min              0.000000            0.000000            0.000000   \n",
       "25%              0.000000            0.000000            0.000000   \n",
       "50%              0.000000            0.000000            0.000000   \n",
       "75%              0.000000            0.000000            0.000000   \n",
       "max              1.000000            1.000000            1.000000   \n",
       "\n",
       "       Medical_Keyword_20  Medical_Keyword_21  Medical_Keyword_22  \\\n",
       "count        59381.000000        59381.000000        59381.000000   \n",
       "mean             0.008134            0.014601            0.037167   \n",
       "std              0.089821            0.119949            0.189172   \n",
       "min              0.000000            0.000000            0.000000   \n",
       "25%              0.000000            0.000000            0.000000   \n",
       "50%              0.000000            0.000000            0.000000   \n",
       "75%              0.000000            0.000000            0.000000   \n",
       "max              1.000000            1.000000            1.000000   \n",
       "\n",
       "       Medical_Keyword_23  Medical_Keyword_24  Medical_Keyword_25  \\\n",
       "count        59381.000000        59381.000000        59381.000000   \n",
       "mean             0.097775            0.018895            0.089456   \n",
       "std              0.297013            0.136155            0.285404   \n",
       "min              0.000000            0.000000            0.000000   \n",
       "25%              0.000000            0.000000            0.000000   \n",
       "50%              0.000000            0.000000            0.000000   \n",
       "75%              0.000000            0.000000            0.000000   \n",
       "max              1.000000            1.000000            1.000000   \n",
       "\n",
       "       Medical_Keyword_26  Medical_Keyword_27  Medical_Keyword_28  \\\n",
       "count        59381.000000        59381.000000        59381.000000   \n",
       "mean             0.013439            0.011856            0.014937   \n",
       "std              0.115145            0.108237            0.121304   \n",
       "min              0.000000            0.000000            0.000000   \n",
       "25%              0.000000            0.000000            0.000000   \n",
       "50%              0.000000            0.000000            0.000000   \n",
       "75%              0.000000            0.000000            0.000000   \n",
       "max              1.000000            1.000000            1.000000   \n",
       "\n",
       "       Medical_Keyword_29  Medical_Keyword_30  Medical_Keyword_31  \\\n",
       "count        59381.000000        59381.000000        59381.000000   \n",
       "mean             0.011755            0.025042            0.010896   \n",
       "std              0.107780            0.156253            0.103813   \n",
       "min              0.000000            0.000000            0.000000   \n",
       "25%              0.000000            0.000000            0.000000   \n",
       "50%              0.000000            0.000000            0.000000   \n",
       "75%              0.000000            0.000000            0.000000   \n",
       "max              1.000000            1.000000            1.000000   \n",
       "\n",
       "       Medical_Keyword_32  Medical_Keyword_33  Medical_Keyword_34  \\\n",
       "count        59381.000000        59381.000000        59381.000000   \n",
       "mean             0.021168            0.022836            0.020646   \n",
       "std              0.143947            0.149380            0.142198   \n",
       "min              0.000000            0.000000            0.000000   \n",
       "25%              0.000000            0.000000            0.000000   \n",
       "50%              0.000000            0.000000            0.000000   \n",
       "75%              0.000000            0.000000            0.000000   \n",
       "max              1.000000            1.000000            1.000000   \n",
       "\n",
       "       Medical_Keyword_35  Medical_Keyword_36  Medical_Keyword_37  \\\n",
       "count        59381.000000        59381.000000        59381.000000   \n",
       "mean             0.006938            0.010407            0.066587   \n",
       "std              0.083007            0.101485            0.249307   \n",
       "min              0.000000            0.000000            0.000000   \n",
       "25%              0.000000            0.000000            0.000000   \n",
       "50%              0.000000            0.000000            0.000000   \n",
       "75%              0.000000            0.000000            0.000000   \n",
       "max              1.000000            1.000000            1.000000   \n",
       "\n",
       "       Medical_Keyword_38  Medical_Keyword_39  Medical_Keyword_40  \\\n",
       "count        59381.000000        59381.000000        59381.000000   \n",
       "mean             0.006837            0.013658            0.056954   \n",
       "std              0.082405            0.116066            0.231757   \n",
       "min              0.000000            0.000000            0.000000   \n",
       "25%              0.000000            0.000000            0.000000   \n",
       "50%              0.000000            0.000000            0.000000   \n",
       "75%              0.000000            0.000000            0.000000   \n",
       "max              1.000000            1.000000            1.000000   \n",
       "\n",
       "       Medical_Keyword_41  Medical_Keyword_42  Medical_Keyword_43  \\\n",
       "count        59381.000000        59381.000000        59381.000000   \n",
       "mean             0.010054            0.045536            0.010710   \n",
       "std              0.099764            0.208479            0.102937   \n",
       "min              0.000000            0.000000            0.000000   \n",
       "25%              0.000000            0.000000            0.000000   \n",
       "50%              0.000000            0.000000            0.000000   \n",
       "75%              0.000000            0.000000            0.000000   \n",
       "max              1.000000            1.000000            1.000000   \n",
       "\n",
       "       Medical_Keyword_44  Medical_Keyword_45  Medical_Keyword_46  \\\n",
       "count        59381.000000        59381.000000        59381.000000   \n",
       "mean             0.007528            0.013691            0.008488   \n",
       "std              0.086436            0.116207            0.091737   \n",
       "min              0.000000            0.000000            0.000000   \n",
       "25%              0.000000            0.000000            0.000000   \n",
       "50%              0.000000            0.000000            0.000000   \n",
       "75%              0.000000            0.000000            0.000000   \n",
       "max              1.000000            1.000000            1.000000   \n",
       "\n",
       "       Medical_Keyword_47  Medical_Keyword_48      Response  \n",
       "count        59381.000000        59381.000000  59381.000000  \n",
       "mean             0.019905            0.054496      5.636837  \n",
       "std              0.139676            0.226995      2.456833  \n",
       "min              0.000000            0.000000      1.000000  \n",
       "25%              0.000000            0.000000      4.000000  \n",
       "50%              0.000000            0.000000      6.000000  \n",
       "75%              0.000000            0.000000      8.000000  \n",
       "max              1.000000            1.000000      8.000000  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ins.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x1c09c83afd0>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "sns.boxplot(ins['Ins_Age'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "ins.drop('Id',axis=1,inplace=True)\n",
    "# ins_test.drop('Id',axis=1,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "ins.Product_Info_2.value_counts()\n",
    "prod_2 = {'A1':1,'A2':2,'A3':3,'A4':4,'A5':5,'A6':6,'A7':7,'A8':8,'B1':9,'B2':10,'C1':11,'C2':12,\n",
    "          'C3':13,'C4':14,'D1':15,'D2':16,'D3':17,'D4':18,'E1':19}\n",
    "\n",
    "ins.replace({\"Product_Info_2\": prod_2},inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(2,6):\n",
    "    ins['Family_Hist_%i' % i].fillna(0,inplace=True)\n",
    "#     ins_test['Family_Hist_%i' % i].fillna(0,inplace=True)\n",
    "\n",
    "for i in [1,10,15,24,32]:\n",
    "    ins['Medical_History_%i' % i].fillna(0,inplace=True)\n",
    "#     ins_test['Medical_History_%i' % i].fillna(0,inplace=True)\n",
    "\n",
    "for i in [1,4,6]:\n",
    "    ins['Employment_Info_%i' % i].fillna(0,inplace=True)\n",
    "#     ins_test['Employment_Info_%i' % i].fillna(0,inplace=True)\n",
    "\n",
    "ins['Insurance_History_5'].fillna(0,inplace=True)\n",
    "# ins_test['Insurance_History_5'].fillna(0,inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creating X and y for modelling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in ins.columns:\n",
    "    if str(ins[i].dtypes) == 'int64':\n",
    "        ins[i] = ins[i].astype('int8')\n",
    "    else:\n",
    "        ins[i] = ins[i].astype('float16')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "features = ins[['BMI','Medical_History_4','Medical_Keyword_15','Medical_Keyword_3','Medical_History_23',\n",
    "                'Medical_History_15','Product_Info_4','Medical_History_40','Medical_History_30',\n",
    "                'InsuredInfo_6','InsuredInfo_2','Medical_History_39','Medical_History_5','Medical_Keyword_38',\n",
    "                'InsuredInfo_5','Medical_History_13','Insurance_History_2','Medical_History_24','Medical_History_27'\n",
    "                ,'InsuredInfo_7']]\n",
    "\n",
    "#Previously completed in notebook 2. Here testing how the performance is when I selent various numbers of the top features.\n",
    "targets = ins.Response\n",
    "targets = targets.map(lambda x: x-1)\n",
    "X, X_holdout, y, y_holdout = train_test_split(features,targets, train_size = 0.8,test_size=0.2,random_state=77)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X,y, train_size = 0.9,test_size=0.1,random_state=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x1c0b68557b8>"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "ins.Medical_Keyword_38.plot(kind='hist')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Determining Baseline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "7    14028\n",
       "5     8069\n",
       "6     5821\n",
       "1     4714\n",
       "0     4489\n",
       "4     3906\n",
       "3     1003\n",
       "2      723\n",
       "Name: Response, dtype: int64"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.36575211096297333\n"
     ]
    }
   ],
   "source": [
    "baseline=15637/len(y_train)\n",
    "print(baseline)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "## general purpose function to test models.\n",
    "def fit_model(alg):\n",
    "    alg.fit(X_train,y_train)\n",
    "    scores= cross_val_score(alg,X_train,y_train,cv=5,n_jobs=-1,verbose=1)\n",
    "    ## calculate accuracy\n",
    "    accuracy_score_test = alg.score(X_test,y_test)\n",
    "    accuracy_score_train = alg.score(X_train,y_train)\n",
    "    ## calculate log loss\n",
    "    y_pred = alg.predict_proba(X_train)\n",
    "    log_loss_train = log_loss(y_train,y_pred)\n",
    "    y_pred = alg.predict_proba(X_test)\n",
    "    log_loss_test = log_loss(y_test,y_pred)\n",
    "    ## print values\n",
    "    print('baseline: ',baseline)\n",
    "    print(\"cv scores: \",scores)\n",
    "    print(\"mean cv scores: \",np.mean(scores))\n",
    "    print(\"std cv scores: \",np.std(scores))\n",
    "    print('-------------------------------')\n",
    "    print(\"accuracy score - train: \",accuracy_score_train)\n",
    "    print(\"accuracy score - test: \",accuracy_score_test)\n",
    "    print('-------------------------------')\n",
    "    print(\"log loss score - train: \",log_loss_train)\n",
    "    print(\"log loss score - test: \",log_loss_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The rest of the notebook is just running models like is notebook 2. The result was slightly lower accuracy when compared to using all features.\n",
    "\n",
    "## KNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Roy\\Anaconda3\\lib\\site-packages\\numpy\\core\\_methods.py:36: RuntimeWarning: overflow encountered in reduce\n",
      "  return umr_sum(a, axis, dtype, out, keepdims, initial)\n",
      "C:\\Users\\Roy\\Anaconda3\\lib\\site-packages\\numpy\\core\\_methods.py:36: RuntimeWarning: overflow encountered in reduce\n",
      "  return umr_sum(a, axis, dtype, out, keepdims, initial)\n",
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done   2 out of   5 | elapsed:   19.9s remaining:   29.9s\n",
      "[Parallel(n_jobs=-1)]: Done   5 out of   5 | elapsed:   35.4s finished\n",
      "C:\\Users\\Roy\\Anaconda3\\lib\\site-packages\\numpy\\core\\_methods.py:36: RuntimeWarning: overflow encountered in reduce\n",
      "  return umr_sum(a, axis, dtype, out, keepdims, initial)\n",
      "C:\\Users\\Roy\\Anaconda3\\lib\\site-packages\\numpy\\core\\_methods.py:36: RuntimeWarning: overflow encountered in reduce\n",
      "  return umr_sum(a, axis, dtype, out, keepdims, initial)\n",
      "C:\\Users\\Roy\\Anaconda3\\lib\\site-packages\\numpy\\core\\_methods.py:36: RuntimeWarning: overflow encountered in reduce\n",
      "  return umr_sum(a, axis, dtype, out, keepdims, initial)\n",
      "C:\\Users\\Roy\\Anaconda3\\lib\\site-packages\\numpy\\core\\_methods.py:36: RuntimeWarning: overflow encountered in reduce\n",
      "  return umr_sum(a, axis, dtype, out, keepdims, initial)\n",
      "C:\\Users\\Roy\\Anaconda3\\lib\\site-packages\\numpy\\core\\_methods.py:36: RuntimeWarning: overflow encountered in reduce\n",
      "  return umr_sum(a, axis, dtype, out, keepdims, initial)\n",
      "C:\\Users\\Roy\\Anaconda3\\lib\\site-packages\\numpy\\core\\_methods.py:36: RuntimeWarning: overflow encountered in reduce\n",
      "  return umr_sum(a, axis, dtype, out, keepdims, initial)\n",
      "C:\\Users\\Roy\\Anaconda3\\lib\\site-packages\\numpy\\core\\_methods.py:36: RuntimeWarning: overflow encountered in reduce\n",
      "  return umr_sum(a, axis, dtype, out, keepdims, initial)\n",
      "C:\\Users\\Roy\\Anaconda3\\lib\\site-packages\\numpy\\core\\_methods.py:36: RuntimeWarning: overflow encountered in reduce\n",
      "  return umr_sum(a, axis, dtype, out, keepdims, initial)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "baseline:  0.36575211096297333\n",
      "cv scores:  [0.41875146 0.41288587 0.41054724 0.41326471 0.42160075]\n",
      "mean cv scores:  0.41541000691531077\n",
      "std cv scores:  0.004101478931804735\n",
      "-------------------------------\n",
      "accuracy score - train:  0.6348326433232756\n",
      "accuracy score - test:  0.4089665333613976\n",
      "-------------------------------\n",
      "log loss score - train:  1.6890593085048007\n",
      "log loss score - test:  12.28054561847877\n"
     ]
    }
   ],
   "source": [
    "knn = KNeighborsClassifier(n_neighbors=3,leaf_size=30,n_jobs=-1)\n",
    "fit_model(knn)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Various results\n",
    "\n",
    "CV - results (n_neighbors=4,leaf_size=30,n_jobs=3)\n",
    "\n",
    "[0.31529109 0.31579563 0.31750672 0.31278512 0.31675638]\n",
    "0.31562698836623093\n",
    "\n",
    "CV - results (n_neighbors=5)\n",
    "\n",
    "([0.29261164 0.29276277 0.30218688 0.29687683 0.29581091]\n",
    "0.29604980581700885"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done   2 out of   5 | elapsed:    8.3s remaining:   12.6s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "baseline:  0.36575211096297333\n",
      "cv scores:  [0.48725742 0.47789991 0.47556127 0.48052404 0.4796396 ]\n",
      "mean cv scores:  0.48017644749419264\n",
      "std cv scores:  0.00392509182438362\n",
      "-------------------------------\n",
      "accuracy score - train:  0.4813463382686595\n",
      "accuracy score - test:  0.48600294674805306\n",
      "-------------------------------\n",
      "log loss score - train:  1.4197696975390914\n",
      "log loss score - test:  1.4337926332815445\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done   5 out of   5 | elapsed:   11.4s finished\n",
      "C:\\Users\\Roy\\Anaconda3\\lib\\site-packages\\numpy\\core\\_methods.py:36: RuntimeWarning: overflow encountered in reduce\n",
      "  return umr_sum(a, axis, dtype, out, keepdims, initial)\n",
      "C:\\Users\\Roy\\Anaconda3\\lib\\site-packages\\numpy\\core\\_methods.py:36: RuntimeWarning: overflow encountered in reduce\n",
      "  return umr_sum(a, axis, dtype, out, keepdims, initial)\n",
      "C:\\Users\\Roy\\Anaconda3\\lib\\site-packages\\numpy\\core\\_methods.py:36: RuntimeWarning: overflow encountered in reduce\n",
      "  return umr_sum(a, axis, dtype, out, keepdims, initial)\n",
      "C:\\Users\\Roy\\Anaconda3\\lib\\site-packages\\numpy\\core\\_methods.py:36: RuntimeWarning: overflow encountered in reduce\n",
      "  return umr_sum(a, axis, dtype, out, keepdims, initial)\n"
     ]
    }
   ],
   "source": [
    "lr = LogisticRegression(multi_class='auto', solver = 'liblinear',max_iter=200)\n",
    "fit_model(lr)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "CV Results - (multi_class='auto', solver = 'liblinear')\n",
    "\n",
    "[0.49590835 0.49397872 0.49923985 0.49584747 0.49075591]\n",
    "0.4951460599227767"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "7    0.328702\n",
       "5    0.189624\n",
       "6    0.136318\n",
       "1    0.110144\n",
       "0    0.102823\n",
       "4    0.091081\n",
       "3    0.024536\n",
       "2    0.016771\n",
       "Name: Response, dtype: float64"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train.value_counts(normalize=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "parameters = {'C':[0.001,0.25,0.5,0.75,1,10],\n",
    "              'kernel':['linear','rbf'],\n",
    "              'gamma':['scale',0.001,0.01,0.1,1,2,3],\n",
    "              'decision_function_shape':['ovo','ovr']}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "svm = SVC(probability=True,random_state=42)\n",
    "grid_search = GridSearchCV(svm,param_grid=parameters,cv=3,n_jobs=3)\n",
    "grid_search.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grid_search.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "svm = SVC(C=1, kernel='rbf', gamma='scale',decision_function_shape='ovr',probability=True,random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done   2 out of   5 | elapsed: 64.1min remaining: 96.1min\n",
      "[Parallel(n_jobs=-1)]: Done   5 out of   5 | elapsed: 64.3min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.36029928 0.36244593 0.3573851  0.35466136 0.35490288]\n",
      "0.35793890883976404\n"
     ]
    }
   ],
   "source": [
    "scores = cross_val_score(svm, X_train, y_train, cv=5,n_jobs=-1,verbose=1)\n",
    "predictions = cross_val_predict(svm, X_train,y_train,cv=5,n_jobs=3)\n",
    "r2 = metrics.r2_score(y_train, predictions)\n",
    "print(scores)\n",
    "print(scores.mean())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "CV Scores - (cv=5,n_jobs=-1,verbose=1)\n",
    "\n",
    "[0.36029928 0.36244593 0.3573851  0.35466136 0.35490288]\n",
    "0.35793890883976404"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "svm.fit(X_train,y_train)\n",
    "accuracy_score_train = grid_search.best_score_\n",
    "\n",
    "accuracy_score_test = grid_search.score(X_test,y_test)\n",
    "\n",
    "y_pred = grid_search.predict_proba(X_test)\n",
    "log_loss_test = log_loss(y_test,y_pred)\n",
    "\n",
    "y_pred = grid_search.predict_proba(X_train)\n",
    "log_loss_train = log_loss(y_train,y_pred)\n",
    "\n",
    "print('baseline: ',baseline)\n",
    "print('-------------------------------')\n",
    "print(\"accuracy score - train: \",accuracy_score_train)\n",
    "print(\"accuracy score - test: \",accuracy_score_test)\n",
    "print('-------------------------------')\n",
    "print(\"log loss score - train: \",log_loss_train)\n",
    "print(\"log loss score - test: \",log_loss_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Test 1\n",
    "- C=0.001, kernel='rbf', gamma='scale',decision_function_shape='ovr',probability=True,random_state=42"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Roy\\Anaconda3\\lib\\site-packages\\sklearn\\ensemble\\forest.py:246: FutureWarning: The default value of n_estimators will change from 10 in version 0.20 to 100 in 0.22.\n",
      "  \"10 in version 0.20 to 100 in 0.22.\", FutureWarning)\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done  10 out of  10 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "baseline:  0.36575211096297333\n",
      "cv scores:  [0.50946925 0.5047942  0.48351263 0.49105158 0.51053124]\n",
      "mean cv scores:  0.49987178212588307\n",
      "std cv scores:  0.01072738131344724\n",
      "-------------------------------\n",
      "accuracy score - train:  0.49760250742637946\n",
      "accuracy score - test:  0.4963165649336982\n",
      "-------------------------------\n",
      "log loss score - train:  1.4170993877551938\n",
      "log loss score - test:  1.4230289774027929\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done   2 out of   5 | elapsed:    0.4s remaining:    0.7s\n",
      "[Parallel(n_jobs=-1)]: Done   5 out of   5 | elapsed:    0.5s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done  10 out of  10 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done  10 out of  10 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done  10 out of  10 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done  10 out of  10 | elapsed:    0.0s finished\n"
     ]
    }
   ],
   "source": [
    "forest = RandomForestClassifier(max_depth=5,max_leaf_nodes=30,verbose=1)\n",
    "fit_model(forest)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "CV Results (max_depth=5,max_leaf_nodes=30,class_weight='balanced',verbose=1)\n",
    "\n",
    "[0.42646715 0.41190226 0.42673372 0.40905369 0.41048444]\n",
    "0.4169282498796433\n",
    "\n",
    "CV Results (max_depth=5,max_leaf_nodes=30,verbose=1)\n",
    "\n",
    "[0.44201543 0.44557465 0.46099871 0.43853082 0.4678212 ]\n",
    "0.4509881644734108"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>feature</th>\n",
       "      <th>importance</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>BMI</td>\n",
       "      <td>0.260038</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>90</th>\n",
       "      <td>Medical_Keyword_15</td>\n",
       "      <td>0.192172</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>57</th>\n",
       "      <td>Medical_History_23</td>\n",
       "      <td>0.100389</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>Medical_History_4</td>\n",
       "      <td>0.098857</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Product_Info_4</td>\n",
       "      <td>0.090573</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Ins_Age</td>\n",
       "      <td>0.047791</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49</th>\n",
       "      <td>Medical_History_15</td>\n",
       "      <td>0.040456</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>InsuredInfo_6</td>\n",
       "      <td>0.022139</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>78</th>\n",
       "      <td>Medical_Keyword_3</td>\n",
       "      <td>0.020943</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>64</th>\n",
       "      <td>Medical_History_30</td>\n",
       "      <td>0.012430</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               feature  importance\n",
       "8                  BMI    0.260038\n",
       "90  Medical_Keyword_15    0.192172\n",
       "57  Medical_History_23    0.100389\n",
       "38   Medical_History_4    0.098857\n",
       "3       Product_Info_4    0.090573\n",
       "7              Ins_Age    0.047791\n",
       "49  Medical_History_15    0.040456\n",
       "20       InsuredInfo_6    0.022139\n",
       "78   Medical_Keyword_3    0.020943\n",
       "64  Medical_History_30    0.012430"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "forest_features = pd.DataFrame()\n",
    "forest_features['feature'] = X.columns\n",
    "forest_features['importance'] = forest.feature_importances_\n",
    "forest_features.sort_values('importance',ascending=False).head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## XGBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0]\tvalidation_0-merror:0.446425\tvalidation_0-mlogloss:1.96987\tvalidation_1-merror:0.443486\tvalidation_1-mlogloss:1.97088\n",
      "[1]\tvalidation_0-merror:0.44432\tvalidation_0-mlogloss:1.88228\tvalidation_1-merror:0.441591\tvalidation_1-mlogloss:1.88458\n",
      "[2]\tvalidation_0-merror:0.442144\tvalidation_0-mlogloss:1.81038\tvalidation_1-merror:0.441591\tvalidation_1-mlogloss:1.81396\n",
      "[3]\tvalidation_0-merror:0.443688\tvalidation_0-mlogloss:1.74866\tvalidation_1-merror:0.441381\tvalidation_1-mlogloss:1.75383\n",
      "[4]\tvalidation_0-merror:0.442144\tvalidation_0-mlogloss:1.69555\tvalidation_1-merror:0.445169\tvalidation_1-mlogloss:1.70229\n",
      "[5]\tvalidation_0-merror:0.440952\tvalidation_0-mlogloss:1.6491\tvalidation_1-merror:0.446853\tvalidation_1-mlogloss:1.65723\n",
      "[6]\tvalidation_0-merror:0.439478\tvalidation_0-mlogloss:1.60783\tvalidation_1-merror:0.44538\tvalidation_1-mlogloss:1.61735\n",
      "[7]\tvalidation_0-merror:0.437466\tvalidation_0-mlogloss:1.57151\tvalidation_1-merror:0.445169\tvalidation_1-mlogloss:1.58271\n",
      "[8]\tvalidation_0-merror:0.435619\tvalidation_0-mlogloss:1.53902\tvalidation_1-merror:0.444328\tvalidation_1-mlogloss:1.55161\n",
      "[9]\tvalidation_0-merror:0.434192\tvalidation_0-mlogloss:1.5098\tvalidation_1-merror:0.443275\tvalidation_1-mlogloss:1.52384\n",
      "[10]\tvalidation_0-merror:0.434355\tvalidation_0-mlogloss:1.48337\tvalidation_1-merror:0.442644\tvalidation_1-mlogloss:1.49875\n",
      "[11]\tvalidation_0-merror:0.432929\tvalidation_0-mlogloss:1.45962\tvalidation_1-merror:0.443065\tvalidation_1-mlogloss:1.47676\n",
      "[12]\tvalidation_0-merror:0.431315\tvalidation_0-mlogloss:1.4381\tvalidation_1-merror:0.440328\tvalidation_1-mlogloss:1.4568\n",
      "[13]\tvalidation_0-merror:0.430262\tvalidation_0-mlogloss:1.41859\tvalidation_1-merror:0.439907\tvalidation_1-mlogloss:1.43894\n",
      "[14]\tvalidation_0-merror:0.428812\tvalidation_0-mlogloss:1.40047\tvalidation_1-merror:0.438644\tvalidation_1-mlogloss:1.42235\n",
      "[15]\tvalidation_0-merror:0.428251\tvalidation_0-mlogloss:1.38396\tvalidation_1-merror:0.43654\tvalidation_1-mlogloss:1.40718\n",
      "[16]\tvalidation_0-merror:0.427268\tvalidation_0-mlogloss:1.36848\tvalidation_1-merror:0.43675\tvalidation_1-mlogloss:1.39338\n",
      "[17]\tvalidation_0-merror:0.427105\tvalidation_0-mlogloss:1.35446\tvalidation_1-merror:0.435698\tvalidation_1-mlogloss:1.38063\n",
      "[18]\tvalidation_0-merror:0.425912\tvalidation_0-mlogloss:1.34141\tvalidation_1-merror:0.436119\tvalidation_1-mlogloss:1.36904\n",
      "[19]\tvalidation_0-merror:0.424508\tvalidation_0-mlogloss:1.32916\tvalidation_1-merror:0.434224\tvalidation_1-mlogloss:1.3583\n",
      "[20]\tvalidation_0-merror:0.423713\tvalidation_0-mlogloss:1.31767\tvalidation_1-merror:0.433382\tvalidation_1-mlogloss:1.34846\n",
      "[21]\tvalidation_0-merror:0.423011\tvalidation_0-mlogloss:1.30664\tvalidation_1-merror:0.432961\tvalidation_1-mlogloss:1.33864\n",
      "[22]\tvalidation_0-merror:0.422122\tvalidation_0-mlogloss:1.29658\tvalidation_1-merror:0.432541\tvalidation_1-mlogloss:1.33018\n",
      "[23]\tvalidation_0-merror:0.421842\tvalidation_0-mlogloss:1.28773\tvalidation_1-merror:0.43212\tvalidation_1-mlogloss:1.32294\n",
      "[24]\tvalidation_0-merror:0.420742\tvalidation_0-mlogloss:1.27918\tvalidation_1-merror:0.431909\tvalidation_1-mlogloss:1.31589\n",
      "[25]\tvalidation_0-merror:0.419807\tvalidation_0-mlogloss:1.27135\tvalidation_1-merror:0.430857\tvalidation_1-mlogloss:1.30942\n",
      "[26]\tvalidation_0-merror:0.418871\tvalidation_0-mlogloss:1.26393\tvalidation_1-merror:0.431067\tvalidation_1-mlogloss:1.30344\n",
      "[27]\tvalidation_0-merror:0.41831\tvalidation_0-mlogloss:1.25689\tvalidation_1-merror:0.431278\tvalidation_1-mlogloss:1.29795\n",
      "[28]\tvalidation_0-merror:0.417444\tvalidation_0-mlogloss:1.25007\tvalidation_1-merror:0.430015\tvalidation_1-mlogloss:1.29248\n",
      "[29]\tvalidation_0-merror:0.416345\tvalidation_0-mlogloss:1.24384\tvalidation_1-merror:0.430225\tvalidation_1-mlogloss:1.28754\n",
      "[30]\tvalidation_0-merror:0.415737\tvalidation_0-mlogloss:1.23781\tvalidation_1-merror:0.429804\tvalidation_1-mlogloss:1.28275\n",
      "[31]\tvalidation_0-merror:0.414474\tvalidation_0-mlogloss:1.23204\tvalidation_1-merror:0.428331\tvalidation_1-mlogloss:1.27854\n",
      "[32]\tvalidation_0-merror:0.413421\tvalidation_0-mlogloss:1.22687\tvalidation_1-merror:0.42791\tvalidation_1-mlogloss:1.27459\n",
      "[33]\tvalidation_0-merror:0.412883\tvalidation_0-mlogloss:1.22129\tvalidation_1-merror:0.42812\tvalidation_1-mlogloss:1.27008\n",
      "[34]\tvalidation_0-merror:0.411807\tvalidation_0-mlogloss:1.21662\tvalidation_1-merror:0.428541\tvalidation_1-mlogloss:1.26631\n",
      "[35]\tvalidation_0-merror:0.411456\tvalidation_0-mlogloss:1.21184\tvalidation_1-merror:0.429594\tvalidation_1-mlogloss:1.26278\n",
      "[36]\tvalidation_0-merror:0.410568\tvalidation_0-mlogloss:1.20749\tvalidation_1-merror:0.429173\tvalidation_1-mlogloss:1.25955\n",
      "[37]\tvalidation_0-merror:0.409562\tvalidation_0-mlogloss:1.20307\tvalidation_1-merror:0.42791\tvalidation_1-mlogloss:1.25639\n",
      "[38]\tvalidation_0-merror:0.40893\tvalidation_0-mlogloss:1.1991\tvalidation_1-merror:0.428541\tvalidation_1-mlogloss:1.25373\n",
      "[39]\tvalidation_0-merror:0.408112\tvalidation_0-mlogloss:1.19525\tvalidation_1-merror:0.428752\tvalidation_1-mlogloss:1.25089\n",
      "[40]\tvalidation_0-merror:0.407293\tvalidation_0-mlogloss:1.19176\tvalidation_1-merror:0.42791\tvalidation_1-mlogloss:1.24856\n",
      "[41]\tvalidation_0-merror:0.406451\tvalidation_0-mlogloss:1.18813\tvalidation_1-merror:0.427278\tvalidation_1-mlogloss:1.24607\n",
      "[42]\tvalidation_0-merror:0.405586\tvalidation_0-mlogloss:1.18507\tvalidation_1-merror:0.427489\tvalidation_1-mlogloss:1.24411\n",
      "[43]\tvalidation_0-merror:0.404907\tvalidation_0-mlogloss:1.18191\tvalidation_1-merror:0.427489\tvalidation_1-mlogloss:1.24219\n",
      "[44]\tvalidation_0-merror:0.404159\tvalidation_0-mlogloss:1.17887\tvalidation_1-merror:0.426226\tvalidation_1-mlogloss:1.24021\n",
      "[45]\tvalidation_0-merror:0.403457\tvalidation_0-mlogloss:1.17579\tvalidation_1-merror:0.426437\tvalidation_1-mlogloss:1.23838\n",
      "[46]\tvalidation_0-merror:0.402755\tvalidation_0-mlogloss:1.17288\tvalidation_1-merror:0.425384\tvalidation_1-mlogloss:1.23647\n",
      "[47]\tvalidation_0-merror:0.402405\tvalidation_0-mlogloss:1.17015\tvalidation_1-merror:0.425595\tvalidation_1-mlogloss:1.23489\n",
      "[48]\tvalidation_0-merror:0.401773\tvalidation_0-mlogloss:1.1674\tvalidation_1-merror:0.424121\tvalidation_1-mlogloss:1.23292\n",
      "[49]\tvalidation_0-merror:0.401352\tvalidation_0-mlogloss:1.16508\tvalidation_1-merror:0.423069\tvalidation_1-mlogloss:1.2314\n",
      "[50]\tvalidation_0-merror:0.400416\tvalidation_0-mlogloss:1.16222\tvalidation_1-merror:0.422648\tvalidation_1-mlogloss:1.2301\n",
      "[51]\tvalidation_0-merror:0.400042\tvalidation_0-mlogloss:1.15959\tvalidation_1-merror:0.42349\tvalidation_1-mlogloss:1.22865\n",
      "[52]\tvalidation_0-merror:0.399387\tvalidation_0-mlogloss:1.1571\tvalidation_1-merror:0.423279\tvalidation_1-mlogloss:1.22722\n",
      "[53]\tvalidation_0-merror:0.398639\tvalidation_0-mlogloss:1.15448\tvalidation_1-merror:0.4237\tvalidation_1-mlogloss:1.22599\n",
      "[54]\tvalidation_0-merror:0.397773\tvalidation_0-mlogloss:1.15223\tvalidation_1-merror:0.424332\tvalidation_1-mlogloss:1.22467\n",
      "[55]\tvalidation_0-merror:0.396744\tvalidation_0-mlogloss:1.14956\tvalidation_1-merror:0.423279\tvalidation_1-mlogloss:1.22335\n",
      "[56]\tvalidation_0-merror:0.396487\tvalidation_0-mlogloss:1.14737\tvalidation_1-merror:0.423069\tvalidation_1-mlogloss:1.22238\n",
      "[57]\tvalidation_0-merror:0.395902\tvalidation_0-mlogloss:1.14541\tvalidation_1-merror:0.422648\tvalidation_1-mlogloss:1.22137\n",
      "[58]\tvalidation_0-merror:0.39527\tvalidation_0-mlogloss:1.14335\tvalidation_1-merror:0.422648\tvalidation_1-mlogloss:1.22028\n",
      "[59]\tvalidation_0-merror:0.394733\tvalidation_0-mlogloss:1.14105\tvalidation_1-merror:0.422437\tvalidation_1-mlogloss:1.21911\n",
      "[60]\tvalidation_0-merror:0.39382\tvalidation_0-mlogloss:1.13888\tvalidation_1-merror:0.422016\tvalidation_1-mlogloss:1.21798\n",
      "[61]\tvalidation_0-merror:0.393165\tvalidation_0-mlogloss:1.13657\tvalidation_1-merror:0.421385\tvalidation_1-mlogloss:1.21694\n",
      "[62]\tvalidation_0-merror:0.392557\tvalidation_0-mlogloss:1.13487\tvalidation_1-merror:0.421385\tvalidation_1-mlogloss:1.21595\n",
      "[63]\tvalidation_0-merror:0.39223\tvalidation_0-mlogloss:1.13294\tvalidation_1-merror:0.421595\tvalidation_1-mlogloss:1.215\n",
      "[64]\tvalidation_0-merror:0.391692\tvalidation_0-mlogloss:1.13124\tvalidation_1-merror:0.422227\tvalidation_1-mlogloss:1.21426\n",
      "[65]\tvalidation_0-merror:0.39106\tvalidation_0-mlogloss:1.12943\tvalidation_1-merror:0.422016\tvalidation_1-mlogloss:1.21354\n",
      "[66]\tvalidation_0-merror:0.390756\tvalidation_0-mlogloss:1.12773\tvalidation_1-merror:0.421174\tvalidation_1-mlogloss:1.2125\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[67]\tvalidation_0-merror:0.390218\tvalidation_0-mlogloss:1.12635\tvalidation_1-merror:0.421174\tvalidation_1-mlogloss:1.21185\n",
      "[68]\tvalidation_0-merror:0.38975\tvalidation_0-mlogloss:1.12447\tvalidation_1-merror:0.421174\tvalidation_1-mlogloss:1.21105\n",
      "[69]\tvalidation_0-merror:0.389259\tvalidation_0-mlogloss:1.12291\tvalidation_1-merror:0.421385\tvalidation_1-mlogloss:1.21026\n",
      "[70]\tvalidation_0-merror:0.388791\tvalidation_0-mlogloss:1.1212\tvalidation_1-merror:0.420964\tvalidation_1-mlogloss:1.20956\n",
      "[71]\tvalidation_0-merror:0.388487\tvalidation_0-mlogloss:1.11987\tvalidation_1-merror:0.420333\tvalidation_1-mlogloss:1.2091\n",
      "[72]\tvalidation_0-merror:0.387832\tvalidation_0-mlogloss:1.11769\tvalidation_1-merror:0.420964\tvalidation_1-mlogloss:1.20826\n",
      "[73]\tvalidation_0-merror:0.387154\tvalidation_0-mlogloss:1.11632\tvalidation_1-merror:0.420122\tvalidation_1-mlogloss:1.20755\n",
      "[74]\tvalidation_0-merror:0.386827\tvalidation_0-mlogloss:1.11505\tvalidation_1-merror:0.420333\tvalidation_1-mlogloss:1.20705\n",
      "[75]\tvalidation_0-merror:0.386289\tvalidation_0-mlogloss:1.11335\tvalidation_1-merror:0.419701\tvalidation_1-mlogloss:1.20638\n",
      "[76]\tvalidation_0-merror:0.385914\tvalidation_0-mlogloss:1.11153\tvalidation_1-merror:0.41928\tvalidation_1-mlogloss:1.20559\n",
      "[77]\tvalidation_0-merror:0.385072\tvalidation_0-mlogloss:1.11011\tvalidation_1-merror:0.419491\tvalidation_1-mlogloss:1.20513\n",
      "[78]\tvalidation_0-merror:0.384768\tvalidation_0-mlogloss:1.10863\tvalidation_1-merror:0.418859\tvalidation_1-mlogloss:1.20439\n",
      "[79]\tvalidation_0-merror:0.384137\tvalidation_0-mlogloss:1.10696\tvalidation_1-merror:0.418228\tvalidation_1-mlogloss:1.20377\n",
      "[80]\tvalidation_0-merror:0.383786\tvalidation_0-mlogloss:1.1058\tvalidation_1-merror:0.418649\tvalidation_1-mlogloss:1.20344\n",
      "[81]\tvalidation_0-merror:0.383342\tvalidation_0-mlogloss:1.10404\tvalidation_1-merror:0.418859\tvalidation_1-mlogloss:1.20268\n",
      "[82]\tvalidation_0-merror:0.383014\tvalidation_0-mlogloss:1.10252\tvalidation_1-merror:0.418017\tvalidation_1-mlogloss:1.20199\n",
      "[83]\tvalidation_0-merror:0.382546\tvalidation_0-mlogloss:1.10113\tvalidation_1-merror:0.418228\tvalidation_1-mlogloss:1.20145\n",
      "[84]\tvalidation_0-merror:0.381868\tvalidation_0-mlogloss:1.09975\tvalidation_1-merror:0.417807\tvalidation_1-mlogloss:1.201\n",
      "[85]\tvalidation_0-merror:0.38154\tvalidation_0-mlogloss:1.0982\tvalidation_1-merror:0.417386\tvalidation_1-mlogloss:1.20046\n",
      "[86]\tvalidation_0-merror:0.380652\tvalidation_0-mlogloss:1.09668\tvalidation_1-merror:0.417596\tvalidation_1-mlogloss:1.19991\n",
      "[87]\tvalidation_0-merror:0.380698\tvalidation_0-mlogloss:1.09527\tvalidation_1-merror:0.417175\tvalidation_1-mlogloss:1.19943\n",
      "[88]\tvalidation_0-merror:0.380348\tvalidation_0-mlogloss:1.09419\tvalidation_1-merror:0.418017\tvalidation_1-mlogloss:1.19906\n",
      "[89]\tvalidation_0-merror:0.38002\tvalidation_0-mlogloss:1.09305\tvalidation_1-merror:0.418017\tvalidation_1-mlogloss:1.19865\n",
      "[90]\tvalidation_0-merror:0.379459\tvalidation_0-mlogloss:1.09195\tvalidation_1-merror:0.417386\tvalidation_1-mlogloss:1.19836\n",
      "[91]\tvalidation_0-merror:0.379178\tvalidation_0-mlogloss:1.09081\tvalidation_1-merror:0.417596\tvalidation_1-mlogloss:1.19797\n",
      "[92]\tvalidation_0-merror:0.378897\tvalidation_0-mlogloss:1.08957\tvalidation_1-merror:0.417596\tvalidation_1-mlogloss:1.19754\n",
      "[93]\tvalidation_0-merror:0.378547\tvalidation_0-mlogloss:1.08827\tvalidation_1-merror:0.417596\tvalidation_1-mlogloss:1.19706\n",
      "[94]\tvalidation_0-merror:0.378009\tvalidation_0-mlogloss:1.08725\tvalidation_1-merror:0.417386\tvalidation_1-mlogloss:1.19676\n",
      "[95]\tvalidation_0-merror:0.377705\tvalidation_0-mlogloss:1.08592\tvalidation_1-merror:0.417386\tvalidation_1-mlogloss:1.19668\n",
      "[96]\tvalidation_0-merror:0.377283\tvalidation_0-mlogloss:1.08449\tvalidation_1-merror:0.418228\tvalidation_1-mlogloss:1.19619\n",
      "[97]\tvalidation_0-merror:0.37705\tvalidation_0-mlogloss:1.08349\tvalidation_1-merror:0.418228\tvalidation_1-mlogloss:1.19576\n",
      "[98]\tvalidation_0-merror:0.376722\tvalidation_0-mlogloss:1.08245\tvalidation_1-merror:0.417386\tvalidation_1-mlogloss:1.19558\n",
      "[99]\tvalidation_0-merror:0.376371\tvalidation_0-mlogloss:1.08146\tvalidation_1-merror:0.418017\tvalidation_1-mlogloss:1.19535\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "XGBClassifier(alpha=0.8, base_score=0.5, booster='gbtree',\n",
       "       colsample_bylevel=1, colsample_bytree=1, eta=0.1, gamma=0,\n",
       "       learning_rate=0.1, max_delta_step=0, max_depth=7,\n",
       "       min_child_weight=1, missing=None, n_estimators=100, n_jobs=1,\n",
       "       nthread=None, num_class=7, objective='multi:softprob',\n",
       "       random_state=0, reg_alpha=0, reg_lambda=50, scale_pos_weight=1,\n",
       "       seed=None, silent=True, subsample=1, verbosity=1)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from xgboost import XGBClassifier\n",
    "model = XGBClassifier(learning_rate=0.01,max_depth= 7,eta= 0.1,verbosity= 1,objective= 'multi:softprob',num_class= 7,reg_lambda=0)\n",
    "eval_set = [(X_train, y_train), (X_test, y_test)]\n",
    "model.fit(X_train,y_train,eval_metric=['merror','mlogloss'],eval_set=eval_set, verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done   2 out of   5 | elapsed:  2.5min remaining:  3.8min\n",
      "[Parallel(n_jobs=-1)]: Done   5 out of   5 | elapsed:  2.6min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.5748188  0.57792587 0.57572214 0.56883846 0.57102738]\n",
      "0.5736665303633456\n"
     ]
    }
   ],
   "source": [
    "model = XGBClassifier(n_estimators=90,max_depth=6,min_child_weight=5,eta=0.01,verbosity= 1,colsample_bytree=0.5,objective= 'multi:softprob',num_class= 8)\n",
    "scores = cross_val_score(model, X_train, y_train, cv=5,n_jobs=-1,verbose=1)\n",
    "predictions = cross_val_predict(model, X_train,y_train,cv=5,n_jobs=3)\n",
    "r2 = metrics.r2_score(y_train, predictions)\n",
    "print(scores)\n",
    "print(scores.mean())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "CV Results - XGBClassifier(max_depth= 7,eta= 0.1,verbosity= 1,objective= 'multi:softprob',num_class=8,alpha=0.8,reg_lambda=50)\n",
    "\n",
    "[0.57657236 0.57780896 0.57595603 0.56743479 0.56938919]\n",
    "0.5734322647763243\n",
    "\n",
    "CV Results - n_estimators=90,max_depth=5,eta=0.1,verbosity= 1,colsample_bytree=0.5,objective= 'multi:softprob',num_class= 8,reg_lambda=0\n",
    "\n",
    "[0.57610475 0.57359991 0.57595603 0.56392561 0.57126141]\n",
    "0.572169539099591\n",
    "\n",
    "n_estimators=90,max_depth=5,eta=0.01,verbosity= 1,colsample_bytree=0.5,objective= 'multi:softprob',num_class= 8,reg_lambda=0)\n",
    "\n",
    "[0.57610475 0.57359991 0.57595603 0.56392561 0.57126141]\n",
    "0.572169539099591"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = model.predict(X_test)\n",
    "predictions = [round(value) for value in y_pred]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "accuracy = accuracy_score(y_test, predictions)\n",
    "print(\"Accuracy: %.2f%%\" % (accuracy * 100.0))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### XGBoost - Grid Search for Best Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "parameters = {'max_depth':[4,5,6,7,8,9],\n",
    "              'lerning_rate':[0.01,0.05,0.1,1],\n",
    "              'gamma':[0,1],\n",
    "              'min_child_weight':[1,5,10,50,100]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=5, error_score='raise-deprecating',\n",
       "       estimator=XGBClassifier(base_score=0.5, booster='gbtree', colsample_bylevel=1,\n",
       "       colsample_bytree=0.5, gamma=0, learning_rate=0.1, max_delta_step=0,\n",
       "       max_depth=3, min_child_weight=1, missing=None, n_estimators=90,\n",
       "       n_jobs=1, nthread=None, num_class=8, objective='multi:softprob',\n",
       "       random_state=0, reg_alpha=0, reg_lambda=1, scale_pos_weight=1,\n",
       "       seed=None, silent=True, subsample=1, verbosity=1),\n",
       "       fit_params=None, iid='warn', n_jobs=-1,\n",
       "       param_grid={'max_depth': [4, 5, 6, 7, 8, 9], 'lerning_rate': [0.01, 0.05, 0.1, 1], 'gamma': [0, 1], 'min_child_weight': [1, 5, 10, 50, 100]},\n",
       "       pre_dispatch='2*n_jobs', refit=True, return_train_score='warn',\n",
       "       scoring=None, verbose=0)"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = XGBClassifier(n_estimators=90,colsample_bytree=0.5,verbosity= 1,objective= 'multi:softprob',num_class= 8)\n",
    "grid_search = GridSearchCV(model,param_grid=parameters,cv=5,n_jobs=-1)\n",
    "grid_search.fit(X_test,y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'gamma': 1, 'lerning_rate': 0.01, 'max_depth': 6, 'min_child_weight': 5}"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid_search.best_params_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### XGBoost - Further tuning to reduce overfitting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done   2 out of   5 | elapsed:   39.3s remaining:   59.0s\n",
      "[Parallel(n_jobs=-1)]: Done   5 out of   5 | elapsed:   42.0s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "baseline:  0.36575211096297333\n",
      "cv scores:  [0.56277765 0.553087   0.55168382 0.55199439 0.5567517 ]\n",
      "mean cv scores:  0.5552589087474359\n",
      "std cv scores:  0.004169303314853838\n",
      "-------------------------------\n",
      "accuracy score - train:  0.5669777559469511\n",
      "accuracy score - test:  0.5609345400968218\n",
      "-------------------------------\n",
      "log loss score - train:  1.2362936050901552\n",
      "log loss score - test:  1.2659841369444684\n"
     ]
    }
   ],
   "source": [
    "xgb = XGBClassifier(n_estimators=100,max_depth=6,subsample=0.8,min_child_weight=5,eta=0.02,verbosity= 1,\n",
    "                    colsample_bytree=0.6,objective= 'multi:softprob',num_class= 8,gamma=1,reg_lambda=10,reg_alpha=4)\n",
    "fit_model(xgb)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Extra Trees"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Roy\\Anaconda3\\lib\\site-packages\\sklearn\\ensemble\\forest.py:246: FutureWarning: The default value of n_estimators will change from 10 in version 0.20 to 100 in 0.22.\n",
      "  \"10 in version 0.20 to 100 in 0.22.\", FutureWarning)\n",
      "[Parallel(n_jobs=-1)]: Using backend ThreadingBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done   6 out of  10 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=-1)]: Done  10 out of  10 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done   2 out of   5 | elapsed:    1.1s remaining:    1.6s\n",
      "[Parallel(n_jobs=-1)]: Done   5 out of   5 | elapsed:    4.5s finished\n",
      "[Parallel(n_jobs=8)]: Using backend ThreadingBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=8)]: Done   6 out of  10 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=8)]: Done  10 out of  10 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=8)]: Using backend ThreadingBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=8)]: Done   6 out of  10 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=8)]: Done  10 out of  10 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=8)]: Using backend ThreadingBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=8)]: Done   6 out of  10 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=8)]: Done  10 out of  10 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=8)]: Using backend ThreadingBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=8)]: Done   6 out of  10 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=8)]: Done  10 out of  10 | elapsed:    0.0s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "baseline:  0.36575211096297333\n",
      "cv scores:  [0.45300444 0.4232928  0.45989242 0.45981986 0.45436462]\n",
      "mean cv scores:  0.45007482783889924\n",
      "std cv scores:  0.013679275949059112\n",
      "-------------------------------\n",
      "accuracy score - train:  0.45959347882019974\n",
      "accuracy score - test:  0.45695643022521576\n",
      "-------------------------------\n",
      "log loss score - train:  1.4849716254873744\n",
      "log loss score - test:  1.4982930537380021\n"
     ]
    }
   ],
   "source": [
    "extra_tree = ExtraTreesClassifier(max_depth=8,max_features=3,\n",
    "                                 bootstrap=True,n_jobs=-1,\n",
    "                                 random_state=1,verbose=1)\n",
    "fit_model(extra_tree)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SMOTE \n",
    "- Did not  seem to improve results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([    0, 14053, 14053, 14053, 14053, 14053, 14053, 14053, 14053],\n",
       "      dtype=int64)"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "smt=SMOTE(k_neighbors=5)\n",
    "X2_train,y2_train = smt.fit_sample(X_train,y_train)\n",
    "np.bincount(y2_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=3)]: Using backend LokyBackend with 3 concurrent workers.\n",
      "[Parallel(n_jobs=3)]: Done   5 out of   5 | elapsed:  4.2min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.57598784 0.57476909 0.5753713  0.56614809 0.5711444 ]\n",
      "0.5726841425903546\n"
     ]
    }
   ],
   "source": [
    "model2 = XGBClassifier(n_estimators=100,max_depth=5,eta=0.01,verbosity= 1,colsample_bytree=0.7,objective= 'multi:softprob',num_class= 8,reg_lambda=0,n_jobs=-1)\n",
    "scores = cross_val_score(model2, X_train, y_train, cv=5,n_jobs=3,verbose=1)\n",
    "predictions = cross_val_predict(model2, X_train,y_train,cv=5,n_jobs=3)\n",
    "r2 = metrics.r2_score(y_train, predictions)\n",
    "print(scores)\n",
    "print(scores.mean())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## RFE Attempt\n",
    "- took a while to run and was not able to finish"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-31-11510b189943>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[0mestimator\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mXGBClassifier\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mn_estimators\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m100\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mmax_depth\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m5\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0meta\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m0.01\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mverbosity\u001b[0m\u001b[1;33m=\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mcolsample_bytree\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m0.7\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mobjective\u001b[0m\u001b[1;33m=\u001b[0m \u001b[1;34m'multi:softprob'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mnum_class\u001b[0m\u001b[1;33m=\u001b[0m \u001b[1;36m8\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mreg_lambda\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mn_jobs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[0mselector\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mRFE\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mestimator\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m5\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mstep\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 4\u001b[1;33m \u001b[0mselector\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mselector\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0my\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      5\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      6\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mselector\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msupports_\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\sklearn\\feature_selection\\rfe.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, X, y)\u001b[0m\n\u001b[0;32m    138\u001b[0m             \u001b[0mThe\u001b[0m \u001b[0mtarget\u001b[0m \u001b[0mvalues\u001b[0m\u001b[1;33m.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    139\u001b[0m         \"\"\"\n\u001b[1;32m--> 140\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_fit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    141\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    142\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_fit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mstep_score\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\sklearn\\feature_selection\\rfe.py\u001b[0m in \u001b[0;36m_fit\u001b[1;34m(self, X, y, step_score)\u001b[0m\n\u001b[0;32m    177\u001b[0m                 \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"Fitting estimator with %d features.\"\u001b[0m \u001b[1;33m%\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msum\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msupport_\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    178\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 179\u001b[1;33m             \u001b[0mestimator\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfeatures\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    180\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    181\u001b[0m             \u001b[1;31m# Get coefs\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\xgboost\\sklearn.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, X, y, sample_weight, eval_set, eval_metric, early_stopping_rounds, verbose, xgb_model, sample_weight_eval_set, callbacks)\u001b[0m\n\u001b[0;32m    711\u001b[0m                               \u001b[0mevals_result\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mevals_result\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mobj\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mobj\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfeval\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mfeval\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    712\u001b[0m                               \u001b[0mverbose_eval\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mverbose\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mxgb_model\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mxgb_model\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 713\u001b[1;33m                               callbacks=callbacks)\n\u001b[0m\u001b[0;32m    714\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    715\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mobjective\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mxgb_options\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"objective\"\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\xgboost\\training.py\u001b[0m in \u001b[0;36mtrain\u001b[1;34m(params, dtrain, num_boost_round, evals, obj, feval, maximize, early_stopping_rounds, evals_result, verbose_eval, xgb_model, callbacks, learning_rates)\u001b[0m\n\u001b[0;32m    214\u001b[0m                            \u001b[0mevals\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mevals\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    215\u001b[0m                            \u001b[0mobj\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mobj\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfeval\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mfeval\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 216\u001b[1;33m                            xgb_model=xgb_model, callbacks=callbacks)\n\u001b[0m\u001b[0;32m    217\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    218\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\xgboost\\training.py\u001b[0m in \u001b[0;36m_train_internal\u001b[1;34m(params, dtrain, num_boost_round, evals, obj, feval, xgb_model, callbacks)\u001b[0m\n\u001b[0;32m     72\u001b[0m         \u001b[1;31m# Skip the first update if it is a recovery step.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     73\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mversion\u001b[0m \u001b[1;33m%\u001b[0m \u001b[1;36m2\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 74\u001b[1;33m             \u001b[0mbst\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdtrain\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mi\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mobj\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     75\u001b[0m             \u001b[0mbst\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msave_rabit_checkpoint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     76\u001b[0m             \u001b[0mversion\u001b[0m \u001b[1;33m+=\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\xgboost\\core.py\u001b[0m in \u001b[0;36mupdate\u001b[1;34m(self, dtrain, iteration, fobj)\u001b[0m\n\u001b[0;32m   1108\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mfobj\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1109\u001b[0m             _check_call(_LIB.XGBoosterUpdateOneIter(self.handle, ctypes.c_int(iteration),\n\u001b[1;32m-> 1110\u001b[1;33m                                                     dtrain.handle))\n\u001b[0m\u001b[0;32m   1111\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1112\u001b[0m             \u001b[0mpred\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdtrain\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "from sklearn.feature_selection import RFE\n",
    "estimator = XGBClassifier(n_estimators=100,max_depth=5,eta=0.01,verbosity= 1,colsample_bytree=0.7,objective= 'multi:softprob',num_class= 8,reg_lambda=0,n_jobs=-1)\n",
    "selector = RFE(estimator, 5, step=1)\n",
    "selector = selector.fit(X,y)\n",
    "\n",
    "print(selector.supports_)\n",
    "print(selector.ranking_)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
