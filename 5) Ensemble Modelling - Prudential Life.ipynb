{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Ensemble Modelling - Prudential Life"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Importing Packages and loading into DF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import print_function\n",
    "import timeit\n",
    "\n",
    "from sklearn.model_selection import learning_curve, ShuffleSplit\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import scipy.stats as stats\n",
    "\n",
    "%matplotlib inline\n",
    "\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn import metrics\n",
    "from sklearn.model_selection import train_test_split, cross_val_score, cross_val_predict\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.linear_model import LogisticRegression, LogisticRegressionCV\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.metrics import confusion_matrix, mean_squared_error\n",
    "from sklearn.ensemble import VotingClassifier, RandomForestClassifier, GradientBoostingClassifier\n",
    "import sklearn.ensemble\n",
    "import xgboost as xgb\n",
    "from sklearn.ensemble import ExtraTreesClassifier\n",
    "# from imblearn.over_sampling import SMOTE\n",
    "\n",
    "from sklearn.metrics import log_loss\n",
    "\n",
    "import lime\n",
    "import lime.lime_tabular\n",
    "\n",
    "pd.set_option('display.max_columns',500)\n",
    "pd.set_option('display.max_rows',500)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "ins_data = './dataset/train.csv'\n",
    "ins = pd.read_csv(ins_data)\n",
    "# ins_test_data = './dataset/test.csv'\n",
    "# ins_test = pd.read_csv(ins_test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(59381, 128)\n"
     ]
    }
   ],
   "source": [
    "print(ins.shape)\n",
    "# print(ins_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cleaing Data\n",
    "- Dropping Axis Column\n",
    "- Creating dummy for column Product_Info_2 column\n",
    "- Removing NaN values - where normally distributed, replacing with mean value, where other columns used meadian."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "ins.drop('Id',axis=1,inplace=True)\n",
    "# ins_test.drop('Id',axis=1,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "ins.Product_Info_2.value_counts()\n",
    "prod_2 = {'A1':1,'A2':2,'A3':3,'A4':4,'A5':5,'A6':6,'A7':7,'A8':8,'B1':9,'B2':10,'C1':11,'C2':12,\n",
    "          'C3':13,'C4':14,'D1':15,'D2':16,'D3':17,'D4':18,'E1':19}\n",
    "\n",
    "ins.replace({\"Product_Info_2\": prod_2},inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(2,6):\n",
    "    ins['Family_Hist_%i' % i].fillna(0,inplace=True)\n",
    "#     ins_test['Family_Hist_%i' % i].fillna(0,inplace=True)\n",
    "\n",
    "for i in [1,10,15,24,32]:\n",
    "    ins['Medical_History_%i' % i].fillna(0,inplace=True)\n",
    "#     ins_test['Medical_History_%i' % i].fillna(0,inplace=True)\n",
    "\n",
    "for i in [1,4,6]:\n",
    "    ins['Employment_Info_%i' % i].fillna(0,inplace=True)\n",
    "#     ins_test['Employment_Info_%i' % i].fillna(0,inplace=True)\n",
    "\n",
    "ins['Insurance_History_5'].fillna(0,inplace=True)\n",
    "# ins_test['Insurance_History_5'].fillna(0,inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creating X and y for modelling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Product_Info_1</th>\n",
       "      <th>Product_Info_2</th>\n",
       "      <th>Product_Info_3</th>\n",
       "      <th>Product_Info_4</th>\n",
       "      <th>Product_Info_5</th>\n",
       "      <th>Product_Info_6</th>\n",
       "      <th>Product_Info_7</th>\n",
       "      <th>Ins_Age</th>\n",
       "      <th>Ht</th>\n",
       "      <th>Wt</th>\n",
       "      <th>BMI</th>\n",
       "      <th>Employment_Info_1</th>\n",
       "      <th>Employment_Info_2</th>\n",
       "      <th>Employment_Info_3</th>\n",
       "      <th>Employment_Info_4</th>\n",
       "      <th>Employment_Info_5</th>\n",
       "      <th>Employment_Info_6</th>\n",
       "      <th>InsuredInfo_1</th>\n",
       "      <th>InsuredInfo_2</th>\n",
       "      <th>InsuredInfo_3</th>\n",
       "      <th>InsuredInfo_4</th>\n",
       "      <th>InsuredInfo_5</th>\n",
       "      <th>InsuredInfo_6</th>\n",
       "      <th>InsuredInfo_7</th>\n",
       "      <th>Insurance_History_1</th>\n",
       "      <th>Insurance_History_2</th>\n",
       "      <th>Insurance_History_3</th>\n",
       "      <th>Insurance_History_4</th>\n",
       "      <th>Insurance_History_5</th>\n",
       "      <th>Insurance_History_7</th>\n",
       "      <th>Insurance_History_8</th>\n",
       "      <th>Insurance_History_9</th>\n",
       "      <th>Family_Hist_1</th>\n",
       "      <th>Family_Hist_2</th>\n",
       "      <th>Family_Hist_3</th>\n",
       "      <th>Family_Hist_4</th>\n",
       "      <th>Family_Hist_5</th>\n",
       "      <th>Medical_History_1</th>\n",
       "      <th>Medical_History_2</th>\n",
       "      <th>Medical_History_3</th>\n",
       "      <th>Medical_History_4</th>\n",
       "      <th>Medical_History_5</th>\n",
       "      <th>Medical_History_6</th>\n",
       "      <th>Medical_History_7</th>\n",
       "      <th>Medical_History_8</th>\n",
       "      <th>Medical_History_9</th>\n",
       "      <th>Medical_History_10</th>\n",
       "      <th>Medical_History_11</th>\n",
       "      <th>Medical_History_12</th>\n",
       "      <th>Medical_History_13</th>\n",
       "      <th>Medical_History_14</th>\n",
       "      <th>Medical_History_15</th>\n",
       "      <th>Medical_History_16</th>\n",
       "      <th>Medical_History_17</th>\n",
       "      <th>Medical_History_18</th>\n",
       "      <th>Medical_History_19</th>\n",
       "      <th>Medical_History_20</th>\n",
       "      <th>Medical_History_21</th>\n",
       "      <th>Medical_History_22</th>\n",
       "      <th>Medical_History_23</th>\n",
       "      <th>Medical_History_24</th>\n",
       "      <th>Medical_History_25</th>\n",
       "      <th>Medical_History_26</th>\n",
       "      <th>Medical_History_27</th>\n",
       "      <th>Medical_History_28</th>\n",
       "      <th>Medical_History_29</th>\n",
       "      <th>Medical_History_30</th>\n",
       "      <th>Medical_History_31</th>\n",
       "      <th>Medical_History_32</th>\n",
       "      <th>Medical_History_33</th>\n",
       "      <th>Medical_History_34</th>\n",
       "      <th>Medical_History_35</th>\n",
       "      <th>Medical_History_36</th>\n",
       "      <th>Medical_History_37</th>\n",
       "      <th>Medical_History_38</th>\n",
       "      <th>Medical_History_39</th>\n",
       "      <th>Medical_History_40</th>\n",
       "      <th>Medical_History_41</th>\n",
       "      <th>Medical_Keyword_1</th>\n",
       "      <th>Medical_Keyword_2</th>\n",
       "      <th>Medical_Keyword_3</th>\n",
       "      <th>Medical_Keyword_4</th>\n",
       "      <th>Medical_Keyword_5</th>\n",
       "      <th>Medical_Keyword_6</th>\n",
       "      <th>Medical_Keyword_7</th>\n",
       "      <th>Medical_Keyword_8</th>\n",
       "      <th>Medical_Keyword_9</th>\n",
       "      <th>Medical_Keyword_10</th>\n",
       "      <th>Medical_Keyword_11</th>\n",
       "      <th>Medical_Keyword_12</th>\n",
       "      <th>Medical_Keyword_13</th>\n",
       "      <th>Medical_Keyword_14</th>\n",
       "      <th>Medical_Keyword_15</th>\n",
       "      <th>Medical_Keyword_16</th>\n",
       "      <th>Medical_Keyword_17</th>\n",
       "      <th>Medical_Keyword_18</th>\n",
       "      <th>Medical_Keyword_19</th>\n",
       "      <th>Medical_Keyword_20</th>\n",
       "      <th>Medical_Keyword_21</th>\n",
       "      <th>Medical_Keyword_22</th>\n",
       "      <th>Medical_Keyword_23</th>\n",
       "      <th>Medical_Keyword_24</th>\n",
       "      <th>Medical_Keyword_25</th>\n",
       "      <th>Medical_Keyword_26</th>\n",
       "      <th>Medical_Keyword_27</th>\n",
       "      <th>Medical_Keyword_28</th>\n",
       "      <th>Medical_Keyword_29</th>\n",
       "      <th>Medical_Keyword_30</th>\n",
       "      <th>Medical_Keyword_31</th>\n",
       "      <th>Medical_Keyword_32</th>\n",
       "      <th>Medical_Keyword_33</th>\n",
       "      <th>Medical_Keyword_34</th>\n",
       "      <th>Medical_Keyword_35</th>\n",
       "      <th>Medical_Keyword_36</th>\n",
       "      <th>Medical_Keyword_37</th>\n",
       "      <th>Medical_Keyword_38</th>\n",
       "      <th>Medical_Keyword_39</th>\n",
       "      <th>Medical_Keyword_40</th>\n",
       "      <th>Medical_Keyword_41</th>\n",
       "      <th>Medical_Keyword_42</th>\n",
       "      <th>Medical_Keyword_43</th>\n",
       "      <th>Medical_Keyword_44</th>\n",
       "      <th>Medical_Keyword_45</th>\n",
       "      <th>Medical_Keyword_46</th>\n",
       "      <th>Medical_Keyword_47</th>\n",
       "      <th>Medical_Keyword_48</th>\n",
       "      <th>Response</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>17</td>\n",
       "      <td>10</td>\n",
       "      <td>0.076923</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.641791</td>\n",
       "      <td>0.581818</td>\n",
       "      <td>0.148536</td>\n",
       "      <td>0.323008</td>\n",
       "      <td>0.028</td>\n",
       "      <td>12</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>6</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0.000667</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.598039</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.526786</td>\n",
       "      <td>4.0</td>\n",
       "      <td>112</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>240.0</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>26</td>\n",
       "      <td>0.076923</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0.059701</td>\n",
       "      <td>0.600000</td>\n",
       "      <td>0.131799</td>\n",
       "      <td>0.272288</td>\n",
       "      <td>0.000</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2</td>\n",
       "      <td>0.0018</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>6</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0.000133</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0.188406</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.084507</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>5.0</td>\n",
       "      <td>412</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>19</td>\n",
       "      <td>26</td>\n",
       "      <td>0.076923</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0.029851</td>\n",
       "      <td>0.745455</td>\n",
       "      <td>0.288703</td>\n",
       "      <td>0.428780</td>\n",
       "      <td>0.030</td>\n",
       "      <td>9</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2</td>\n",
       "      <td>0.0300</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>8</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>0.304348</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.225352</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>10.0</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>18</td>\n",
       "      <td>10</td>\n",
       "      <td>0.487179</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0.164179</td>\n",
       "      <td>0.672727</td>\n",
       "      <td>0.205021</td>\n",
       "      <td>0.352438</td>\n",
       "      <td>0.042</td>\n",
       "      <td>9</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3</td>\n",
       "      <td>0.2000</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>8</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>0.420290</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.352113</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>350</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>16</td>\n",
       "      <td>26</td>\n",
       "      <td>0.230769</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0.417910</td>\n",
       "      <td>0.654545</td>\n",
       "      <td>0.234310</td>\n",
       "      <td>0.424046</td>\n",
       "      <td>0.027</td>\n",
       "      <td>9</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2</td>\n",
       "      <td>0.0500</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>6</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>0.463768</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.408451</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>162</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Product_Info_1  Product_Info_2  Product_Info_3  Product_Info_4  \\\n",
       "0               1              17              10        0.076923   \n",
       "1               1               1              26        0.076923   \n",
       "2               1              19              26        0.076923   \n",
       "3               1              18              10        0.487179   \n",
       "4               1              16              26        0.230769   \n",
       "\n",
       "   Product_Info_5  Product_Info_6  Product_Info_7   Ins_Age        Ht  \\\n",
       "0               2               1               1  0.641791  0.581818   \n",
       "1               2               3               1  0.059701  0.600000   \n",
       "2               2               3               1  0.029851  0.745455   \n",
       "3               2               3               1  0.164179  0.672727   \n",
       "4               2               3               1  0.417910  0.654545   \n",
       "\n",
       "         Wt       BMI  Employment_Info_1  Employment_Info_2  \\\n",
       "0  0.148536  0.323008              0.028                 12   \n",
       "1  0.131799  0.272288              0.000                  1   \n",
       "2  0.288703  0.428780              0.030                  9   \n",
       "3  0.205021  0.352438              0.042                  9   \n",
       "4  0.234310  0.424046              0.027                  9   \n",
       "\n",
       "   Employment_Info_3  Employment_Info_4  Employment_Info_5  Employment_Info_6  \\\n",
       "0                  1                0.0                  3             0.0000   \n",
       "1                  3                0.0                  2             0.0018   \n",
       "2                  1                0.0                  2             0.0300   \n",
       "3                  1                0.0                  3             0.2000   \n",
       "4                  1                0.0                  2             0.0500   \n",
       "\n",
       "   InsuredInfo_1  InsuredInfo_2  InsuredInfo_3  InsuredInfo_4  InsuredInfo_5  \\\n",
       "0              1              2              6              3              1   \n",
       "1              1              2              6              3              1   \n",
       "2              1              2              8              3              1   \n",
       "3              2              2              8              3              1   \n",
       "4              1              2              6              3              1   \n",
       "\n",
       "   InsuredInfo_6  InsuredInfo_7  Insurance_History_1  Insurance_History_2  \\\n",
       "0              2              1                    1                    1   \n",
       "1              2              1                    2                    1   \n",
       "2              1              1                    2                    1   \n",
       "3              2              1                    2                    1   \n",
       "4              2              1                    2                    1   \n",
       "\n",
       "   Insurance_History_3  Insurance_History_4  Insurance_History_5  \\\n",
       "0                    3                    1             0.000667   \n",
       "1                    3                    1             0.000133   \n",
       "2                    1                    3             0.000000   \n",
       "3                    1                    3             0.000000   \n",
       "4                    1                    3             0.000000   \n",
       "\n",
       "   Insurance_History_7  Insurance_History_8  Insurance_History_9  \\\n",
       "0                    1                    1                    2   \n",
       "1                    1                    3                    2   \n",
       "2                    3                    2                    3   \n",
       "3                    3                    2                    3   \n",
       "4                    3                    2                    3   \n",
       "\n",
       "   Family_Hist_1  Family_Hist_2  Family_Hist_3  Family_Hist_4  Family_Hist_5  \\\n",
       "0              2       0.000000       0.598039       0.000000       0.526786   \n",
       "1              2       0.188406       0.000000       0.084507       0.000000   \n",
       "2              3       0.304348       0.000000       0.225352       0.000000   \n",
       "3              3       0.420290       0.000000       0.352113       0.000000   \n",
       "4              2       0.463768       0.000000       0.408451       0.000000   \n",
       "\n",
       "   Medical_History_1  Medical_History_2  Medical_History_3  Medical_History_4  \\\n",
       "0                4.0                112                  2                  1   \n",
       "1                5.0                412                  2                  1   \n",
       "2               10.0                  3                  2                  2   \n",
       "3                0.0                350                  2                  2   \n",
       "4                0.0                162                  2                  2   \n",
       "\n",
       "   Medical_History_5  Medical_History_6  Medical_History_7  Medical_History_8  \\\n",
       "0                  1                  3                  2                  2   \n",
       "1                  1                  3                  2                  2   \n",
       "2                  1                  3                  2                  2   \n",
       "3                  1                  3                  2                  2   \n",
       "4                  1                  3                  2                  2   \n",
       "\n",
       "   Medical_History_9  Medical_History_10  Medical_History_11  \\\n",
       "0                  1                 0.0                   3   \n",
       "1                  1                 0.0                   3   \n",
       "2                  2                 0.0                   3   \n",
       "3                  2                 0.0                   3   \n",
       "4                  2                 0.0                   3   \n",
       "\n",
       "   Medical_History_12  Medical_History_13  Medical_History_14  \\\n",
       "0                   2                   3                   3   \n",
       "1                   2                   3                   3   \n",
       "2                   2                   3                   3   \n",
       "3                   2                   3                   3   \n",
       "4                   2                   3                   3   \n",
       "\n",
       "   Medical_History_15  Medical_History_16  Medical_History_17  \\\n",
       "0               240.0                   3                   3   \n",
       "1                 0.0                   1                   3   \n",
       "2                 0.0                   1                   3   \n",
       "3                 0.0                   1                   3   \n",
       "4                 0.0                   1                   3   \n",
       "\n",
       "   Medical_History_18  Medical_History_19  Medical_History_20  \\\n",
       "0                   1                   1                   2   \n",
       "1                   1                   1                   2   \n",
       "2                   1                   1                   2   \n",
       "3                   1                   1                   2   \n",
       "4                   1                   1                   2   \n",
       "\n",
       "   Medical_History_21  Medical_History_22  Medical_History_23  \\\n",
       "0                   1                   2                   3   \n",
       "1                   1                   2                   3   \n",
       "2                   1                   2                   3   \n",
       "3                   2                   2                   3   \n",
       "4                   1                   2                   3   \n",
       "\n",
       "   Medical_History_24  Medical_History_25  Medical_History_26  \\\n",
       "0                 0.0                   1                   3   \n",
       "1                 0.0                   1                   3   \n",
       "2                 0.0                   2                   2   \n",
       "3                 0.0                   1                   3   \n",
       "4                 0.0                   2                   2   \n",
       "\n",
       "   Medical_History_27  Medical_History_28  Medical_History_29  \\\n",
       "0                   3                   1                   3   \n",
       "1                   3                   1                   3   \n",
       "2                   3                   1                   3   \n",
       "3                   3                   1                   3   \n",
       "4                   3                   1                   3   \n",
       "\n",
       "   Medical_History_30  Medical_History_31  Medical_History_32  \\\n",
       "0                   2                   3                 0.0   \n",
       "1                   2                   3                 0.0   \n",
       "2                   2                   3                 0.0   \n",
       "3                   2                   3                 0.0   \n",
       "4                   2                   3                 0.0   \n",
       "\n",
       "   Medical_History_33  Medical_History_34  Medical_History_35  \\\n",
       "0                   1                   3                   1   \n",
       "1                   3                   1                   1   \n",
       "2                   3                   3                   1   \n",
       "3                   3                   3                   1   \n",
       "4                   3                   3                   1   \n",
       "\n",
       "   Medical_History_36  Medical_History_37  Medical_History_38  \\\n",
       "0                   2                   2                   1   \n",
       "1                   2                   2                   1   \n",
       "2                   3                   2                   1   \n",
       "3                   2                   2                   1   \n",
       "4                   3                   2                   1   \n",
       "\n",
       "   Medical_History_39  Medical_History_40  Medical_History_41  \\\n",
       "0                   3                   3                   3   \n",
       "1                   3                   3                   1   \n",
       "2                   3                   3                   1   \n",
       "3                   3                   3                   1   \n",
       "4                   3                   3                   1   \n",
       "\n",
       "   Medical_Keyword_1  Medical_Keyword_2  Medical_Keyword_3  Medical_Keyword_4  \\\n",
       "0                  0                  0                  0                  0   \n",
       "1                  0                  0                  0                  0   \n",
       "2                  0                  0                  0                  0   \n",
       "3                  0                  0                  0                  0   \n",
       "4                  0                  0                  0                  0   \n",
       "\n",
       "   Medical_Keyword_5  Medical_Keyword_6  Medical_Keyword_7  Medical_Keyword_8  \\\n",
       "0                  0                  0                  0                  0   \n",
       "1                  0                  0                  0                  0   \n",
       "2                  0                  0                  0                  0   \n",
       "3                  0                  0                  0                  0   \n",
       "4                  0                  0                  0                  0   \n",
       "\n",
       "   Medical_Keyword_9  Medical_Keyword_10  Medical_Keyword_11  \\\n",
       "0                  0                   0                   0   \n",
       "1                  0                   0                   0   \n",
       "2                  0                   0                   0   \n",
       "3                  0                   0                   0   \n",
       "4                  0                   0                   0   \n",
       "\n",
       "   Medical_Keyword_12  Medical_Keyword_13  Medical_Keyword_14  \\\n",
       "0                   0                   0                   0   \n",
       "1                   0                   0                   0   \n",
       "2                   0                   0                   0   \n",
       "3                   0                   0                   0   \n",
       "4                   0                   0                   0   \n",
       "\n",
       "   Medical_Keyword_15  Medical_Keyword_16  Medical_Keyword_17  \\\n",
       "0                   0                   0                   0   \n",
       "1                   0                   0                   0   \n",
       "2                   0                   0                   0   \n",
       "3                   0                   0                   0   \n",
       "4                   0                   0                   0   \n",
       "\n",
       "   Medical_Keyword_18  Medical_Keyword_19  Medical_Keyword_20  \\\n",
       "0                   0                   0                   0   \n",
       "1                   0                   0                   0   \n",
       "2                   0                   0                   0   \n",
       "3                   0                   0                   0   \n",
       "4                   0                   0                   0   \n",
       "\n",
       "   Medical_Keyword_21  Medical_Keyword_22  Medical_Keyword_23  \\\n",
       "0                   0                   0                   0   \n",
       "1                   0                   0                   0   \n",
       "2                   0                   0                   0   \n",
       "3                   0                   0                   0   \n",
       "4                   0                   0                   0   \n",
       "\n",
       "   Medical_Keyword_24  Medical_Keyword_25  Medical_Keyword_26  \\\n",
       "0                   0                   0                   0   \n",
       "1                   0                   0                   0   \n",
       "2                   0                   0                   0   \n",
       "3                   0                   0                   0   \n",
       "4                   0                   0                   0   \n",
       "\n",
       "   Medical_Keyword_27  Medical_Keyword_28  Medical_Keyword_29  \\\n",
       "0                   0                   0                   0   \n",
       "1                   0                   0                   0   \n",
       "2                   0                   0                   0   \n",
       "3                   0                   0                   0   \n",
       "4                   0                   0                   0   \n",
       "\n",
       "   Medical_Keyword_30  Medical_Keyword_31  Medical_Keyword_32  \\\n",
       "0                   0                   0                   0   \n",
       "1                   0                   0                   0   \n",
       "2                   0                   0                   0   \n",
       "3                   0                   0                   1   \n",
       "4                   0                   0                   0   \n",
       "\n",
       "   Medical_Keyword_33  Medical_Keyword_34  Medical_Keyword_35  \\\n",
       "0                   0                   0                   0   \n",
       "1                   0                   0                   0   \n",
       "2                   0                   0                   0   \n",
       "3                   0                   0                   0   \n",
       "4                   0                   0                   0   \n",
       "\n",
       "   Medical_Keyword_36  Medical_Keyword_37  Medical_Keyword_38  \\\n",
       "0                   0                   0                   0   \n",
       "1                   0                   0                   0   \n",
       "2                   0                   0                   0   \n",
       "3                   0                   0                   0   \n",
       "4                   0                   0                   0   \n",
       "\n",
       "   Medical_Keyword_39  Medical_Keyword_40  Medical_Keyword_41  \\\n",
       "0                   0                   0                   0   \n",
       "1                   0                   0                   0   \n",
       "2                   0                   0                   0   \n",
       "3                   0                   0                   0   \n",
       "4                   0                   0                   0   \n",
       "\n",
       "   Medical_Keyword_42  Medical_Keyword_43  Medical_Keyword_44  \\\n",
       "0                   0                   0                   0   \n",
       "1                   0                   0                   0   \n",
       "2                   0                   0                   0   \n",
       "3                   0                   0                   0   \n",
       "4                   0                   0                   0   \n",
       "\n",
       "   Medical_Keyword_45  Medical_Keyword_46  Medical_Keyword_47  \\\n",
       "0                   0                   0                   0   \n",
       "1                   0                   0                   0   \n",
       "2                   0                   0                   0   \n",
       "3                   0                   0                   0   \n",
       "4                   0                   0                   0   \n",
       "\n",
       "   Medical_Keyword_48  Response  \n",
       "0                   0         8  \n",
       "1                   0         4  \n",
       "2                   0         8  \n",
       "3                   0         8  \n",
       "4                   0         8  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ins.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#converting number to reduce size\n",
    "for i in ins.columns:\n",
    "    if str(ins[i].dtypes) == 'int64':\n",
    "        ins[i] = ins[i].astype('int8')\n",
    "    else:\n",
    "        ins[i] = ins[i].astype('float16')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "features = ins.drop(['Response','Ht','Wt'],axis=1)\n",
    "targets = ins.Response\n",
    "targets = targets.map(lambda x: x-1)\n",
    "X, X_holdout, y, y_holdout = train_test_split(features,targets, train_size = 0.8,test_size=0.2,random_state=77)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X,y, train_size = 0.9,test_size=0.1,random_state=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "int_col_num= []\n",
    "int_col_name= []\n",
    "flt_col_name = []\n",
    "for i in range(0,len(X_train.columns)):\n",
    "    if str(X_train.dtypes[i]) == 'int64':\n",
    "        int_col_num.append(int(i))\n",
    "        int_col_name.append(X_train.columns[i])\n",
    "    else:\n",
    "        flt_col_name.append(X_train.columns[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(42753, 124)\n"
     ]
    }
   ],
   "source": [
    "print(X_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "#trying out log transformation on the below 3 columns. This appeared to have minimal impact overall however.\n",
    "i=1\n",
    "\n",
    "for n in ['BMI', 'Employment_Info_1','Medical_History_1']:\n",
    "    ins[n] = ins[n].apply(lambda x: np.log(x) if x !=0 else x)\n",
    "    plt.figure(i)\n",
    "    sns.distplot(ins[n])\n",
    "    i += 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Determining Baseline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "7    14028\n",
       "5     8069\n",
       "6     5821\n",
       "1     4714\n",
       "0     4489\n",
       "4     3906\n",
       "3     1003\n",
       "2      723\n",
       "Name: Response, dtype: int64"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.36575211096297333\n"
     ]
    }
   ],
   "source": [
    "baseline=15637/len(y_train)\n",
    "print(baseline)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr = LogisticRegression(multi_class='auto', solver = 'liblinear')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done   2 out of   5 | elapsed:  1.5min remaining:  2.2min\n",
      "[Parallel(n_jobs=-1)]: Done   5 out of   5 | elapsed:  1.7min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.49532383 0.49304338 0.49690095 0.49666628 0.49052188]\n",
      "0.494491261460248\n"
     ]
    }
   ],
   "source": [
    "scores = cross_val_score(lr, X_train, y_train, cv=5,n_jobs=-1,verbose=1)\n",
    "predictions = cross_val_predict(lr, X_train,y_train,cv=5,n_jobs=3)\n",
    "r2 = metrics.r2_score(y_train, predictions)\n",
    "print(scores)\n",
    "print(scores.mean())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "CV Results - (multi_class='auto', solver = 'liblinear')\n",
    "\n",
    "[0.49590835 0.49397872 0.49923985 0.49584747 0.49075591]\n",
    "0.4951460599227767"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "scores=cross_val_score(lr,X_train,y_train,cv=5,n_jobs=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "baseline:  0.36575211096297333\n",
      "-------------------------------\n",
      "accuracy score - train:  0.494491261460248\n",
      "accuracy score - test:  0.4980004209640076\n",
      "-------------------------------\n",
      "log loss score - train:  1.366988536571226\n",
      "log loss score - test:  1.384657443589925\n"
     ]
    }
   ],
   "source": [
    "accuracy_score_train = scores.mean()\n",
    "lr.fit(X_train,y_train)\n",
    "accuracy_score_test = lr.score(X_test,y_test)\n",
    "\n",
    "y_pred = lr.predict_proba(X_test)\n",
    "log_loss_test = log_loss(y_test,y_pred)\n",
    "\n",
    "y_pred = lr.predict_proba(X_train)\n",
    "log_loss_train = log_loss(y_train,y_pred)\n",
    "\n",
    "print('baseline: ',baseline)\n",
    "print('-------------------------------')\n",
    "print(\"accuracy score - train: \",accuracy_score_train)\n",
    "print(\"accuracy score - test: \",accuracy_score_test)\n",
    "print('-------------------------------')\n",
    "print(\"log loss score - train: \",log_loss_train)\n",
    "print(\"log loss score - test: \",log_loss_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "7    0.328702\n",
       "5    0.189624\n",
       "6    0.136318\n",
       "1    0.110144\n",
       "0    0.102823\n",
       "4    0.091081\n",
       "3    0.024536\n",
       "2    0.016771\n",
       "Name: Response, dtype: float64"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train.value_counts(normalize=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Logistic Regression - Ridge"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr_lasso = LogisticRegressionCV(penalty='l2', Cs=200, cv=5, solver='liblinear',multi_class='auto',n_jobs=3)\n",
    "lr_lasso.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracy_score_train = lr_ridge.score(X_train,y_train)\n",
    "accuracy_score_test = lr_ridge.score(X_test,y_test)\n",
    "\n",
    "y_pred = lr_ridge.predict_proba(X_test)\n",
    "log_loss_test = log_loss(y_test,y_pred)\n",
    "\n",
    "y_pred = lr_ridge.predict_proba(X_train)\n",
    "log_loss_train = log_loss(y_train,y_pred)\n",
    "\n",
    "print('baseline: ',baseline)\n",
    "print('-------------------------------')\n",
    "print(\"accuracy score - train: \",accuracy_score_train)\n",
    "print(\"accuracy score - test: \",accuracy_score_test)\n",
    "print('-------------------------------')\n",
    "print(\"log loss score - train: \",log_loss_train)\n",
    "print(\"log loss score - test: \",log_loss_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Logistic Regression - Lasso"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr_lasso = LogisticRegressionCV(penalty='l1', solver='liblinear', Cs=200, cv=10)\n",
    "lr_lasso.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracy_score_train = lr_lasso.score(X_train,y_train)\n",
    "accuracy_score_test = lr_lasso.score(X_test,y_test)\n",
    "\n",
    "y_pred = lr_lasso.predict_proba(X_test)\n",
    "log_loss_test = log_loss(y_test,y_pred)\n",
    "\n",
    "y_pred = lr_lasso.predict_proba(X_train)\n",
    "log_loss_train = log_loss(y_train,y_pred)\n",
    "\n",
    "print('baseline: ',baseline)\n",
    "print('-------------------------------')\n",
    "print(\"accuracy score - train: \",accuracy_score_train)\n",
    "print(\"accuracy score - test: \",accuracy_score_test)\n",
    "print('-------------------------------')\n",
    "print(\"log loss score - train: \",log_loss_train)\n",
    "print(\"log loss score - test: \",log_loss_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "parameters = {'C':[0.001,0.25,0.5,0.75,1,10],\n",
    "              'kernel':['linear','rbf'],\n",
    "              'gamma':['scale',0.001,0.01,0.1,1,2,3],\n",
    "              'decision_function_shape':['ovo','ovr']}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "svm = SVC(probability=True,random_state=42)\n",
    "grid_search = GridSearchCV(svm,param_grid=parameters,cv=3,n_jobs=3)\n",
    "grid_search.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grid_search.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "svm = SVC(C=1, kernel='rbf', gamma='scale',decision_function_shape='ovr',probability=True,random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done   2 out of   5 | elapsed: 64.1min remaining: 96.1min\n",
      "[Parallel(n_jobs=-1)]: Done   5 out of   5 | elapsed: 64.3min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.36029928 0.36244593 0.3573851  0.35466136 0.35490288]\n",
      "0.35793890883976404\n"
     ]
    }
   ],
   "source": [
    "scores = cross_val_score(svm, X_train, y_train, cv=5,n_jobs=-1,verbose=1)\n",
    "predictions = cross_val_predict(svm, X_train,y_train,cv=5,n_jobs=3)\n",
    "r2 = metrics.r2_score(y_train, predictions)\n",
    "print(scores)\n",
    "print(scores.mean())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "CV Scores - (cv=5,n_jobs=-1,verbose=1)\n",
    "\n",
    "[0.36029928 0.36244593 0.3573851  0.35466136 0.35490288]\n",
    "0.35793890883976404"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "svm.fit(X_train,y_train)\n",
    "accuracy_score_train = grid_search.best_score_\n",
    "\n",
    "accuracy_score_test = grid_search.score(X_test,y_test)\n",
    "\n",
    "y_pred = grid_search.predict_proba(X_test)\n",
    "log_loss_test = log_loss(y_test,y_pred)\n",
    "\n",
    "y_pred = grid_search.predict_proba(X_train)\n",
    "log_loss_train = log_loss(y_train,y_pred)\n",
    "\n",
    "print('baseline: ',baseline)\n",
    "print('-------------------------------')\n",
    "print(\"accuracy score - train: \",accuracy_score_train)\n",
    "print(\"accuracy score - test: \",accuracy_score_test)\n",
    "print('-------------------------------')\n",
    "print(\"log loss score - train: \",log_loss_train)\n",
    "print(\"log loss score - test: \",log_loss_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Test 1\n",
    "- C=0.001, kernel='rbf', gamma='scale',decision_function_shape='ovr',probability=True,random_state=42"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "forest = RandomForestClassifier(max_depth=5,max_leaf_nodes=30,verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=3)]: Using backend LokyBackend with 3 concurrent workers.\n",
      "[Parallel(n_jobs=3)]: Done   5 out of   5 | elapsed:    5.1s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.44821136 0.45703262 0.41831365 0.43829688 0.46173648]\n",
      "0.4447181984995579\n"
     ]
    }
   ],
   "source": [
    "scores = cross_val_score(forest, X_train, y_train, cv=5,n_jobs=3,verbose=1)\n",
    "predictions = cross_val_predict(forest, X_train,y_train,cv=5,n_jobs=3)\n",
    "r2 = metrics.r2_score(y_train, predictions)\n",
    "print(scores)\n",
    "print(scores.mean())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "CV Results (max_depth=5,max_leaf_nodes=30,class_weight='balanced',verbose=1)\n",
    "\n",
    "[0.42646715 0.41190226 0.42673372 0.40905369 0.41048444]\n",
    "0.4169282498796433\n",
    "\n",
    "CV Results (max_depth=5,max_leaf_nodes=30,verbose=1)\n",
    "\n",
    "[0.44201543 0.44557465 0.46099871 0.43853082 0.4678212 ]\n",
    "0.4509881644734108"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Roy\\Anaconda3\\lib\\site-packages\\sklearn\\ensemble\\forest.py:246: FutureWarning: The default value of n_estimators will change from 10 in version 0.20 to 100 in 0.22.\n",
      "  \"10 in version 0.20 to 100 in 0.22.\", FutureWarning)\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done  10 out of  10 | elapsed:    0.2s finished\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
       "            max_depth=5, max_features='auto', max_leaf_nodes=30,\n",
       "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "            min_samples_leaf=1, min_samples_split=2,\n",
       "            min_weight_fraction_leaf=0.0, n_estimators=10, n_jobs=None,\n",
       "            oob_score=False, random_state=None, verbose=1,\n",
       "            warm_start=False)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "forest.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done  10 out of  10 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done  10 out of  10 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done  10 out of  10 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done  10 out of  10 | elapsed:    0.0s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "baseline:  0.36575211096297333\n",
      "-------------------------------\n",
      "accuracy score - train:  0.46139452202184644\n",
      "accuracy score - test:  0.46095558829720057\n",
      "-------------------------------\n",
      "log loss score - train:  1.4964091323898545\n",
      "log loss score - test:  1.4962416907564446\n"
     ]
    }
   ],
   "source": [
    "accuracy_score_train = forest.score(X_train,y_train)\n",
    "\n",
    "accuracy_score_test = forest.score(X_test,y_test)\n",
    "\n",
    "y_pred = forest.predict_proba(X_test)\n",
    "log_loss_test = log_loss(y_test,y_pred)\n",
    "\n",
    "y_pred = forest.predict_proba(X_train)\n",
    "log_loss_train = log_loss(y_train,y_pred)\n",
    "\n",
    "print('baseline: ',baseline)\n",
    "print('-------------------------------')\n",
    "print(\"accuracy score - train: \",accuracy_score_train)\n",
    "print(\"accuracy score - test: \",accuracy_score_test)\n",
    "print('-------------------------------')\n",
    "print(\"log loss score - train: \",log_loss_train)\n",
    "print(\"log loss score - test: \",log_loss_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "forest_features = pd.DataFrame()\n",
    "forest_features['feature'] = X.columns\n",
    "forest_features['importance'] = forest.feature_importances_\n",
    "forest_features.sort_values('importance',ascending=False).head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## XGBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0]\tvalidation_0-merror:0.446425\tvalidation_0-mlogloss:1.96987\tvalidation_1-merror:0.443486\tvalidation_1-mlogloss:1.97088\n",
      "[1]\tvalidation_0-merror:0.44432\tvalidation_0-mlogloss:1.88228\tvalidation_1-merror:0.441591\tvalidation_1-mlogloss:1.88458\n",
      "[2]\tvalidation_0-merror:0.442144\tvalidation_0-mlogloss:1.81038\tvalidation_1-merror:0.441591\tvalidation_1-mlogloss:1.81396\n",
      "[3]\tvalidation_0-merror:0.443688\tvalidation_0-mlogloss:1.74866\tvalidation_1-merror:0.441381\tvalidation_1-mlogloss:1.75383\n",
      "[4]\tvalidation_0-merror:0.442144\tvalidation_0-mlogloss:1.69555\tvalidation_1-merror:0.445169\tvalidation_1-mlogloss:1.70229\n",
      "[5]\tvalidation_0-merror:0.440952\tvalidation_0-mlogloss:1.6491\tvalidation_1-merror:0.446853\tvalidation_1-mlogloss:1.65723\n",
      "[6]\tvalidation_0-merror:0.439478\tvalidation_0-mlogloss:1.60783\tvalidation_1-merror:0.44538\tvalidation_1-mlogloss:1.61735\n",
      "[7]\tvalidation_0-merror:0.437466\tvalidation_0-mlogloss:1.57151\tvalidation_1-merror:0.445169\tvalidation_1-mlogloss:1.58271\n",
      "[8]\tvalidation_0-merror:0.435619\tvalidation_0-mlogloss:1.53902\tvalidation_1-merror:0.444328\tvalidation_1-mlogloss:1.55161\n",
      "[9]\tvalidation_0-merror:0.434192\tvalidation_0-mlogloss:1.5098\tvalidation_1-merror:0.443275\tvalidation_1-mlogloss:1.52384\n",
      "[10]\tvalidation_0-merror:0.434355\tvalidation_0-mlogloss:1.48337\tvalidation_1-merror:0.442644\tvalidation_1-mlogloss:1.49875\n",
      "[11]\tvalidation_0-merror:0.432929\tvalidation_0-mlogloss:1.45962\tvalidation_1-merror:0.443065\tvalidation_1-mlogloss:1.47676\n",
      "[12]\tvalidation_0-merror:0.431315\tvalidation_0-mlogloss:1.4381\tvalidation_1-merror:0.440328\tvalidation_1-mlogloss:1.4568\n",
      "[13]\tvalidation_0-merror:0.430262\tvalidation_0-mlogloss:1.41859\tvalidation_1-merror:0.439907\tvalidation_1-mlogloss:1.43894\n",
      "[14]\tvalidation_0-merror:0.428812\tvalidation_0-mlogloss:1.40047\tvalidation_1-merror:0.438644\tvalidation_1-mlogloss:1.42235\n",
      "[15]\tvalidation_0-merror:0.428251\tvalidation_0-mlogloss:1.38396\tvalidation_1-merror:0.43654\tvalidation_1-mlogloss:1.40718\n",
      "[16]\tvalidation_0-merror:0.427268\tvalidation_0-mlogloss:1.36848\tvalidation_1-merror:0.43675\tvalidation_1-mlogloss:1.39338\n",
      "[17]\tvalidation_0-merror:0.427105\tvalidation_0-mlogloss:1.35446\tvalidation_1-merror:0.435698\tvalidation_1-mlogloss:1.38063\n",
      "[18]\tvalidation_0-merror:0.425912\tvalidation_0-mlogloss:1.34141\tvalidation_1-merror:0.436119\tvalidation_1-mlogloss:1.36904\n",
      "[19]\tvalidation_0-merror:0.424508\tvalidation_0-mlogloss:1.32916\tvalidation_1-merror:0.434224\tvalidation_1-mlogloss:1.3583\n",
      "[20]\tvalidation_0-merror:0.423713\tvalidation_0-mlogloss:1.31767\tvalidation_1-merror:0.433382\tvalidation_1-mlogloss:1.34846\n",
      "[21]\tvalidation_0-merror:0.423011\tvalidation_0-mlogloss:1.30664\tvalidation_1-merror:0.432961\tvalidation_1-mlogloss:1.33864\n",
      "[22]\tvalidation_0-merror:0.422122\tvalidation_0-mlogloss:1.29658\tvalidation_1-merror:0.432541\tvalidation_1-mlogloss:1.33018\n",
      "[23]\tvalidation_0-merror:0.421842\tvalidation_0-mlogloss:1.28773\tvalidation_1-merror:0.43212\tvalidation_1-mlogloss:1.32294\n",
      "[24]\tvalidation_0-merror:0.420742\tvalidation_0-mlogloss:1.27918\tvalidation_1-merror:0.431909\tvalidation_1-mlogloss:1.31589\n",
      "[25]\tvalidation_0-merror:0.419807\tvalidation_0-mlogloss:1.27135\tvalidation_1-merror:0.430857\tvalidation_1-mlogloss:1.30942\n",
      "[26]\tvalidation_0-merror:0.418871\tvalidation_0-mlogloss:1.26393\tvalidation_1-merror:0.431067\tvalidation_1-mlogloss:1.30344\n",
      "[27]\tvalidation_0-merror:0.41831\tvalidation_0-mlogloss:1.25689\tvalidation_1-merror:0.431278\tvalidation_1-mlogloss:1.29795\n",
      "[28]\tvalidation_0-merror:0.417444\tvalidation_0-mlogloss:1.25007\tvalidation_1-merror:0.430015\tvalidation_1-mlogloss:1.29248\n",
      "[29]\tvalidation_0-merror:0.416345\tvalidation_0-mlogloss:1.24384\tvalidation_1-merror:0.430225\tvalidation_1-mlogloss:1.28754\n",
      "[30]\tvalidation_0-merror:0.415737\tvalidation_0-mlogloss:1.23781\tvalidation_1-merror:0.429804\tvalidation_1-mlogloss:1.28275\n",
      "[31]\tvalidation_0-merror:0.414474\tvalidation_0-mlogloss:1.23204\tvalidation_1-merror:0.428331\tvalidation_1-mlogloss:1.27854\n",
      "[32]\tvalidation_0-merror:0.413421\tvalidation_0-mlogloss:1.22687\tvalidation_1-merror:0.42791\tvalidation_1-mlogloss:1.27459\n",
      "[33]\tvalidation_0-merror:0.412883\tvalidation_0-mlogloss:1.22129\tvalidation_1-merror:0.42812\tvalidation_1-mlogloss:1.27008\n",
      "[34]\tvalidation_0-merror:0.411807\tvalidation_0-mlogloss:1.21662\tvalidation_1-merror:0.428541\tvalidation_1-mlogloss:1.26631\n",
      "[35]\tvalidation_0-merror:0.411456\tvalidation_0-mlogloss:1.21184\tvalidation_1-merror:0.429594\tvalidation_1-mlogloss:1.26278\n",
      "[36]\tvalidation_0-merror:0.410568\tvalidation_0-mlogloss:1.20749\tvalidation_1-merror:0.429173\tvalidation_1-mlogloss:1.25955\n",
      "[37]\tvalidation_0-merror:0.409562\tvalidation_0-mlogloss:1.20307\tvalidation_1-merror:0.42791\tvalidation_1-mlogloss:1.25639\n",
      "[38]\tvalidation_0-merror:0.40893\tvalidation_0-mlogloss:1.1991\tvalidation_1-merror:0.428541\tvalidation_1-mlogloss:1.25373\n",
      "[39]\tvalidation_0-merror:0.408112\tvalidation_0-mlogloss:1.19525\tvalidation_1-merror:0.428752\tvalidation_1-mlogloss:1.25089\n",
      "[40]\tvalidation_0-merror:0.407293\tvalidation_0-mlogloss:1.19176\tvalidation_1-merror:0.42791\tvalidation_1-mlogloss:1.24856\n",
      "[41]\tvalidation_0-merror:0.406451\tvalidation_0-mlogloss:1.18813\tvalidation_1-merror:0.427278\tvalidation_1-mlogloss:1.24607\n",
      "[42]\tvalidation_0-merror:0.405586\tvalidation_0-mlogloss:1.18507\tvalidation_1-merror:0.427489\tvalidation_1-mlogloss:1.24411\n",
      "[43]\tvalidation_0-merror:0.404907\tvalidation_0-mlogloss:1.18191\tvalidation_1-merror:0.427489\tvalidation_1-mlogloss:1.24219\n",
      "[44]\tvalidation_0-merror:0.404159\tvalidation_0-mlogloss:1.17887\tvalidation_1-merror:0.426226\tvalidation_1-mlogloss:1.24021\n",
      "[45]\tvalidation_0-merror:0.403457\tvalidation_0-mlogloss:1.17579\tvalidation_1-merror:0.426437\tvalidation_1-mlogloss:1.23838\n",
      "[46]\tvalidation_0-merror:0.402755\tvalidation_0-mlogloss:1.17288\tvalidation_1-merror:0.425384\tvalidation_1-mlogloss:1.23647\n",
      "[47]\tvalidation_0-merror:0.402405\tvalidation_0-mlogloss:1.17015\tvalidation_1-merror:0.425595\tvalidation_1-mlogloss:1.23489\n",
      "[48]\tvalidation_0-merror:0.401773\tvalidation_0-mlogloss:1.1674\tvalidation_1-merror:0.424121\tvalidation_1-mlogloss:1.23292\n",
      "[49]\tvalidation_0-merror:0.401352\tvalidation_0-mlogloss:1.16508\tvalidation_1-merror:0.423069\tvalidation_1-mlogloss:1.2314\n",
      "[50]\tvalidation_0-merror:0.400416\tvalidation_0-mlogloss:1.16222\tvalidation_1-merror:0.422648\tvalidation_1-mlogloss:1.2301\n",
      "[51]\tvalidation_0-merror:0.400042\tvalidation_0-mlogloss:1.15959\tvalidation_1-merror:0.42349\tvalidation_1-mlogloss:1.22865\n",
      "[52]\tvalidation_0-merror:0.399387\tvalidation_0-mlogloss:1.1571\tvalidation_1-merror:0.423279\tvalidation_1-mlogloss:1.22722\n",
      "[53]\tvalidation_0-merror:0.398639\tvalidation_0-mlogloss:1.15448\tvalidation_1-merror:0.4237\tvalidation_1-mlogloss:1.22599\n",
      "[54]\tvalidation_0-merror:0.397773\tvalidation_0-mlogloss:1.15223\tvalidation_1-merror:0.424332\tvalidation_1-mlogloss:1.22467\n",
      "[55]\tvalidation_0-merror:0.396744\tvalidation_0-mlogloss:1.14956\tvalidation_1-merror:0.423279\tvalidation_1-mlogloss:1.22335\n",
      "[56]\tvalidation_0-merror:0.396487\tvalidation_0-mlogloss:1.14737\tvalidation_1-merror:0.423069\tvalidation_1-mlogloss:1.22238\n",
      "[57]\tvalidation_0-merror:0.395902\tvalidation_0-mlogloss:1.14541\tvalidation_1-merror:0.422648\tvalidation_1-mlogloss:1.22137\n",
      "[58]\tvalidation_0-merror:0.39527\tvalidation_0-mlogloss:1.14335\tvalidation_1-merror:0.422648\tvalidation_1-mlogloss:1.22028\n",
      "[59]\tvalidation_0-merror:0.394733\tvalidation_0-mlogloss:1.14105\tvalidation_1-merror:0.422437\tvalidation_1-mlogloss:1.21911\n",
      "[60]\tvalidation_0-merror:0.39382\tvalidation_0-mlogloss:1.13888\tvalidation_1-merror:0.422016\tvalidation_1-mlogloss:1.21798\n",
      "[61]\tvalidation_0-merror:0.393165\tvalidation_0-mlogloss:1.13657\tvalidation_1-merror:0.421385\tvalidation_1-mlogloss:1.21694\n",
      "[62]\tvalidation_0-merror:0.392557\tvalidation_0-mlogloss:1.13487\tvalidation_1-merror:0.421385\tvalidation_1-mlogloss:1.21595\n",
      "[63]\tvalidation_0-merror:0.39223\tvalidation_0-mlogloss:1.13294\tvalidation_1-merror:0.421595\tvalidation_1-mlogloss:1.215\n",
      "[64]\tvalidation_0-merror:0.391692\tvalidation_0-mlogloss:1.13124\tvalidation_1-merror:0.422227\tvalidation_1-mlogloss:1.21426\n",
      "[65]\tvalidation_0-merror:0.39106\tvalidation_0-mlogloss:1.12943\tvalidation_1-merror:0.422016\tvalidation_1-mlogloss:1.21354\n",
      "[66]\tvalidation_0-merror:0.390756\tvalidation_0-mlogloss:1.12773\tvalidation_1-merror:0.421174\tvalidation_1-mlogloss:1.2125\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[67]\tvalidation_0-merror:0.390218\tvalidation_0-mlogloss:1.12635\tvalidation_1-merror:0.421174\tvalidation_1-mlogloss:1.21185\n",
      "[68]\tvalidation_0-merror:0.38975\tvalidation_0-mlogloss:1.12447\tvalidation_1-merror:0.421174\tvalidation_1-mlogloss:1.21105\n",
      "[69]\tvalidation_0-merror:0.389259\tvalidation_0-mlogloss:1.12291\tvalidation_1-merror:0.421385\tvalidation_1-mlogloss:1.21026\n",
      "[70]\tvalidation_0-merror:0.388791\tvalidation_0-mlogloss:1.1212\tvalidation_1-merror:0.420964\tvalidation_1-mlogloss:1.20956\n",
      "[71]\tvalidation_0-merror:0.388487\tvalidation_0-mlogloss:1.11987\tvalidation_1-merror:0.420333\tvalidation_1-mlogloss:1.2091\n",
      "[72]\tvalidation_0-merror:0.387832\tvalidation_0-mlogloss:1.11769\tvalidation_1-merror:0.420964\tvalidation_1-mlogloss:1.20826\n",
      "[73]\tvalidation_0-merror:0.387154\tvalidation_0-mlogloss:1.11632\tvalidation_1-merror:0.420122\tvalidation_1-mlogloss:1.20755\n",
      "[74]\tvalidation_0-merror:0.386827\tvalidation_0-mlogloss:1.11505\tvalidation_1-merror:0.420333\tvalidation_1-mlogloss:1.20705\n",
      "[75]\tvalidation_0-merror:0.386289\tvalidation_0-mlogloss:1.11335\tvalidation_1-merror:0.419701\tvalidation_1-mlogloss:1.20638\n",
      "[76]\tvalidation_0-merror:0.385914\tvalidation_0-mlogloss:1.11153\tvalidation_1-merror:0.41928\tvalidation_1-mlogloss:1.20559\n",
      "[77]\tvalidation_0-merror:0.385072\tvalidation_0-mlogloss:1.11011\tvalidation_1-merror:0.419491\tvalidation_1-mlogloss:1.20513\n",
      "[78]\tvalidation_0-merror:0.384768\tvalidation_0-mlogloss:1.10863\tvalidation_1-merror:0.418859\tvalidation_1-mlogloss:1.20439\n",
      "[79]\tvalidation_0-merror:0.384137\tvalidation_0-mlogloss:1.10696\tvalidation_1-merror:0.418228\tvalidation_1-mlogloss:1.20377\n",
      "[80]\tvalidation_0-merror:0.383786\tvalidation_0-mlogloss:1.1058\tvalidation_1-merror:0.418649\tvalidation_1-mlogloss:1.20344\n",
      "[81]\tvalidation_0-merror:0.383342\tvalidation_0-mlogloss:1.10404\tvalidation_1-merror:0.418859\tvalidation_1-mlogloss:1.20268\n",
      "[82]\tvalidation_0-merror:0.383014\tvalidation_0-mlogloss:1.10252\tvalidation_1-merror:0.418017\tvalidation_1-mlogloss:1.20199\n",
      "[83]\tvalidation_0-merror:0.382546\tvalidation_0-mlogloss:1.10113\tvalidation_1-merror:0.418228\tvalidation_1-mlogloss:1.20145\n",
      "[84]\tvalidation_0-merror:0.381868\tvalidation_0-mlogloss:1.09975\tvalidation_1-merror:0.417807\tvalidation_1-mlogloss:1.201\n",
      "[85]\tvalidation_0-merror:0.38154\tvalidation_0-mlogloss:1.0982\tvalidation_1-merror:0.417386\tvalidation_1-mlogloss:1.20046\n",
      "[86]\tvalidation_0-merror:0.380652\tvalidation_0-mlogloss:1.09668\tvalidation_1-merror:0.417596\tvalidation_1-mlogloss:1.19991\n",
      "[87]\tvalidation_0-merror:0.380698\tvalidation_0-mlogloss:1.09527\tvalidation_1-merror:0.417175\tvalidation_1-mlogloss:1.19943\n",
      "[88]\tvalidation_0-merror:0.380348\tvalidation_0-mlogloss:1.09419\tvalidation_1-merror:0.418017\tvalidation_1-mlogloss:1.19906\n",
      "[89]\tvalidation_0-merror:0.38002\tvalidation_0-mlogloss:1.09305\tvalidation_1-merror:0.418017\tvalidation_1-mlogloss:1.19865\n",
      "[90]\tvalidation_0-merror:0.379459\tvalidation_0-mlogloss:1.09195\tvalidation_1-merror:0.417386\tvalidation_1-mlogloss:1.19836\n",
      "[91]\tvalidation_0-merror:0.379178\tvalidation_0-mlogloss:1.09081\tvalidation_1-merror:0.417596\tvalidation_1-mlogloss:1.19797\n",
      "[92]\tvalidation_0-merror:0.378897\tvalidation_0-mlogloss:1.08957\tvalidation_1-merror:0.417596\tvalidation_1-mlogloss:1.19754\n",
      "[93]\tvalidation_0-merror:0.378547\tvalidation_0-mlogloss:1.08827\tvalidation_1-merror:0.417596\tvalidation_1-mlogloss:1.19706\n",
      "[94]\tvalidation_0-merror:0.378009\tvalidation_0-mlogloss:1.08725\tvalidation_1-merror:0.417386\tvalidation_1-mlogloss:1.19676\n",
      "[95]\tvalidation_0-merror:0.377705\tvalidation_0-mlogloss:1.08592\tvalidation_1-merror:0.417386\tvalidation_1-mlogloss:1.19668\n",
      "[96]\tvalidation_0-merror:0.377283\tvalidation_0-mlogloss:1.08449\tvalidation_1-merror:0.418228\tvalidation_1-mlogloss:1.19619\n",
      "[97]\tvalidation_0-merror:0.37705\tvalidation_0-mlogloss:1.08349\tvalidation_1-merror:0.418228\tvalidation_1-mlogloss:1.19576\n",
      "[98]\tvalidation_0-merror:0.376722\tvalidation_0-mlogloss:1.08245\tvalidation_1-merror:0.417386\tvalidation_1-mlogloss:1.19558\n",
      "[99]\tvalidation_0-merror:0.376371\tvalidation_0-mlogloss:1.08146\tvalidation_1-merror:0.418017\tvalidation_1-mlogloss:1.19535\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "XGBClassifier(alpha=0.8, base_score=0.5, booster='gbtree',\n",
       "       colsample_bylevel=1, colsample_bytree=1, eta=0.1, gamma=0,\n",
       "       learning_rate=0.1, max_delta_step=0, max_depth=7,\n",
       "       min_child_weight=1, missing=None, n_estimators=100, n_jobs=1,\n",
       "       nthread=None, num_class=7, objective='multi:softprob',\n",
       "       random_state=0, reg_alpha=0, reg_lambda=50, scale_pos_weight=1,\n",
       "       seed=None, silent=True, subsample=1, verbosity=1)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = XGBClassifier(learning_rate=0.01,max_depth= 7,eta= 0.1,verbosity= 1,objective= 'multi:softprob',num_class= 7,reg_lambda=0)\n",
    "eval_set = [(X_train, y_train), (X_test, y_test)]\n",
    "model.fit(X_train,y_train,eval_metric=['merror','mlogloss'],eval_set=eval_set, verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done   2 out of   5 | elapsed:  2.5min remaining:  3.8min\n",
      "[Parallel(n_jobs=-1)]: Done   5 out of   5 | elapsed:  2.6min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.5748188  0.57792587 0.57572214 0.56883846 0.57102738]\n",
      "0.5736665303633456\n"
     ]
    }
   ],
   "source": [
    "model = XGBClassifier(n_estimators=90,max_depth=6,min_child_weight=5,eta=0.01,verbosity= 1,colsample_bytree=0.5,objective= 'multi:softprob',num_class= 8)\n",
    "scores = cross_val_score(model, X_train, y_train, cv=5,n_jobs=-1,verbose=1)\n",
    "predictions = cross_val_predict(model, X_train,y_train,cv=5,n_jobs=3)\n",
    "r2 = metrics.r2_score(y_train, predictions)\n",
    "print(scores)\n",
    "print(scores.mean())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "CV Results - XGBClassifier(max_depth= 7,eta= 0.1,verbosity= 1,objective= 'multi:softprob',num_class=8,alpha=0.8,reg_lambda=50)\n",
    "\n",
    "[0.57657236 0.57780896 0.57595603 0.56743479 0.56938919]\n",
    "0.5734322647763243\n",
    "\n",
    "CV Results - n_estimators=90,max_depth=5,eta=0.1,verbosity= 1,colsample_bytree=0.5,objective= 'multi:softprob',num_class= 8,reg_lambda=0\n",
    "\n",
    "[0.57610475 0.57359991 0.57595603 0.56392561 0.57126141]\n",
    "0.572169539099591\n",
    "\n",
    "n_estimators=90,max_depth=5,eta=0.01,verbosity= 1,colsample_bytree=0.5,objective= 'multi:softprob',num_class= 8,reg_lambda=0)\n",
    "\n",
    "[0.57610475 0.57359991 0.57595603 0.56392561 0.57126141]\n",
    "0.572169539099591"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = model.predict(X_test)\n",
    "predictions = [round(value) for value in y_pred]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "accuracy = accuracy_score(y_test, predictions)\n",
    "print(\"Accuracy: %.2f%%\" % (accuracy * 100.0))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### XGBoost - Grid Search for Best Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "parameters = {'max_depth':[4,5,6,7,8,9],\n",
    "              'lerning_rate':[0.01,0.05,0.1,1],\n",
    "              'gamma':[0,1],\n",
    "              'min_child_weight':[1,5,10,50,100]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=5, error_score='raise-deprecating',\n",
       "       estimator=XGBClassifier(base_score=0.5, booster='gbtree', colsample_bylevel=1,\n",
       "       colsample_bytree=0.5, gamma=0, learning_rate=0.1, max_delta_step=0,\n",
       "       max_depth=3, min_child_weight=1, missing=None, n_estimators=90,\n",
       "       n_jobs=1, nthread=None, num_class=8, objective='multi:softprob',\n",
       "       random_state=0, reg_alpha=0, reg_lambda=1, scale_pos_weight=1,\n",
       "       seed=None, silent=True, subsample=1, verbosity=1),\n",
       "       fit_params=None, iid='warn', n_jobs=-1,\n",
       "       param_grid={'max_depth': [4, 5, 6, 7, 8, 9], 'lerning_rate': [0.01, 0.05, 0.1, 1], 'gamma': [0, 1], 'min_child_weight': [1, 5, 10, 50, 100]},\n",
       "       pre_dispatch='2*n_jobs', refit=True, return_train_score='warn',\n",
       "       scoring=None, verbose=0)"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = XGBClassifier(n_estimators=90,colsample_bytree=0.5,verbosity= 1,objective= 'multi:softprob',num_class= 8)\n",
    "grid_search = GridSearchCV(model,param_grid=parameters,cv=5,n_jobs=-1)\n",
    "grid_search.fit(X_test,y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'gamma': 1, 'lerning_rate': 0.01, 'max_depth': 6, 'min_child_weight': 5}"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid_search.best_params_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### XGBoost - Further tuning to reduce overfitting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "baseline:  0.36575211096297333\n",
      "-------------------------------\n",
      "accuracy score - train:  0.5829532430472716\n",
      "accuracy score - test:  0.5701776542898038\n",
      "-------------------------------\n",
      "log loss score - train:  1.1895278844277202\n",
      "log loss score - test:  1.218885442312442\n"
     ]
    }
   ],
   "source": [
    "from xgboost import XGBClassifier\n",
    "model = XGBClassifier(n_estimators=100,max_depth=6,subsample=0.8,min_child_weight=5,eta=0.02,verbosity= 1,colsample_bytree=0.6,objective= 'multi:softprob',num_class= 8,gamma=5,reg_lambda=10,reg_alpha=6)\n",
    "model.fit(X_train.values,y_train)\n",
    "\n",
    "accuracy_score_test = model.score(X_holdout.values,y_holdout)\n",
    "accuracy_score_train = model.score(X_train.values,y_train)\n",
    "\n",
    "y_pred = model.predict_proba(X_holdout.values)\n",
    "log_loss_test = log_loss(y_holdout,y_pred)\n",
    "\n",
    "y_pred = model.predict_proba(X_train.values)\n",
    "log_loss_train = log_loss(y_train,y_pred)\n",
    "\n",
    "print('baseline: ',baseline)\n",
    "print('-------------------------------')\n",
    "print(\"accuracy score - train: \",accuracy_score_train)\n",
    "print(\"accuracy score - test: \",accuracy_score_test)\n",
    "print('-------------------------------')\n",
    "print(\"log loss score - train: \",log_loss_train)\n",
    "print(\"log loss score - test: \",log_loss_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------------------------------\n",
      "accuracy score - test:  0.5765102083771837\n",
      "-------------------------------\n",
      "log loss score - test:  1.215316698195068\n"
     ]
    }
   ],
   "source": [
    "accuracy_score_test = model.score(X_test.values,y_test)\n",
    "\n",
    "y_pred = model.predict_proba(X_test.values)\n",
    "log_loss_test = log_loss(y_test.values,y_pred)\n",
    "\n",
    "\n",
    "print('-------------------------------')\n",
    "print(\"accuracy score - test: \",accuracy_score_test)\n",
    "print('-------------------------------')\n",
    "print(\"log loss score - test: \",log_loss_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Roy\\Anaconda3\\lib\\site-packages\\xgboost\\core.py:587: FutureWarning: Series.base is deprecated and will be removed in a future version\n",
      "  if getattr(data, 'base', None) is not None and \\\n"
     ]
    }
   ],
   "source": [
    "dmatrix = xgb.DMatrix(X_train, label=y_train)\n",
    "# shap_values = explainer.shap_values(dmatrix)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Extra Trees"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import ExtraTreesClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done   2 out of   5 | elapsed:    2.4s remaining:    3.6s\n",
      "[Parallel(n_jobs=-1)]: Done   5 out of   5 | elapsed:    4.1s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.53320084 0.53513387 0.5411063  0.52567552 0.52527498]\n",
      "0.5320783032552917\n",
      "0.06869960644352158\n"
     ]
    }
   ],
   "source": [
    "extra_tree = ExtraTreesClassifier(max_depth=10,max_features=100,\n",
    "                                 bootstrap=True,n_jobs=-1,\n",
    "                                 random_state=1,verbose=1)\n",
    "scores = cross_val_score(extra_tree, X_train, y_train, cv=5,n_jobs=-1,verbose=1)\n",
    "predictions = cross_val_predict(extra_tree, X_train,y_train,cv=5,n_jobs=3)\n",
    "r2 = metrics.r2_score(y_train, predictions)\n",
    "print(scores)\n",
    "print(scores.mean())\n",
    "print(r2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ensemble - Voting Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import VotingClassifier\n",
    "\n",
    "estimators=[('rf', forest),('xgboost', model)]\n",
    "\n",
    "ensemble = VotingClassifier(estimators, voting='hard')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done  10 out of  10 | elapsed:    0.2s finished\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "VotingClassifier(estimators=[('rf', RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
       "            max_depth=5, max_features='auto', max_leaf_nodes=30,\n",
       "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "            min_samples_leaf=1, min_samples_split=2,\n",
       "            min_weight_...a=6, reg_lambda=10, scale_pos_weight=1,\n",
       "       seed=None, silent=None, subsample=0.8, verbosity=1))],\n",
       "         flatten_transform=None, n_jobs=None, voting='hard', weights=None)"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ensemble.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done  10 out of  10 | elapsed:    0.0s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.5733632727527893\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done  10 out of  10 | elapsed:    0.0s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.5649336981688066\n"
     ]
    }
   ],
   "source": [
    "print(ensemble.score(X_train, y_train))\n",
    "print(ensemble.score(X_test, y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ensemble  Attempt\n",
    "\n",
    "Manual attempt at creating an ensamble. This was also done through a package in the model comparison workbook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "meta_learner = GradientBoostingClassifier(n_estimators=1000,max_depth=5,subsample=0.8,learning_rate=0.001,random_state=20)\n",
    "xtrain_base, xpred_base, ytrain_base, ypred_base = train_test_split(X_train, y_train, test_size=0.5, random_state=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr = LogisticRegression(multi_class='auto', solver = 'liblinear')\n",
    "forest = RandomForestClassifier(max_depth=5,max_leaf_nodes=30,verbose=1)\n",
    "xgb = XGBClassifier(n_estimators=100,max_depth=6,subsample=0.8,min_child_weight=5,eta=0.02,\n",
    "                    verbosity= 1,colsample_bytree=0.6,objective= 'multi:softprob',num_class= 8,\n",
    "                    gamma=5,reg_lambda=10,reg_alpha=6)\n",
    "extra_tree = ExtraTreesClassifier(max_depth=10,max_features=100,\n",
    "                                 bootstrap=True,n_jobs=-1,\n",
    "                                 random_state=1,verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_base_learners(base_learners, inp, out, verbose=True): ## Just fitting models here\n",
    "    if verbose: print(\"Fitting models.\")\n",
    "    for i, (name, m) in enumerate(base_learners.items()):\n",
    "        if verbose: print(\"%s...\" % name, end=\" \", flush=False)\n",
    "        m.fit(inp, out) ## main line\n",
    "        if verbose: print(\"done\")\n",
    "    \n",
    "            \n",
    "def predict_base_learners(pred_base_learners, inp, verbose=True):\n",
    "    P = np.zeros((inp.shape[0], len(pred_base_learners)))\n",
    "    if verbose: print(\"Generating base learner predictions.\")\n",
    "    for i, (name, m) in enumerate(pred_base_learners.items()):\n",
    "        if verbose: print(\"%s...\" % name, end=\" \", flush=False)\n",
    "        p = m.predict(inp) #predicting using base learners and creating a np array of the results from all the base learners.\n",
    "        P[:, i] = p\n",
    "        if verbose: print(\"done\")\n",
    "    return P"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting models.\n",
      "lr... done\n",
      "xgb... done\n"
     ]
    }
   ],
   "source": [
    "#attempted various combinations of the 4 models. The last testd was as below (LR and XGB only)\n",
    "train_base_learners({'lr':lr,'xgb':xgb}, xtrain_base, ytrain_base,verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generating base learner predictions.\n",
      "lr... done\n",
      "xgb... "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Roy\\Anaconda3\\lib\\site-packages\\numpy\\core\\_methods.py:36: RuntimeWarning: overflow encountered in reduce\n",
      "  return umr_sum(a, axis, dtype, out, keepdims, initial)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done\n"
     ]
    }
   ],
   "source": [
    "P_base = predict_base_learners({'lr':lr,'xgb':xgb}, xpred_base)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GradientBoostingClassifier(criterion='friedman_mse', init=None,\n",
       "              learning_rate=0.001, loss='deviance', max_depth=5,\n",
       "              max_features=None, max_leaf_nodes=None,\n",
       "              min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "              min_samples_leaf=1, min_samples_split=2,\n",
       "              min_weight_fraction_leaf=0.0, n_estimators=1000,\n",
       "              n_iter_no_change=None, presort='auto', random_state=20,\n",
       "              subsample=0.8, tol=0.0001, validation_fraction=0.1,\n",
       "              verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "meta_learner.fit(P_base, ypred_base) # fitting meta learning which is a Gradient Boosting Classifier defined previously"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_learners = {'lr':lr,'xgb':xgb}\n",
    "\n",
    "def ensemble_predict(base_learners, meta_learner, inp, verbose=True):\n",
    "    P_pred = predict_base_learners(base_learners, inp, verbose=verbose)\n",
    "    return P_pred, meta_learner.predict(P_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generating base learner predictions.\n",
      "lr... done\n",
      "xgb... "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Roy\\Anaconda3\\lib\\site-packages\\numpy\\core\\_methods.py:36: RuntimeWarning: overflow encountered in reduce\n",
      "  return umr_sum(a, axis, dtype, out, keepdims, initial)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done\n",
      "\n",
      "Ensemble y_holdout score: 0.559\n"
     ]
    }
   ],
   "source": [
    "P_pred, p = ensemble_predict(base_learners, meta_learner, X_holdout)\n",
    "print(\"\\nEnsemble y_holdout score: %.3f\" % accuracy_score(y_holdout, p))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "ename": "NotFittedError",
     "evalue": "This RandomForestClassifier instance is not fitted yet. Call 'fit' with appropriate arguments before using this method.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNotFittedError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-94-22e96dda2924>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mtesty\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mforest\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpredict_proba\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_test\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\sklearn\\ensemble\\forest.py\u001b[0m in \u001b[0;36mpredict_proba\u001b[1;34m(self, X)\u001b[0m\n\u001b[0;32m    579\u001b[0m             \u001b[0mclasses\u001b[0m \u001b[0mcorresponds\u001b[0m \u001b[0mto\u001b[0m \u001b[0mthat\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mthe\u001b[0m \u001b[0mattribute\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m`\u001b[0m\u001b[0mclasses_\u001b[0m\u001b[0;31m`\u001b[0m\u001b[1;33m.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    580\u001b[0m         \"\"\"\n\u001b[1;32m--> 581\u001b[1;33m         \u001b[0mcheck_is_fitted\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'estimators_'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    582\u001b[0m         \u001b[1;31m# Check data\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    583\u001b[0m         \u001b[0mX\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_validate_X_predict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\u001b[0m in \u001b[0;36mcheck_is_fitted\u001b[1;34m(estimator, attributes, msg, all_or_any)\u001b[0m\n\u001b[0;32m    949\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    950\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mall_or_any\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mhasattr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mestimator\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mattr\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mattr\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mattributes\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 951\u001b[1;33m         \u001b[1;32mraise\u001b[0m \u001b[0mNotFittedError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmsg\u001b[0m \u001b[1;33m%\u001b[0m \u001b[1;33m{\u001b[0m\u001b[1;34m'name'\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mtype\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mestimator\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__name__\u001b[0m\u001b[1;33m}\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    952\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    953\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNotFittedError\u001b[0m: This RandomForestClassifier instance is not fitted yet. Call 'fit' with appropriate arguments before using this method."
     ]
    }
   ],
   "source": [
    "testy=forest.predict_proba(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4751, 8)"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "testy[:,0:8].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=8)]: Using backend ThreadingBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=8)]: Done   6 out of  10 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=8)]: Done  10 out of  10 | elapsed:    0.0s finished\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.5270469374868448"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "extra_tree.score(X_test,y_test)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
